[{"title":"JVM简述","date":"2024-10-10T03:24:21.517Z","date_formatted":{"ll":"2024年10月10日","L":"2024/10/10","MM-DD":"10-10"},"updated":"2024-10-11T08:00:57.057Z","content":"一、什么是JVM\nJVM是Java Virtual Machine（Java 虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。\nJava语言的一个非常重要的特点就是平台无关性。而使用Java虚拟机是实现这一特点的关键。一般的高级语言如果要在不同的平台上运行，至少需要编译成不同的目标代码。而引入Java语言虚拟机后，Java语言在不同平台上运行时不需要重新编译。Java语言使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。这就是Java的能够“一次编译，到处运行”的原因。\n二、JVM总体概述\nJVM总体上是由类装载子系统（ClassLoader）、运行时数据区、执行引擎、垃圾收集这四个部分组成。其中我们最为关注的运行时数据区，也就是JVM的内存部分则是由方法区（Method Area）、JAVA堆（Java Heap）、虚拟机栈（JVM Stack）、程序计数器、本地方法栈（Native Method Stack）这几部分组成。\n三、JVM体系结构\n\n3.1 类装载子系统\nClass Loader类加载器负责加载.class文件，class文件在文件开头有特定的文件标示，并且ClassLoader负责class文件的加载等，至于它是否可以运行，则由Execution Engine决定。\n3.2 运行时数据区\n栈管运行，堆管存储。JVM调优主要是优化Java堆和方法区。\n3.2.1 方法区(Method Area)\n方法区是各线程共享的内存区域，它用于存储已被JVM加载的类信息、常量、静态变量、运行时常量池等数据。\n3.2.2 Java堆(Java Heap)\nJava堆是各线程共享的内存区域，在JVM启动时创建，这块区域是JVM中最大的， 用于存储应用的对象和数组，也是GC主要的回收区，一个 JVM 实例只存在一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件后，需要把类、方法、常变量放到堆内存中，以方便执行器执行，堆内存分为三部分：新生代、老年代、永久代。\n说明：\n\nJdk1.6及之前：常量池分配在永久代 。\nJdk1.7：有，但已经逐步“去永久代” 。\nJdk1.8及之后：无永久代，改用元空间代替(java.lang.OutOfMemoryError: PermGen space,这种错误将不会出现在JDK1.8中)。\n\n3.2.3 Java栈(JVM Stack)\n\n栈是什么\n\nJava栈是线程私有的，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就Over，生命周期和线程一致。基本类型的变量和对象的引用变量都是在函数的栈内存中分配。\n\n栈存储什么\n\n每个方法执行的时候都会创建一个栈帧，栈帧中主要存储3类数据：\n\n局部变量表：输入参数和输出参数以及方法内的变量；\n栈操作：记录出栈和入栈的操作；\n栈帧数据：包括类文件、方法等等。\n\n\n栈运行原理\n\n栈中的数据都是以栈帧的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法和运行期数据的数据集。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在栈中从入栈到出栈的过程。\n\n\n本地方法栈(Native Method Stack)\n\n本地方法栈和JVM栈发挥的作用非常相似，也是线程私有的，区别是JVM栈为JVM执行Java方法（也就是字节码）服务，而本地方法栈为JVM使用到的Native方法服务。它的具体做法是在本地方法栈中登记native方法，在执行引擎执行时加载Native Liberies.有的虚拟机（比如Sun Hotpot）直接把两者合二为一。\n\n\n程序计数器(Program Counter Register)\n程序计数器是一块非常小的内存空间，几乎可以忽略不计，每个线程都有一个程序计算器，是线程私有的，可以看作是当前线程所执行的字节码的行号指示器，指向方法区中的方法字节码（下一个将要执行的指令代码），由执行引擎读取下一条指令。\n\n\n运行时常量池\n运行时常量池是方法区的一部分，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。相较于Class文件常量池，运行时常量池更具动态性，在运行期间也可以将新的变量放入常量池中，而不是一定要在编译时确定的常量才能放入。最主要的运用便是String类的intern()方法。\n\n\n\n3.3 执行引擎(Execution Engine)\n执行引擎执行包在装载类的方法中的指令，也就是方法。执行引擎以指令为单位读取Java字节码。它就像一个CPU一样，一条一条地执行机器指令。每个字节码指令都由一个1字节的操作码和附加的操作数组成。执行引擎取得一个操作码，然后根据操作数来执行任务，完成后就继续执行下一条操作码。\n不过Java字节码是用一种人类可以读懂的语言编写的，而不是用机器可以直接执行的语言。因此，执行引擎必须把字节码转换成可以直接被JVM执行的语言。字节码可以通过以下两种方式转换成合适的语言：\n\n解释器： 一条一条地读取，解释并执行字节码执行，所以它可以很快地解释字节码，但是执行起来会比较慢。这是解释执行语言的一个缺点。\n即时编译器：用来弥补解释器的缺点，执行引擎首先按照解释执行的方式来执行，然后在合适的时候，即时编译器把整段字节码编译成本地代码。然后，执行引擎就没有必要再去解释执行方法了，它可以直接通过本地代码去执行。执行本地代码比一条一条进行解释执行的速度快很多，编译后的代码可以执行的很快，因为本地代码是保存在缓存里的。\n\n\n3.4 垃圾收集(Garbage Collection, GC)\n3.4.1 什么是垃圾收集\n垃圾收集即垃圾回收，简单的说垃圾回收就是回收内存中不再使用的对象。所谓使用中的对象（已引用对象），指的是程序中有指针指向的对象；而未使用中的对象（未引用对象），则没有被任何指针给指向，因此占用的内存也可以被回收掉。\n垃圾回收的基本步骤分两步：\n\n查找内存中不再使用的对象（GC判断策略）\n释放这些对象占用的内存（GC收集算法）\n\n3.4.2 GC判断策略\n\n\n引用计数算法\n引用计数算法是给对象添加一个引用计数器，每当有一个引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器都为0的对象就是不可能再被使用的对象。缺点：很难解决对象之间相互循环引用的问题。\n\n\n根搜索算法\n根搜索算法的基本思路就是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连（也就是说从GC Roots到这个对象不可达）时，则证明此对象是不可用的。\n\n\n在Java语言里，可作为GC Roots的对象包括以下几种：\n\n虚拟机栈（栈帧中的本地变量表）中引用的对象；\n方法区中类静态属性引用的对象；\n方法区中常量应用的对象；\n本地方法栈中JNI（Native方法）引用的对象。\n\n\n注：在根搜索算法中不可达的对象，也并非是“非死不可”的，因为要真正宣告一个对象死亡，至少要经历两次标记过程：第一次是标记没有与GC Roots相连接的引用链；第二次是GC对在F-Queue执行队列中的对象进行的小规模标记(对象需要覆盖finalize()方法且没被调用过)。\n3.4.3 GC收集算法\n\n标记-清除算法（Mark-Sweep）\n\n标记-清楚算法采用从根集合（GC Roots）进行扫描，首先标记出所有需要回收的对象（根搜索算法），标记完成后统一回收掉所有被标记的对象。\n\n该算法有两个问题：\n\n效率问题：标记和清除过程的效率都不高；\n空间问题：标记清除后会产生大量不连续的内存碎片, 空间碎片太多可能会导致在运行过程中需要分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾收集。\n\n\n复制算法（Copying）\n\n复制算法是将可用内存按容量划分为大小相等的两块, 每次只用其中一块, 当这一块的内存用完, 就将还存活的对象复制到另外一块上面, 然后把已使用过的内存空间一次清理掉。\n\n\n标记-整理算法（Mark-Compact）\n\n标记整理算法的标记过程与标记清除算法相同, 但后续步骤不再对可回收对象直接清理, 而是让所有存活的对象都向一端移动,然后清理掉端边界以外的内存。\n\n\n分代收集算法（Generational Collection）\n\n分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。\n\n新生代（Young Generation）的回收算法（以复制算法为主）\n\n所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。\n新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。\n当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC(Major GC)，也就是新生代、老年代都进行回收。\n新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发)。\n\n老年代（Tenured Generation）的回收算法（以标记-清除、标记-整理为主）\n\n在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到老年代中。因此，可以认为老年代中存放的都是一些生命周期较长的对象。\n内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。\n\n永久代（Permanet Generation）的回收算法\n用于存放静态文件，如Java类、方法等。永久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的永久代空间来存放这些运行过程中新增的类。永久代也称方法区。方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过根搜索算法来判断，但是对于无用的类则需要同时满足下面3个条件：\n\n该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；\n加载该类的ClassLoader已经被回收；\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\n3.4.4 垃圾收集器\n\nSerial收集器（复制算法)\n\n新生代单线程收集器，标记和清理都是单线程，优点是简单高效。是client级别默认的GC方式，可以通过-XX:+UseSerialGC来强制指定。\n\nSerial Old收集器(标记-整理算法)\n\n老年代单线程收集器，Serial收集器的老年代版本。\n\nParNew收集器(停止-复制算法)\n\n新生代多线程收集器，其实就是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。\n\nParallel Scavenge收集器(停止-复制算法)\n\n新生代并行的多线程收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。是server级别默认采用的GC方式，可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。\n\nParallel Old收集器(停止-复制算法)\n\n老年代并行的多线程收集器，Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先。\n\nCMS(Concurrent Mark Sweep)收集器（标记-清除算法）\n\nCMS收集器是一种以获取最短回收停顿时间为目标的收集器，CMS收集器是基于“标记–清除”(Mark-Sweep)算法实现的，整个过程分为四个步骤：\n\n初始标记： 标记GC Roots能直接关联到的对象，速度很快；\n并发标记： 进行GC Roots Tracing的过程；\n重新标记： 修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但比并发标记时间短；\n并发清除： 整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。\n优点：并发收集、低停顿\n缺点：对CPU资源非常敏感、无法处理浮动垃圾、产生大量空间碎片。\n\n\nG1(Garbage First)收集器（标记-整理算法）\n\nG1是一款面向服务端应用的垃圾收集器，是基于“标记-整理”算法实现的，与其他GC收集器相比，G1具备如下特点：\n\n并行与并发\n分代收集\n空间整合\n可预测性的停顿\n\nG1运作步骤：\n\n初始标记(stop the world事件，CPU停顿只处理垃圾)\n并发标记(与用户线程并发执行)\n最终标记(stop the world事件，CPU停顿处理垃圾)\n筛选回收(stop the world事件，根据用户期望的GC停顿时间回收)\n\n3.4.5 垃圾收集结构图\n\n","plink":"https://zinki.github.io/2024/10/10/JVM简述/"},{"title":"一致性Hash原理与实现","date":"2023-10-25T10:30:00.000Z","date_formatted":{"ll":"2023年10月25日","L":"2023/10/25","MM-DD":"10-25"},"updated":"2024-10-11T08:05:48.513Z","content":"前言\n互联网公司中，绝大部分都没有马爸爸系列的公司那样财大气粗，他们即没有强劲的服务器、也没有钱去购买昂贵的海量数据库。那他们是怎么应对大数据量高并发的业务场景的呢？\n 这个和当前的开源技术、海量数据架构都有着不可分割的关系。比如通过mysql、nginx等开源软件，通过架构和低成本的服务器搭建千万级别的用户访问系统。\n 怎么样搭建一个好的系统架构，这个话题我们能聊上个七天七夜。这里我主要结合Redis集群来讲一下一致性Hash的相关问题。\nRedis集群的使用\n我们在使用Redis的过程中，为了保证Redis的高可用，我们一般会对Redis做主从复制，组成Master-Master或者Master-Slave的形式，进行数据的读写分离，如下图1-1所示：\n\n当缓存数据量超过一定的数量时，我们就要对Redis集群做分库分表的操作。\n来个栗子，我们有一个电商平台，需要使用Redis存储商品的图片资源，存储的格式为键值对，key值为图片名称，Value为该图片所在的文件服务器的路径，我们需要根据文件名，查找到文件所在的文件服务器上的路径，我们的图片数量大概在3000w左右，按照我们的规则进行分库，规则就是随机分配的，我们以每台服务器存500w的数量，部署12台缓存服务器，并且进行主从复制，架构图如下图1-2所示：\n\n由于我们定义的规则是随机的，所以我们的数据有可能存储在任何一组Redis中，比如我们需要查询&quot;product.png&quot;的图片，由于规则的随机性，我们需要遍历所有Redis服务器，才能查询得到。这样的结果显然不是我们所需要的。所以我们会想到按某一个字段值进行Hash值、取模。所以我们就看看使用Hash的方式是怎么进行的。\n使用Hash的Redis集群\n如果我们使用Hash的方式，每一张图片在进行分库的时候都可以定位到特定的服务器，示意图如图1-3所示：\n\n从上图中，我们需要查询的是图product.png，由于我们有6台主服务器，所以计算的公式为：hash(product.png) % 6 = 5, 我们就可以定位到是5号主从，这们就省去了遍历所有服务器的时间，从而大大提升了性能。\n使用Hash时遇到的问题\n在上述hash取模的过程中，我们虽然不需要对所有Redis服务器进行遍历而提升了性能。但是，使用Hash算法缓存时会出现一些问题，Redis服务器变动时，所有缓存的位置都会发生改变。\n 比如，现在我们的Redis缓存服务器增加到了8台，我们计算的公式从hash(product.png) % 6 = 5变成了hash(product.png) % 8 = ? 结果肯定不是原来的5了。\n 再者，6台的服务器集群中，当某个主从群出现故障时，无法进行缓存，那我们需要把故障机器移除，所以取模数又会从6变成了5。我们计算的公式也会变化。\n由于上面hash算法是使用取模来进行缓存的，为了规避上述情况，Hash一致性算法就诞生了\n一致性Hash算法原理\n一致性Hash算法也是使用取模的方法，不过，上述的取模方法是对服务器的数量进行取模，而一致性的Hash算法是对2的32方取模。即一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为0 ~ 2^32 - 1(一个32位无符号整型)，整个哈希环如下：\n\n整个圆环以顺时针方向组织，圆环正上方的点代表0，0点右侧的第一个点代表1，以此类推。 第二步，我们将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台服务器就确定在了哈希环的一个位置上，比如我们有三台机器，使用IP地址哈希后在环空间的位置如图1-4所示：\n\n现在，我们使用以下算法定位数据访问到相应的服务器：\n将数据Key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是其应该定位到的服务器。\n例如，现在有ObjectA，ObjectB，ObjectC三个数据对象，经过哈希计算后，在环空间上的位置如下：\n\n根据一致性算法，Object -&gt; NodeA，ObjectB -&gt; NodeB, ObjectC -&gt; NodeC\n一致性Hash算法的容错性和可扩展性\n现在，假设我们的Node C宕机了，我们从图中可以看到，A、B不会受到影响，只有Object C对象被重新定位到Node A。所以我们发现，在一致性Hash算法中，如果一台服务器不可用，受影响的数据仅仅是此服务器到其环空间前一台服务器之间的数据（这里为Node C到Node B之间的数据），其他不会受到影响。如图1-6所示：\n\n另外一种情况，现在我们系统增加了一台服务器Node X，如图1-7所示：\n\n此时对象ObjectA、ObjectB没有受到影响，只有Object C重新定位到了新的节点X上。\n 如上所述：\n一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，有很好的容错性和可扩展性。\n数据倾斜问题\n在一致性Hash算法服务节点太少的情况下，容易因为节点分布不均匀面造成数据倾斜（被缓存的对象大部分缓存在某一台服务器上）问题，如图1-8特例：\n\n这时我们发现有大量数据集中在节点A上，而节点B只有少量数据。为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。 具体操作可以为服务器IP或主机名后加入编号来实现，实现如图1-9所示：\n\n数据定位算法不变，只需要增加一步：虚拟节点到实际点的映射。\n 所以加入虚拟节点之后，即使在服务节点很少的情况下，也能做到数据的均匀分布。\n具体实现\n算法接口类\n123public interface IHashService &#123;      Long hash(String key);  &#125;\n算法接口实现类\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class HashService implements IHashService &#123;        /**       * MurMurHash算法,性能高,碰撞率低     *       * @param key String       * @return Long       */      public Long hash(String key) &#123;          ByteBuffer buf = ByteBuffer.wrap(key.getBytes());          int seed = 0x1234ABCD;            ByteOrder byteOrder = buf.order();          buf.order(ByteOrder.LITTLE_ENDIAN);            long m = 0xc6a4a7935bd1e995L;          int r = 47;            long h = seed ^ (buf.remaining() * m);            long k;          while (buf.remaining() &gt;= 8) &#123;              k = buf.getLong();                k *= m;              k ^= k &gt;&gt;&gt; r;              k *= m;                h ^= k;              h *= m;          &#125;            if (buf.remaining() &gt; 0) &#123;              ByteBuffer finish = ByteBuffer.allocate(8).order(ByteOrder.LITTLE_ENDIAN);              finish.put(buf).rewind();              h ^= finish.getLong();              h *= m;          &#125;            h ^= h &gt;&gt;&gt; r;          h *= m;          h ^= h &gt;&gt;&gt; r;            buf.order(byteOrder);          return h;        &#125;  &#125;\n模拟机器节点\n1234567891011121314151617181920212223242526272829303132333435public class Node&lt;T&gt; &#123;      private String ip;      private String name;        public Node(String ip, String name) &#123;          this.ip = ip;          this.name = name;      &#125;        public String getIp() &#123;          return ip;      &#125;        public void setIp(String ip) &#123;          this.ip = ip;      &#125;        public String getName() &#123;          return name;      &#125;        public void setName(String name) &#123;          this.name = name;      &#125;        /**       * 使用IP当做hash的Key       *       * @return String       */      @Override      public String toString() &#123;          return ip;      &#125;  &#125;\n一致性Hash操作\n123456789101112131415161718192021222324252627282930313233343536373839404142434445public class ConsistentHash&lt;T&gt; &#123;      // Hash函数接口    private final IHashService iHashService;      // 每个机器节点关联的虚拟节点数量    private final int          numberOfReplicas;      // 环形虚拟节点    private final SortedMap&lt;Long, T&gt; circle = new TreeMap&lt;Long, T&gt;();        public ConsistentHash(IHashService iHashService, int numberOfReplicas, Collection&lt;T&gt; nodes) &#123;          this.iHashService = iHashService;          this.numberOfReplicas = numberOfReplicas;          for (T node : nodes) &#123;              add(node);          &#125;      &#125;        /**       * 增加真实机器节点     *       * @param node T       */      public void add(T node) &#123;          for (int i = 0; i &lt; this.numberOfReplicas; i++) &#123;              circle.put(this.iHashService.hash(node.toString() + i), node);          &#125;      &#125;        /**       * 删除真实机器节点     *       * @param node T       */      public void remove(T node) &#123;          for (int i = 0; i &lt; this.numberOfReplicas; i++) &#123;              circle.remove(this.iHashService.hash(node.toString() + i));          &#125;      &#125;        public T get(String key) &#123;          if (circle.isEmpty()) return null;            long hash = iHashService.hash(key);            // 沿环的顺时针找到一个虚拟节点        if (!circle.containsKey(hash)) &#123;              SortedMap&lt;Long, T&gt; tailMap = circle.tailMap(hash);              hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey();          &#125;          return circle.get(hash);      &#125;  &#125;\n测试类\n12345678910111213141516171819202122232425262728public class TestHashCircle &#123;      // 机器节点IP前缀    private static final String IP_PREFIX = &quot;192.168.0.&quot;;        public static void main(String[] args) &#123;          // 每台真实机器节点上保存的记录条数        Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();            // 真实机器节点, 模拟10台        List&lt;Node&lt;String&gt;&gt; nodes = new ArrayList&lt;Node&lt;String&gt;&gt;();          for (int i = 1; i &lt;= 10; i++) &#123;              map.put(IP_PREFIX + i, 0); // 初始化记录            Node&lt;String&gt; node = new Node&lt;String&gt;(IP_PREFIX + i, &quot;node&quot; + i);              nodes.add(node);          &#125;            IHashService iHashService = new HashService();          // 每台真实机器引入100个虚拟节点        ConsistentHash&lt;Node&lt;String&gt;&gt; consistentHash = new ConsistentHash&lt;Node&lt;String&gt;&gt;(iHashService, 500, nodes);            // 将5000条记录尽可能均匀的存储到10台机器节点上        for (int i = 0; i &lt; 5000; i++) &#123;              // 产生随机一个字符串当做一条记录，可以是其它更复杂的业务对象,比如随机字符串相当于对象的业务唯一标识            String data = UUID.randomUUID().toString() + i;              // 通过记录找到真实机器节点            Node&lt;String&gt; node = consistentHash.get(data);              // 再这里可以能过其它工具将记录存储真实机器节点上，比如MemoryCache等            // ...              // 每台真实机器节点上保存的记录条数加1              map.put(node.getIp(), map.get(node.getIp()) + 1);          &#125;            // 打印每台真实机器节点保存的记录条数        for (int i = 1; i &lt;= 10; i++) &#123;              System.out.println(IP_PREFIX + i + &quot;节点记录条数：&quot; + map.get(IP_PREFIX + i));          &#125;      &#125;  &#125;\n每台机器映射的虚拟节点越多，则分布的越均匀~~~ 感兴趣的同学可以拷贝上面的代码运行尝试一下。\n原文链接：\n一致性Hash原理与实现\n","plink":"https://zinki.github.io/2023/10/25/一致性Hash原理与实现/"},{"title":"一次数据库连接池优化的实践剖析","date":"2023-08-20T03:35:00.000Z","date_formatted":{"ll":"2023年8月20日","L":"2023/08/20","MM-DD":"08-20"},"updated":"2024-10-11T08:05:32.760Z","content":"问题背景：MySQL 线程数只升不降\n一段时间以来，XXX 部门开放平台 OPENXXX 系统在业务高峰频繁出现 MySQL 线程数升高的现象。升高本身不是问题，问题是随着业务高峰过去，QPS 下来后 ，MySQL 线程数却依然居高不下，这是什么原因？\n思考方向上，大家都知道，MySQL 是通过线程池来进行线程管理的，基于过往经验，上述情况很可能是线程池的配置策略不合理导致线程创建后无法及时释放，而实际上线程的利用率是很低的————这一点通过分析系统线程也可以看到，waiting 态线程占据 MySQL 总线程数的一半有余（见下图）。\n落地实践上，方向虽然是明确的，但具体是 MySQL 的哪一项策略配置不合理、又该做怎样的调整，需要做细致的调研分析才能回答。由此发起 MySQL 线程的优化治理专项。\n\n追根溯源：问题根源的分析定位\n对比业务高峰前后的 MySQL 线程，发现飙升的主要是 [MySQL Statement Cancellation Timer] ，由此引出第一阶段问题，[MySQL Statement Cancellation Timer] 线程是从哪里来的？\n一、Timer 线程生命周期\n走读代码流程，梳理得到 Timer 线程的生命周期，如下图所示（Timer 节点以及问题节点已标识）——\n\n二、生命周期详细解读\nTimer 线程创建链路\ndump 现场线程，配合线程 stack 走读 mysql connector jar 的代码。\n\n1、定位代码，java.util.TimerThread#run—— TimerThread 是 mysql-connector-java-xxx.jar 中的 Timer 的一个内部类，等待 Timer 队列中的任务以执行、调度\n\n2、顺藤摸瓜，可以追到 [MySQL Statement Cancellation Timer] 线程的生成链路\ncom.mysql.jdbc.ConnectionImpl#getCancelTimer\n\n3、查看 getCancelTimer 的上游调用 ，主要是 mysql-connector-java-xxx.jar 中的主管 sql 查询的 Statement\n\ncom.mysql.jdbc.StatementImpl#executeQuery\n\n小结\n走读 [MySQL Statement Cancellation Timer] 线程的调用链逻辑，可以抽象 3 点核心信息——\n\nTimer 线程是 mysql connection 连接维度的\n应用开启 mysql 的 queryTimeouts 且 timeoutInMillis != 0 的话，伴随每一个连接的创建，都会同步开启一个 Timer 线程，以进行超时控制\nTimer 线程便是之前通过 jstack 抓取到的 DB 异常线程 [MySQL Statement Cancellation Timer]\n\n可以推断 OPENXXX 应用必定开启了 queryTimeout。查看 mybatis-config.xml，确定在每次 DB 查询的时候，均插上了 queryTimeout——defaultStatementTimeout 设置对全局 sql 生效，包括 insert、select、update\n\nTimer 线程销毁链路\njdk 规范保证，任何线程都有自身的退出机制。查看 Statement 中 cancelTask 的执行过程，依次追溯。\n1、com.mysql.jdbc.StatementImpl.CancelTask#run——调用 Connection 进行 cancel\n![[Pasted image 20240706222430.png]]\n2、com.mysql.jdbc.ConnectionImpl#close\n\n3、com.mysql.jdbc.ConnectionImpl#realClose——关闭 Timer 线程\n\n小结\n至此获取到 [MySQL Statement Cancellation Timer] 线程的 cancel 链路，走读代码逻辑，抽象核心信息——连接关闭时，会调用 Connection.close 方法 cancel 掉 Timer 线程，即 [MySQL Statement Cancellation Timer] 线程。\n三、核心问题总结定位\n连接创建时，queryTimeout 会使 jdbc driver 新建 cancelTask 并使用 Timer 进行调度，一旦 sql 查询超时则执行 cancel 动作；连接关闭时，调用 Connection 以 cancel 掉 Timer 线程。\n问题来到第二个阶段：既然连接超时关闭的时候，才会将 Timer 线程 cancel 掉，那么控制超时的具体是哪些策略呢？\n超时策略：MySQL 线程数下降的关键\n对于选型关系型数据库的应用而言，数据库的连接关闭策略自上而下由两层组成：1、JDBC；2、Mysql，经由各层的一系列超时参数进行控制。需要注意的是，网络文档对各层各参数的释义大多不够精准，甚至相互矛盾。以下参数分析均来自官方文档，并随载官方链接以便详细查阅。\n一、JDBC 层（c3p0）\n连接超时参数\n\nmaxIdleTime：在从池中剔除连接之前，允许连接闲置多少秒\n\n有效性检测参数\n\nidleConnecnTestPeriod：定时检测池中空闲连接的周期，用以校验连接的有效性\ntestConnectionOnCheckin：连接提交时，异步校验其有效性\ntestConnectionOnCheckout：连接回收时，同步校验其有效性\npreferredTestQuery：连接的有效性校验语句。JDBC4 的连接包括一个名为 isvalid（）的方法，该方法可作为快速、可靠的连接测试来执行\n\n解读一下\n\ntestConnectionOnCheckin 是一个异步检测参数而非同步参数，connection 提交指的是 connection 连接到 mysql server 而非执行任务\n3个检测参数是搭配使用的——连接提交后，会开启连接状态的定期检测机制（testConnectionOnCheckin 为 true），即每 30 秒（idleConnectionTestPeriod=30）通过 SELECT 1（preferredTestQuery=SELECT 1）语句检测一次连接状态，从而降低 Communications link failure 的发生概率\n\n关于参数的 Q&amp;A\n设置完连接超时参数 maxIdleTime 之后，有必要设置有效性检测参数么——两者的关系是：连接空闲超过 maxIdleTime 后，就会被 mysql server 断开。但此时连接池并没有回收这个连接，直到连接池检测到该连接已被废弃后，才会进行回收。在这个时间段内，如果客户端使用了这个连接，就会报错：Communications link failure。\n\n二、DB Server 层\nwait_timeout]：mysql server 关闭连接之前，允许连接闲置多少秒。默认是 28800，单位秒，即 8 个小时\n三、超时策略探究总结\n既然 jdbc 层面以及 mysql 层面都有完备的连接关闭策略，那么问题来到第三个阶段：OPENXXX 系统自身的配置策略是怎样的？\n系统分析：OPENXXX 的超时关闭策略\n依据上文调研的连接关闭策略，摸查 OPENXXX 应用，1、JDBC；2、Mysql。\n一、JDBC 层（c3p0）\nOPENXXX 在 jdbc 层面未配置连接关闭策略（无 maxIdleTime），如此一来，只能依赖下层 mysql 的 timeout 机制进行连接的关闭。但实际上，mysql server 能否关掉连接呢？\n二、DB Server 层\n1、查询 mysql server 的 wait_timeout 参数，观察 DB 设定的连接超时配置——[select variable_name,variable_value from information_schema.session_variables where variable_name like ‘wait_timeout’]\n![[Pasted image 20240706222925.png]]\n2、查询 mysql server 的 Threads_connected 参数，观察 DB 当前打开的连接数——[show status where variable_name = ‘Threads_connected’]\n\n3、查询 DB 日常的 qps\n![[Pasted image 20240706222951.png]]\n4、汇总信息：connectionSize～800，qps～800，keepAliveTime～28800s。由此计算线程释放的概率：(qps _keepAliveTime) / connectionSize，即 800_28800/800=28800——意味着每个连接在关闭之前，有 28800 次机会拿到任务而不被终止。这种概率下，连接是不可能释放的，连接空置率也会很高。\n三、系统分析判断印证\n\n查询 DB 日常的总连接数，可以看到连接无法主动释放\n\n![[Pasted image 20240706223005.png]]\n\n查询 DB 当前所有连接的运行情况，可以看到连接空置率很高，绝大多数处于 idle 状态——[show full processlist] 查看，其中 Command 标识连接的运行状态，比如：Sleep，Query，Connect 等\n\n\n解决方案：恰当的超时关闭策略\n通过配置 jdbc 层的连接关闭策略，及时关掉空闲连接，从而确保 timer 线程的 cancle。问题来到第四个阶段：如何配置 OPENXXX 的连接关闭策略？\n一、建议方案\n实际上，官方已经给出了建议：\nThe most reliable time to test Connections is on check-out. But this is also the most costly choice from a client-performance perspective. Most applications should work quite reliably using a combination of idleConnectionTestPeriod and testConnectionOnCheckin. Both the idle test and the check-in test are performed asynchronously, which can lead to better performance, both perceived and actual.\n最可靠的连接测试时机是在 connection 回收时进行（testConnectionOnCheckout），但从系统性能的角度来看，这也是最耗费性能的选择。大多数应用程序应该组合使用 idleConnectionTestPeriod 和 testconConnectionCheckin，一方面可以保证系统非常可靠地运行，另一方面空闲测试和提交测试都是异步执行的，这会带来更好的系统性能。\nSet idleConnectionTestPeriod to 30, fire up you application and observe. This is a pretty robust setting, all Connections will tested on check-in and every 30 seconds thereafter while in the pool. Your application should experience broken or stale Connections only very rarely, and the pool should recover from a database shutdown and restart quickly\n将 idleConnectionTestPeriod 设置为 30，启动系统并观察。这是一个非常健壮的设置，所有连接都将在提交时进行测试，之后每隔 30 秒在池中进行一次测试。这样应用程序可以很少拿到断开或过时的连接，并且可以在 DB 重启之后支持连接的快速恢复。\n二、策略配置\n1234&lt;property name=&quot;preferredTestQuery&quot;&gt;SELECT 1&lt;/property&gt; &lt;!-- 有效性检测语句 --&gt;  &lt;property name=&quot;testConnectionOnCheckin&quot;&gt;true&lt;/property&gt; &lt;!-- 提交连接时校验连接的有效性。Default: false --&gt;=  &lt;property name=&quot;idleConnectionTestPeriod&quot;&gt;30&lt;/property&gt; &lt;!-- 每 30 秒检查连接池中的空闲连接。若为 0 则永不检测。Default: 0 --&gt;  &lt;property name=&quot;maxIdleTime&quot;&gt;30&lt;/property&gt; &lt;!-- 最大空闲时间，30 秒内未使用连接被丢弃。若为 0 则永不丢弃。Default: 0 --&gt;\n测试验证：超时策略的有效性验证\ntest 环境进行测试，验证配置策略的有效性，三步走：\n1、高 qps，mock db 流量，重复发起 query 请求——观察 cat 堆栈，是否生成大量的 [MySQL Statement Cancellation Timer]\n2、低 qps，mock db 流量，间隔发起 query 请求——观察 cat 堆栈，是否开始缩减 [MySQL Statement Cancellation Timer]\n3、无 qps，关闭 db 流量——观察 cat 堆栈，无 [MySQL Statement Cancellation Timer]\n一、测试代码展示\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@Controller@RequestMapping(&quot;/dbtimer&quot;)public class DBTimerController &#123;    @Resource    private PushCallbackService callbackService;    @Autowired    private MccClient mccClient;    private static final Logger LOGGER = LoggerFactory.getLogger(DBTimerController.class);    private static final ExecutorService executorService = Executors.newFixedThreadPool(50);//创建线程池    @ResponseBody    @RequestMapping(value = &quot;/dbtest&quot;, method = RequestMethod.GET)    @Ignore(&quot;工具接口,无需鉴权&quot;)    public void dbTest() &#123;        TimerQ timerQ = new TimerQ();        for (int i = 0; i &lt; 50; i++) &#123;            executorService.execute(new TimerR(timerQ));        &#125;    &#125;    @ResponseBody    @RequestMapping(value = &quot;/dbtestdown&quot;, method = RequestMethod.GET)    @Ignore(&quot;工具接口,无需鉴权&quot;)    public void dbTestDown() &#123;        executorService.shutdown();    &#125;    class TimerQ &#123;        public void queryTimer() throws InterruptedException &#123;            int i = 1;            while (Boolean.valueOf(mccClient.getValue(&quot;mcc_timer_query_switch&quot;))) &#123;                CallbackLog callbackLog = callbackService.querybyid(i);                if (callbackLog==null) &#123;                    continue;                &#125;                LOGGER.warn(&quot;query timer, callbackInfo:&#123;&#125;&quot;, callbackLog.getId());                ++i;                if (Boolean.valueOf(mccClient.getValue(&quot;mcc_timer_sleep_switch&quot;))) &#123;                    Thread.sleep(Long.valueOf(mccClient.getValue(&quot;mcc_timer_time_switch&quot;)));                &#125;            &#125;        &#125;    &#125;    class TimerR implements Runnable &#123;        private TimerQ timerQ;        public TimerR(TimerQ timerQ) &#123;            this.timerQ = timerQ;        &#125;        @Override        public void run() &#123;            try &#123;                timerQ.queryTimer();            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;  &#125;\n二、3 重场景验证\n1、初始阶段\nMySQL Statement Cancellation Timer 线程数为 0\n2、高 qps——生成大量的 [MySQL Statement Cancellation Timer]\nMySQL Statement Cancellation Timer 线程数为 50\n3、低 qps——[MySQL Statement Cancellation Timer] 开始缩减\nMySQL Statement Cancellation Timer 线程数为 35\n4、无 qps——无 [MySQL Statement Cancellation Timer]\nMySQL Statement Cancellation Timer 线程数为 0\n三、上线效果展示\n详见 OPENXXX 系统 DB 异常线程优化案——总结报告。一句话总结：DB 连接超时策略的引入，可以及时有效的关闭连接，进而关闭 [MySQL Statement Cancellation Timer]，使得 OPENXXX 系统线程表现出了良好的业务弹性，且未损失原有的 sql 性能。\n个人总结：抽象提炼优化方法\n本次问题的表象是明确的，但掩藏的内核是艰深的。历经「三方包代码（原理）— jdbc（c3p0 文档）— mysql server(manual 文档) — openXXX(分析) — 测试（验证）」，个人尽力呈现本次优化实践从调研到上线的完整过程，亦收获良多。同时在这里抽象、提炼一下，主要是个人对于 DB 线程调优的提纲式整理，方便各位同学进行参考，寻找优化思路——\n\n原文链接\n一次数据库连接池优化的实践剖析\n","plink":"https://zinki.github.io/2023/08/20/一次数据库连接池优化的实践剖析/"},{"title":"MySQL沉浸式面试","date":"2023-07-26T02:10:00.000Z","date_formatted":{"ll":"2023年7月26日","L":"2023/07/26","MM-DD":"07-26"},"updated":"2024-10-11T08:01:30.330Z","content":"今天我们来聊聊MySQL原理\n\n基础篇主要是侧重基础知识，原理篇是有一定基础后的递进，通过学习本篇，不仅可以进一步了解MySQL的各项特性，还能为接下来的容灾调优打下坚实的基础\nACID与隔离级别\n那你先来说说MySQL的四种隔离级别吧。\nSQL标准定义了4类隔离级别，包括一些具体规则，用来限定事务之间的隔离性。\n这四种级别分别是读未提交、读已提交、可重复读、串型化。\n读未提交，顾名思义，就是可以读到还没有提交的数据；读已提交会读到其它事务已经提交的数据；可重复读确保了同一事务中，读取同一条数据时，会看到同样的数据行；串型化通过强制事务排序，使其不可能相互冲突。\n重点介绍下Repeatable Read吧。\nRepeatable Read就是可重复读。它确保了在同一事务中，读取同一条数据时，会看到同样的数据行。\n它也是MyQL的默认事务隔离级别，这种级别事务之间影响很小，通常已经能够满足日常需要了。\n\n说出四种隔离级别只是最低要求，能每一项具体去阐述特性就算过关。如果还能指出存在的问题、依赖的技术，那么就是妥妥的加分了！\n下面我们来聊聊InnoDB中ACID的实现吧，先说一下原子性是怎么实现的。\n事务要么失败，要么成功，不能做一半。聪明的InnoDB，在干活儿之前，先将要做的事情记录到一个叫undo log的日志文件中，如果失败了或者主动rollback，就可以通过undo log的内容，将事务回滚。\n那undo log里面具体记录了什么信息呢？\nundo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作，使数据回到之前的状态。。。\n\n那持久性又是怎么实现的？\n持久性是用来保证一旦给客户返回成功，数据就不会消失，持久存在。最简单的做法，是每次写完磁盘落地之后，再给客户返回成功。但如果每次读写数据都需要磁盘IO，效率就会很低。\n为此，追求极致的InnoDB提供了缓冲。当向数据库写入数据时，会首先写入缓冲池，缓冲池中修改的数据会定期刷新到磁盘中，这一过程称为刷脏。\n如果MySQL宕机，那此时Buffer Pool中修改的数据不是丢失了吗？\nInnodb引入了redo log来解决这个问题。当数据修改时，会先在redo log记录这次操作，然后再修改缓冲池中的数据，当事务提交时，会调用fsync接口对redo log进行刷盘。\n如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。由于redo log是WAL日志，也就是预写式日志，所有修改先写入日志，所以保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。\n\n按你所说，redo log 也需要写磁盘，为什么不直接将数据写磁盘呢？\n嗯。。。主要是有以下两方面的原因：\n\n对Buffer Pool进行刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO；\n刷脏是以数据页为单位，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入，所以积累一些数据一并写入会大大提升性能；而redo log中只包含真正需要写入的部分，无效IO比较少。\nredo log是持久性的核心，WAL的思路也是持久化的常见解决方式，只有先落地了，才能应对后续的各种异常。\n\n那隔离性怎么实现呢？\n\nMySQL能支持Repeatable Read这种高隔离级别，主要是锁和MVCC一起努力的结果。\n我先说锁吧。事务在读取某数据的瞬间，必须先对其加行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间，必须先对其加行级排他锁，直到事务结束才释放；\n为了防止幻读，还会有间隙锁进行区间排它锁定。\n然后是MVCC，多版本并发控制，主要是为了实现可重复读，虽然锁也可以，但是为了更高性能考虑，使用了这种多版本快照的方式。\n因为是快照，所以一个事务针对同一条Sql查询语句的结果，不会受其它事务影响。\n索引原理\n索引的底层实现是什么？\n用的B+树，它是一个N叉排序树，每个节点通常有多个子节点。节点种类有普通节点和叶子节点。根节点可能是一个叶子节点， 也可能是个普通节点。\n\n那MySQL为什么用树做索引？\n一般而言，能做索引的，要么Hash，要么树，要么就是比较特殊的跳表。Hash不支持范围查询，跳表不适合这种磁盘场景，而树支持范围查询，且多种多样，很多树适合磁盘存储。所以MySQL选择了树来做索引。\n那你能说说为什么是B+树，而不是平衡二叉树、红黑树或者B-树吗？\n平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。\n同时，B+树优势在于每个节点能存储多个信息，这样深度比平衡二叉树会浅很多，减少数据查找的次数。\n\n红黑树放弃了追求完全平衡，只追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。\n但是红黑树多用于内部排序，即全放在内存中，而B+树多用于外存上时，B+也被称为一个磁盘友好的数据结构。\n同时，红黑树和平衡二叉树有相同缺点，即每个节点存储一个关键词，数据量大时，导致它们的深度很深，MySQL每次读取时都会消耗大量IO。\n\n那B+树相比B-树有什么优点呢？\n哈哈，我觉得这就属于同门师兄较劲儿了。B+树非叶子节点只存储key值，而B-树存储key值和data值，这样B+树的层级更少，查询效率更高；\nMySQL进行区间访问时，由于B+树叶子节点之间用指针相连，只需要遍历所有的叶子节点即可，而B-树则需要中序遍历一遍。\n\n这类选型问题其实很深，要深刻理解为什么要用B+树、B+树有哪些竞争对手。换句话说，也就是要了解，哪些数据结构能做索引。如果能答出哈希表、树、跳表这三大类，就说明确实有自己的深入思考，这部分知识点学透了，也是加分项。\n接下来讲讲聚簇索引和二级索引吧。\n聚簇索引是主键上的索引，二级索引是非主键字段的索引。这两者相同点是都是基于B+树实现。\n区别在于，二级索引的叶子结点只存储索引本身内容，以及主键ID，聚簇索引的叶子结点，会存储完整的行数据。在一定程度上，可以说二级索引就是主键索引的索引。\n一般来说，面试官让介绍两个名词或者概念，潜台词就是要我们说清楚两者的相同点、不同点，说清楚了就过关。如果有些自己的总结性思考，比如在上面的对话中，阿柴回答出二级索引是主键索引的索引，这样就会让面试官眼前一亮。\n\n下面讲讲MySQL锁的分类吧。\nMySQL从锁粒度粒度上讲，有表级锁、行级锁。从强度上讲，又分为意向共享锁、共享锁、意向排它锁和排它锁。\n\n锁模式的兼容情况\n那select操作会加锁吗？\n对于普通select语句，InnoDB 不会加任何锁。但是select语句，也可以显示指定加锁。有两种模式，一种是LOCK IN SHARE MODE是加共享锁，还有Select … for updates是加排它锁。\n什么情况下会发生死锁？\n嗯。。。比如事务A锁住了资源1，然后去申请资源2，但事务B已经占据了资源2，需要资源1，谁都不退让，就死锁了。对于MySQL，最常见的情况，就是资源1、资源2分别对应一个排它锁。\n\n那间隙锁你有了解么？\n间隙锁就是对索引行进行加锁操作，不仅锁住其本身，还会锁住周围邻近的范围区间。间隙锁的目的是为了解决幻影读，但也因此带来了更大的死锁隐患。\n比如，一个任务表里面有个状态字段，是一个非唯一索引，有一个任务id，是唯一索引。\n一个sql将状态处于执行中的任务设置为等待中，另一个sql正好通过任务id更新在范围内的一条任务信息。那么因为是在不同索引加锁的，所以都能成功。但是最后去更新主键数据的时候，就会死锁\n\n原文链接：\n【面试官来袭】第三弹之MySQL原理篇\n","plink":"https://zinki.github.io/2023/07/26/MySQL沉浸式面试/"},{"title":"Luhn算法使用","date":"2022-02-21T11:30:00.000Z","date_formatted":{"ll":"2022年2月21日","L":"2022/02/21","MM-DD":"02-21"},"updated":"2024-10-10T08:03:05.450Z","content":"银行卡号码的校验采用Luhn算法，校验过程大致如下：\n\n\n从右到左给卡号字符串编号，最右边第一位是1，最右边第二位是2，最右边第三位是3….\n\n\n从右向左遍历，对每一位字符t执行第三个步骤，并将每一位的计算结果相加得到一个数s。\n\n\n对每一位的计算规则：如果这一位是奇数位，则返回t本身，如果是偶数位，则先将t乘以2得到一个数n，如果n是一位数（小于10），直接返回n，否则将n的个位数和十位数相加返回。\n\n\n如果s能够整除10，则此号码有效，否则号码无效。\n\n\n因为最终的结果会对10取余来判断是否能够整除10，所以又叫做模10算法。\n1234567891011121314public static Boolean validCheckNum(String cardNo)&#123;    int sum = 0;    for (int i = 1; i &lt;= cardNo.length(); i++) &#123;        int unit = cardNo.charAt(i-1) - &#x27;0&#x27;;        if ((i &amp; 1) == 0) &#123;            unit = unit * 2;            if (unit &gt; 9) &#123;                unit = unit / 10 + unit % 10;            &#125;        &#125;        sum += unit;    &#125;    return sum % 10 == 0 ? Boolean.TRUE : Boolean.FALSE;&#125;\n计算校验码\n1234567891011121314int sum = 0;for (int i = 0; i &lt; cardNo.length(); i++) &#123;    int unit = cardNo.charAt(cardNo.length()-1 - i) - &#x27;0&#x27;;    if ((i &amp; 1) == 0) &#123;        if (unit &lt; 5) &#123;            sum += unit * 2;        &#125; else &#123;            sum += unit * 2 - 9;        &#125;    &#125; else &#123;        sum += unit;    &#125;&#125;int remainder = sum % 10;\n参考\n银行卡号码的校验规则(Luhn算法/模10算法) - CodeAntenna\n","plink":"https://zinki.github.io/2022/02/21/Luhn算法使用/"},{"title":"循环链表实践","date":"2022-01-20T03:35:00.000Z","date_formatted":{"ll":"2022年1月20日","L":"2022/01/20","MM-DD":"01-20"},"updated":"2024-10-11T02:21:23.248Z","content":"工作中涉及到针对证件号做软加密需求，要求是密文必须唯一，开始是通过数据库去重来实现，每次都要去数据库查询是否存在，存在的话重新生成，直到生成可用密文，这样有性能瓶颈。\n需要更换密文生成方式，后采用根据字符映射的方式，鉴于过于简单，所以添加偏移量增加复杂度。经过评估，双向循环链表很适合这种场景。\n节点信息\njava\n/**\n* 源数据\n/\npublic Character sourceData;\n/*\n* 目标数据\n/\npublic Character targetData;\n/*\n* 上一个节点\n/\npublic Node previous;\n/*\n* 下一个节点\n*/\npu\nblic Node next;\n\n添加节点\n/**\n * 添加元素\n * @param sourceData\n * @param targetData\n * @return\n */\npublic Node add(Character sourceData,Character targetData)&#123;\n    Node newNode = new Node(sourceData,targetData);\n    if(size == 0)&#123;\n        head = newNode;\n        head.next = head;\n        head.previous = head;\n    &#125;else&#123;\n        Node target = head;\n        while(target.next!=head)&#123;\n            target = target.next;\n        &#125;\n        target.next = newNode;\n        newNode.previous = target;\n        newNode.next = head;\n        head.previous = newNode;\n    &#125;\n    size++;\n    return newNode;\n&#125;\n\n12345678910111213141516171819202122232425262728293031323334353637### 定位节点```java    /**     * 返回指定元素     * @return     */    public Node findSourceNode(Character obj,int offset)&#123;        Node target = head;        while(target.next!=null)&#123;            if(obj.equals(target.sourceData))&#123;                return getNext(target,offset);            &#125;else&#123;                target = target.next;            &#125;        &#125;        return null;    &#125;    /**     * 返回指定元素     * @return     */    public Node findTargetNode(Character obj,int offset)&#123;        Node target = head;        while(target.next!=null)&#123;            if(obj.equals(target.targetData))&#123;                return getPrevious(target,offset);            &#125;else&#123;                target = target.next;            &#125;        &#125;        return null;    &#125;\n经过测试完全满足加解密需求\n参考\n数据结构Java实现：循环链表和双向链表 - 云+社区 - 腾讯云\n","plink":"https://zinki.github.io/2022/01/20/循环链表实践/"},{"title":"Markdown图片解析","date":"2022-01-11T11:00:00.000Z","date_formatted":{"ll":"2022年1月11日","L":"2022/01/11","MM-DD":"01-11"},"updated":"2024-10-10T08:03:05.451Z","content":"最近想对图床做个备份，刚好再看Python，遂参考网上代码写了解析Markdown文件并下载图片的Python脚本。\n大致分为3部分：\n\n读取目录下所有Markdown文件\n\n12345678910111213141516171819202122def find_sub_path(path):    # 初始化一个空的文章列表    article_list = []    if os.path.isfile(path):        article_list.append(path)    else:        # 获取该文件夹下的所以子文件        temp_files = os.listdir(path)        # 遍历子文件        for temp_file in temp_files:            # 拼接该文件绝对路径            full_path = os.path.join(path, temp_file)            # 匹配.md文件            if os.path.isfile(full_path) and os.path.splitext(full_path)[1] == &quot;.md&quot;:                # 如果是.md文件 加入文章列表                article_list.append(full_path)            # 如果是文件夹 进行递归继续搜索            elif os.path.isdir(full_path):                # 将子文件夹中的文章列表拼接到上级目录的文章列表中                article_list.extend(find_sub_path(full_path))    return article_list\n\n解析Markdown文本并获取图片链接\n\n12345678910111213141516171819# 查找图片def find_pics(article_path):    # 打开md文件    f = open(article_path, &#x27;rb&#x27;)    content = f.read().decode(&#x27;UTF-8&#x27;)    pics = []    # 匹配正则 match ![]()    results = re.findall(r&quot;!\\[(.+?)\\)&quot;, content)    for result in results:        temp_pic = result.split(&quot;](&quot;)        # 将图片加入到图片数组当中        if len(temp_pic) == 2:            basename = os.path.basename(article_path)            pic = picture.image(basename, temp_pic[1])            pics.append(pic)    f.close()    return pics\n\n\n下载图片到指定目录\n1234567891011def download(self):    sub_path = directory.find_sub_path(self.name_entry.get())    if len(sub_path) &gt; 0:        index = 0        for path in sub_path:            pics = article.find_pics(path)            if len(pics) &gt; 0:                picture.start_download_pic(self.path_entry.get(), pics)            index = index + 1            per = index / len(sub_path) * 100            self.increment(round(per))\n\n\n后面还用内置的tk，做了输入弹窗并显示处理进度条，详细代码参考：parse markdown file\n参考\n实现 Markdown 图片下载器 - 掘金\n","plink":"https://zinki.github.io/2022/01/11/Markdown图片解析/"},{"title":"X509证书解析","date":"2021-12-21T03:00:00.000Z","date_formatted":{"ll":"2021年12月21日","L":"2021/12/21","MM-DD":"12-21"},"updated":"2024-10-10T08:03:05.461Z","content":"X.509是密码学里公钥证书的格式标准。X.509证书已应用在包括TLS/SSL在内的众多网络协议里，同时它也用在很多非在线应用场景里，比如电子签名服务。X.509证书里含有公钥、身份信息（比如网络主机名，组织的名称或个体名称等）和签名信息（可以是证书签发机构CA的签名，也可以是自签名）\nX.509证书结构描述\n证书的结构如下所示：\n123456789101112131415161718CertificateVersionSerial NumberAlgorithm IDIssuer (CA’s name)ValidityNot BeforeNot AfterSubjectSubject Public Key InfoPublic Key AlgorithmSubject Public KeyIssuer Unique Identifier (Optional)Subject Unique Identifier (Optional)Extensions (Optional)Certificate Signature AlgorithmCertificate Signature\n解释：\nVersion 版本号：标识证书的版本（版本1、版本2或是版本3）。\nSerial Number 序列号：标识证书的唯一整数，由证书颁发者分配的本证书的唯一标识符。\nAlgorithm ID：算法ID: 标识证书算法\nIssuer (CA’s name) 颁发者：证书颁发者的可识别名（DN）。\nValidity 有效期：证书有效期的时间段。本字段由”Not Before”和”Not After”两项组成，它们分别由UTC时间或一般的时间表示。\nSubject 主体：证书拥有者的可识别名，这个字段必须是非空的，除非你在证书扩展中有别名。\nSubject Public Key Info 主体公钥信息： 主体的公钥（以及算法标识符）。\nIssuer Unique Identifier (Optional) 颁发者唯一标识符：标识符—证书颁发者的唯一标识符，仅在版本2和版本3中有要求，属于可选项。\nSubject Unique Identifier (Optional) 主体唯一标识符：证书拥有者的唯一标识符，仅在版本2和版本3中有要求，属于可选项。\nExtensions (Optional) X.509证书扩展部分\nCertificate Signature Algorithm 签名认证算法\nCertificate Signature 认证签名\n证书解析\n123456789101112import sun.security.x509.X500Name;import java.io.ByteArrayInputStream;import java.security.cert.CertificateFactory;import java.security.cert.X509Certificate;import org.apache.commons.net.util.Base64;byte[] bCertData = Base64.decodeBase64(certData);CertificateFactory certificateFactory = CertificateFactory.getInstance(&quot;X.509&quot;, new BouncyCastleProvider());X509Certificate certificate = (X509Certificate)certificateFactory.generateCertificate(new ByteArrayInputStream(bCertData));X500Name x500Name = X500Name.asX500Name(certificate.getIssuerX500Principal());Date effectedDate = certificate.getNotBefore();Date expireDate = certificate.getNotAfter();\n证书序列\n证书的签发者和证书主体用X.509 DN表示，DN是由RDN构成的序列。\n\n\n属性类型名称\n含义\n简写\n\n\n\n\nCommon Name\n通用名称\nCN\n\n\nOrganizational Unit name\n机构单位名称\nOU\n\n\nOrganization name\n机构名\nO\n\n\nLocality\n地理位置\nL\n\n\nState or province name\n州/省名\nS\n\n\nCountry\n国名\nC\n\n\n参考\nX.509 维基百科\nX.509证书的读取与解释\n","plink":"https://zinki.github.io/2021/12/21/X509证书解析/"},{"title":"负载相关知识","date":"2021-11-19T09:20:00.000Z","date_formatted":{"ll":"2021年11月19日","L":"2021/11/19","MM-DD":"11-19"},"updated":"2024-10-10T08:03:05.477Z","content":"负载这一块的知识有些乱, 听人家常说软负载、硬负载，四层负载，七层负载、客户端负载,服务端负载之类的,所以梳理一下。\n负载均衡在系统架构中是一个非常重要,通过负载均衡可以提高系统的高可用，缓解网络、硬件资源的限制。\n\n\n软负载\n客户端负载\nSpring Cloud Ribbon\n\n\n\n\n\n\n\n服务端负载\nNgixn (4-7)层负载\nHyproxy (4-7)层负载\nkube-proxy (4-7)层负载\n\n\n\n\nLVS(4)层负载\n\n\n\n\n硬负载\nF5\n\n\n\n\n\n软负载\n处理传输层到应用层的数据，为了能通一个URL或者IP+PORT将前端的访问分发到后台的多个服务器上\n\n客户端负载\n\nDev 即开发角度的负载均衡。开发中的负载均衡一般是在微服务中涉及。服务提供方一般以多实例的形式提供服务，负载均衡功能能够让服务调用方连接到合适的服务节点。 并且，服务节点选择的过程对服务调用方来说是透明的\n\n\n服务端负载\nOps 即运维角度的负载均衡,这里的负载我们也称为服务端负载\n所谓服务端负载均衡,比如传统的Nginx的方式，调用的客户端并不知道具体是哪个服务提供的服务,它也不关心,反正请求发送给Nginx, 或者hyproxy作为代理的服务器，然后 Ngixn 在请求负载任意服务,客户端只需要记着Nginx的地址即可。\n\n\nNginx负载\n\n\n七层(应用层)负载\nNginx 7层负载是最常见的一种负载,所谓7层负载，即应用层负载，即基于应用层协议(TELNET,SSH,HTTP,SMTP,POP…)做的代理，7层负载需要解析数据包的具体内容，需要消耗额外的cpu，然后根据具体内容(url, 参数, cookie, 请求头)匹配相应的路径，然后转发到相应的服务器。转发的过程是：建立和目标机器的连接，然后转发请求，收到响应数据再转发给请求客户端。\n\n\n四层(传输层)负载\n所谓四层负载，即在传输层协议的基础上来做负载，基于TCP,UDP等协议，传输层的作用是确保数据被可靠的传输送到目标地址，能够让应用程序之间实现通信，所以彼此传递的是数据包，标识的只有IP+端口。不涉及具体的url其他结构解析。路径匹配等，不会涉及具体的应用层协议，所以理论上四层负载要比七成负载快。\nnginx 四层代理是nginx1.9.0开始新增的功能，需要开启–with-stream模块，可以实现四层协议的转发、代理、负载等功能\n\n\n\n\nHAProxy负载\nHAProxy 是一款提供高可用性、负载均衡以及基于TCP（第四层）和HTTP（第七层）应用的代理软件，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。\nHAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy完全可以支持数以万计的并发连接。\n\n\n\n\n参考\n关于开发部署中(4层/7层/C端/S端)软负载均衡笔记\n","plink":"https://zinki.github.io/2021/11/19/负载相关知识/"},{"title":"Markdown常用语法","date":"2021-10-25T11:40:00.000Z","date_formatted":{"ll":"2021年10月25日","L":"2021/10/25","MM-DD":"10-25"},"updated":"2024-10-10T08:03:05.451Z","content":"Markdown 是一种纯文本格式的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。\n基本语法\n如果你只想高亮语句中的某个函数名或关键字，可以使用反引号 function_name() 实现。\n通常编辑器根据代码片段适配合适的高亮方法，但你也可以用 ```包裹一段代码，并指定一种语言，示例:\n1234```javascript$(document).ready(function () &#123;    alert(&#x27;hello world&#x27;);&#125;);\n也可以使用 4 空格缩进，再贴上代码，实现相同的的效果：\n123····def g(x):····    yield from range(x, 0, -1)····yield from range(x)\n如你不需要代码高亮，可以用下面的方法禁用：\n12```nohighlight// 代码内容\n标题\n文章内容较多时，可以用标题分段：\n12345## 大标题### 中标题#### 小标题\n粗体、斜体\n123**粗体文本***斜体文本****粗斜体文本***\n链接\n常用链接：\n12文字链接 [SegmentFault](https://segmentfault.com)网址链接 &lt;https://segmentfault.com&gt;\n高级链接：\n12345这个链接用 1 作为网址变量 [Google][1]这个链接用 yahoo 作为网址变量 [Yahoo][yahoo]然后在文档的结尾为变量赋值（网址）[1]: http://www.google.com[yahoo]: http://www.yahoo.com\n列表\n无序列表\n123* 列表文本前使用 `减号 + 空格`+ 列表文本前使用 `加号 + 空格`- 列表文本前使用 `星号 + 空格`\n有序列表\n1231. 列表前使用 `数字 + . + 空格`2. 我们会自动帮你添加数字7. 不用担心数字不对，显示的时候我们会自动把这行的 7 纠正为 3\n列表嵌套\n1234567891011121314151617181920212223241. 列出所有元素：···- 无序列表元素 A······1. 元素 A 的有序子列表······2. 元素 A 的有序子列表···- 前面加三个空格2. 列表里的多段换行：···新的一个段落···这样换行，整体的格式不会乱3. 列表里引用：···&gt; 引用内容···&gt; 引用内容4. 列表里代码段：···```···前面三个空格，之后用三个反引号形成代码块···```·······或者直接空七个，引入代码块\n引用\n普通引用\n12&gt; 引用文本前使用 `大于号 + 空格`&gt; 折行可以不加，新起一行都要加上哦\n嵌套引用\n123&gt; 最外层引用&gt; &gt; 第二层引用&gt; &gt; &gt; 可以嵌套很多层\n引用里嵌套列表\n1234&gt; - 这是引用里嵌套的一个列表&gt; - 还可以有子列表&gt; ··- 子列表&gt; ··- 子列表\n引用里嵌套代码块\n1&gt; ····同样的，在前面加四个空格形成代码块\n图片\n跟链接的方法区别在于前面加了个感叹号 !，这样是不是觉得好记多了呢？\n1![图片名称](http://图片网址)\n当然，你也可以像网址那样对图片网址使用变量\n123这个链接用 1 作为网址变量 `[Google][1]`.然后在文档的结尾位变量赋值（网址）[1]: http://www.google.com/logo.png\n换行\n如果另起一行，只需在当前行结尾加 2 个空格：\n12在当前行的结尾加 2 个空格··这行就会新起一行\n如果是要起一个新段落，只需要空出一行即可。\n分隔符\n如果你有写分割线的习惯，可以新起一行输入三个减号 -。当前后都有段落时，请空出一行：\n12345前面的段落---后面的段落\n高级技巧\n行内 HTML 元素\n目前只支持部分段内 HTML 元素效果，包括 &lt;kdb&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sup&gt; &lt;sub&gt; &lt;br&gt;：\n键位显示\n1使用 &lt;kbd&gt;Enter&lt;/kbd&gt; 键换行\n代码块\n1使用 &lt;pre&gt;&lt;/pre&gt; 元素同样可以形成代码块\n粗斜体\n1&lt;b&gt;Markdown 在此处同样适用，如 **加粗**&lt;/b&gt;\n符号转义\n如果你的描述中需要用到 markdown 的符号，比如 _、#、* 等，但又不想它被转义，这时候可以在这些符号前加反斜杠，如 \\_、\\#、\\* 进行避免。\n12\\*不想这里的文本变斜体\\*\\*\\*不想这里的文本被加粗\\*\\*\n扩展\n支持 jsfiddle、gist、codepen，直接填写 URL，在其之后会自动添加预览点击会展开相关内容：\n123https://jsfiddle.net/&#123;&#123; name &#125;&#125;/&#123;&#123; id &#125;&#125;/https://gist.github.com/&#123;&#123; name &#125;&#125;/&#123;&#123; id &#125;&#125;https://codepen.io/&#123;&#123; name &#125;&#125;/pen/&#123;&#123; id &#125;&#125;\n脚注\n1234Markdown[^1] 可以提高排版效率，并将文本转换为 HTML[^html][^1]: Markdown 是一种纯文本标记语言[^html]: HyperText Markup Language 超文本标记语言\n公式\n当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。如：\n12345$$ E=mc^2 $$$$E=mc^2$$\n如果要使用行内公式，可以在公式前后用 \\( 和 \\) 包裹实现：\n1\\\\( E=mc^2 \\\\)\n参考\nMarkdown 语法指南\nMarkdown 教程\n","plink":"https://zinki.github.io/2021/10/25/Markdown常用语法/"},{"title":"PowerMock基础教程","date":"2021-09-15T11:20:00.000Z","date_formatted":{"ll":"2021年9月15日","L":"2021/09/15","MM-DD":"09-15"},"updated":"2024-10-10T08:03:05.457Z","content":"Mockito与PowerMock都是Java流行的一种Mock框架，使用Mock技术能让我们隔离外部依赖以便对我们自己的业务逻辑代码进行单元测试，在编写单元测试时，不需要再进行繁琐的初始化工作，在需要调用某一个接口时，直接模拟一个假方法，并任意指定方法的返回值。\n原理\nMockito的工作原理是通过创建依赖对象的proxy，所有的调用先经过proxy对象，proxy对象拦截了所有的请求再根据预设的返回值进行处理。PowerMock则在Mockito原有的基础上做了扩展，通过修改类字节码并使用自定义ClassLoader加载运行的方式来实现mock静态方法、final方法、private方法、系统类的功能。   从两者的项目结构中就可以看出，PowerMock直接依赖于Mockito，所以如果项目中已经导入了PowerMock包就不需要再单独导入Mockito包，如果两者同时导入还要小心PowerMock和Mockito不同版本之间的兼容问题：\n\n\nMockito包依赖：\n123456&lt;dependency&gt;     &lt;groupId&gt;org.mockito&lt;/groupId&gt;     &lt;artifactId&gt;mockito-core&lt;/artifactId&gt;     &lt;version&gt;2.23.0&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n\nPowerMock包依赖：\n123456789101112&lt;dependency&gt;     &lt;groupId&gt;org.powermock&lt;/groupId&gt;     &lt;artifactId&gt;powermock-module-junit4&lt;/artifactId&gt;     &lt;version&gt;2.0.0-RC.3&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;     &lt;groupId&gt;org.powermock&lt;/groupId&gt;     &lt;artifactId&gt;powermock-api-mockito2&lt;/artifactId&gt;     &lt;version&gt;2.0.0-RC.3&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;\n\n\nMockito的使用\nMockito一般通过创建mock或spy对象，并制定具体返回规则来实现模拟的功能，在调用完成后还可以进行方法调用验证以检验程序逻辑是否正确。mock和spy对象的区别是mock对象对于未指定处理规则的调用会按方法返回值类型返回该类型的默认值（如int、long则返回0，boolean则返回false，对象则返回null，void则什么都不做），而spy对象在未指定处理规则时则会直接调用真实方法。\n以下3个类是我们的项目中需要用到的一些业务类：\n1234567891011121314151617181920212223242526272829303132//实体类public class Node &#123;    private int num;    private String name;    //以下忽略所有构造方法和get、set方法&#125;//本地负责实现具体业务的业务类public class LocalServiceImpl implements ILocalService &#123;    //外部依赖    @Autowired    private IRemoteService remoteService;    //具体业务处理方法    @Override    public Node getRemoteNode(int num) &#123;        return remoteService.getRemoteNode(num);    &#125;    //以下忽略其他业务调用方法，在后面例子中补充&#125;//外部依赖业务类，由其他人实现，可能我们的业务类写好了别人还没写好public class RemoteServiceImpl implements IRemoteService &#123;    //外部类提供的一些业务方法    @Override    public Node getRemoteNode(int num) &#123;        return new Node(num, &quot;Node from remote service&quot;);    &#125;    //其他业务方法在后面例子中补充&#125;\n下面是Mockito具体使用的一些示例：\n\n\nmock外部依赖对象，并注入到我们的业务类中，以便在单元测试中进行模拟调用：\n12345678910111213141516171819202122232425262728293031323334@RunWith(MockitoJUnitRunner.class) //让测试运行于Mockito环境public class LocalServiceImplMockTest &#123; @InjectMocks    //此注解表示这个对象需要被注入mock对象 private LocalServiceImpl localService; @Mock   //此注解会自动创建1个mock对象并注入到@InjectMocks对象中 private RemoteServiceImpl remoteService; //如果不使用上述注解，可以使用@Before方法来手动进行mock对象的创建和注入，但会几行很多代码 /* private LocalServiceImpl localService; private RemoteServiceImpl remoteService; @Before public void setUp() throws Exception &#123;     localService = new LocalServiceImpl();     remoteService = Mockito.mock(RemoteServiceImpl.class);  //创建Mock对象     Whitebox.setInternalState(localService, &quot;remoteService&quot;, remoteService); //注入依赖对象 &#125; */ @Test public void testMock() &#123;     Node target = new Node(1, &quot;target&quot;);    //创建一个Node对象作为返回值     Mockito.when(remoteService.getRemoteNode(1)).thenReturn(target); //指定当remoteService.getRemoteNode(int)方法传入参数为1时返回target对象     Node result = localService.getRemoteNode(1);    //调用我们的业务方法，业务方法内部调用依赖对象方法     assertEquals(target, result);   //可以断言我们得到的返回值其实就是target对象     assertEquals(1, result.getNum());   //具体属性和我们指定的返回值相同     assertEquals(&quot;target&quot;, result.getName());   //具体属性和我们指定的返回值相同     Node result2 = localService.getRemoteNode(2);   //未指定参数为2时对应的返回规则     assertNull(result2);    //未指定时返回为null &#125;&#125;\n\n\nspy外部依赖对象，并注入到我们的业务类中：\n123456789101112131415161718192021222324252627@RunWith(MockitoJUnitRunner.class)public class LocalServiceImplSpyTest &#123; @InjectMocks private LocalServiceImpl localService; @Spy    //注意这里使用的是@Spy注解 private RemoteServiceImpl remoteService; //注意如果自己创建spy对象的话要这么写： /*     remoteService = new RemoteServiceImpl();    //先创建一个具体实例     remoteService = Mockito.spy(remoteService);   //再调用Mockito.spy(T)方法创建spy对象 */ @Test public void testSpy() &#123;     Node target = new Node(1, &quot;target&quot;);    //创建一个Node对象作为返回值     Mockito.when(remoteService.getRemoteNode(1)).thenReturn(target); //指定当remoteService.getRemoteNode(int)方法传入参数为1时返回target对象     Node result = localService.getRemoteNode(1);    //调用我们的业务方法，业务方法内部调用依赖对象方法     assertEquals(target, result);   //可以断言我们得到的返回值其实就是target对象     assertEquals(1, result.getNum());   //具体属性和我们指定的返回值相同     assertEquals(&quot;target&quot;, result.getName());   //具体属性和我们指定的返回值相同     Node result2 = localService.getRemoteNode(2);   //未指定参数为2时的调用规则，所以会直接调用真实对象，返回remote创建的节点     assertEquals(2, result2.getNum());     assertEquals(&quot;Node from remote service&quot;, result2.getName());    //remoteService创建Node对象时设置name属性为&quot;Node from remote service&quot; &#125;&#125;\n\n\n使用ArgumentMatchers的any系列方法指定多种返回值，有any()、anyInt()、anyString()、anyByte()、anyLong()等等，可以看下ArgumentMatchers类源码中定义的所有方法：\n12345678910@Test public void testAny() &#123;     Node target = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(anyInt())).thenReturn(target); //静态导入Mockito.when和ArgumentMatchers.anyInt后可以简化代码提升可读性     Node result = localService.getRemoteNode(20); //上面指定了调用remoteService.getRemoteNode(int)时，不管传入什么参数都会返回target对象     assertEquals(target, result);   //可以断言我们得到的返回值其实就是target对象     assertEquals(1, result.getNum());   //具体属性和我们指定的返回值相同     assertEquals(&quot;target&quot;, result.getName());   //具体属性和我们指定的返回值相同 &#125;\n\n\n指定mock对象多次调用的返回值：\n123456789101112131415161718/**  * 指定mock多次调用返回值  */ @Test public void testMultipleReturn() &#123;     Node target1 = new Node(1, &quot;target&quot;);     Node target2 = new Node(1, &quot;target&quot;);     Node target3 = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(anyInt())).thenReturn(target1).thenReturn(target2).thenReturn(target3);     //第一次调用返回target1、第二次返回target2、第三次返回target3     Node result1 = localService.getRemoteNode(1); //第1次调用     assertEquals(target1, result1);     Node result2 = localService.getRemoteNode(2); //第2次调用     assertEquals(target2, result2);     Node result3 = localService.getRemoteNode(3); //第3次调用     assertEquals(target3, result3); &#125;\n\n\n指定mock对象抛出异常（注意如果方法中未声明会抛出异常，只能指定抛出运行时异常，如果仍指定为抛出受检查异常，运行时会报错误org.mockito.exceptions.base.MockitoException: Checked exception is invalid for this method!）：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071//RemoteServiceImpl方法： @Override public Node getRemoteNode(String name) throws MockException &#123;     if (StringUtils.isEmpty(name)) &#123;         throw new MockException(&quot;name不能为空&quot;, name);     &#125;     return new Node(name); &#125; //LocalServiceImpl方法 @Override public Node getRemoteNode(String name) throws MockException &#123;     try &#123;         return remoteService.getRemoteNode(name);     &#125; catch (IllegalArgumentException e) &#123;         throw e;     &#125; &#125; /**  * 指定mock对象已声明异常抛出的方法抛出受检查异常  */ @Test public void testExceptionDeclare() &#123;     try &#123;         Node target = new Node(1, &quot;target&quot;);         when(remoteService.getRemoteNode(&quot;name&quot;)).thenReturn(target).thenThrow(new MockException(                 &quot;message&quot;, &quot;exception&quot;)); //第一次调用正常返回，第二次则抛出一个Exception         Node result1 = localService.getRemoteNode(&quot;name&quot;);         assertEquals(target, result1); //第一次调用正常返回         Node result2 = localService.getRemoteNode(&quot;name&quot;); //第二次调用不会正常返回，会抛出异常         assertEquals(target, result2);     &#125; catch (MockException e) &#123;         assertEquals(&quot;exception&quot;, e.getName()); //验证是否返回指定异常内容         assertEquals(&quot;message&quot;, e.getMessage()); //验证是否返回指定异常内容     &#125; &#125; /**  * 指定mock对象为声明异常抛出的方法抛出运行时异常  */ @Test public void testRuntimeException() &#123;     Node target = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(1)).thenThrow(new RuntimeException(&quot;exception&quot;)); //指定调用时抛出一个运行时异常     try &#123;         Node result = localService.getRemoteNode(1);         assertEquals(target, result);     &#125; catch (RuntimeException e) &#123;         assertEquals(&quot;exception&quot;, e.getMessage());     &#125; &#125; /**  * 指定mock对象未声明异常抛出的方法抛出受检查异常，以下方法执行会报错  */ @Test public void testNotDefineCheckedException() &#123;     Node target = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(1)).thenThrow(new IOException(&quot;io exception&quot;));     try &#123;         Node result = localService.getRemoteNode(1);         assertEquals(target, result);     &#125; catch (Exception e) &#123;         assertEquals(&quot;io exception&quot;, e.getMessage());     &#125; &#125;\n\n\nmock void方法抛异常、什么都不做：\n123456789101112131415//RemoteServiceImpl方法： @Override public void doSometing() &#123;     System.out.println(&quot;remote service do something!&quot;); &#125; //LocalServiceImpl方法 @Override public void remoteDoSomething() &#123;     remoteService.doSometing(); &#125; //注意void方法没有返回值，所以mock规则写法顺序不一样 doNothing().when(remoteService).doSometing(); doThrow(new RuntimeException(&quot;exception&quot;)).when(remoteService).doSometing();\n\n\n校验mock对象的调用情况（除Mockito中的never()、times(int)方法外，还有atLeast(int)、atLeastOne()、atMost(int)等方法）：\n1234567891011121314151617/**  * 校验mock对象和方法的调用情况  *  */ public void testVerify() &#123;     Node target = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(anyInt())).thenReturn(target);     verify(remoteService, never()).getRemoteNode(1); //mock方法未调用过     localService.getRemoteNode(1);     Mockito.verify(remoteService, times(1)).getRemoteNode(anyInt()); //目前mock方法调用过1次     localService.getRemoteNode(2);     verify(remoteService, times(2)).getRemoteNode(anyInt()); //目前mock方法调用过2次     verify(remoteService, times(1)).getRemoteNode(2); //目前mock方法参数为2只调用过1次 &#125;\n\n\n利用ArgumentCaptor捕获方法参数进行mock方法参数校验\n1234567891011121314151617/**  * 利用ArgumentCaptor捕获方法参数进行mock方法参数校验  */ @Test public void testCaptor() throws Exception &#123;     Node target = new Node(1, &quot;target&quot;);     when(remoteService.getRemoteNode(anyString())).thenReturn(target);     localService.getRemoteNode(&quot;name1&quot;);     localService.getRemoteNode(&quot;name2&quot;);     verify(remoteService, atLeastOnce()).getRemoteNode(localCaptor.capture()); //设置captor     assertEquals(&quot;name2&quot;, localCaptor.getValue()); //获取最后一次调用的参数     List&lt;String&gt; list = localCaptor.getAllValues(); //按顺序获取所有传入的参数     assertEquals(&quot;name1&quot;, list.get(0));     assertEquals(&quot;name2&quot;, list.get(1)); &#125;\n\n\nmock对象调用真实方法：\n1234567891011/**  * mock对象调用真实方法  */ @Test public void testCallRealMethod() &#123;     when(remoteService.getRemoteNode(anyInt())).thenCallRealMethod(); //设置调用真实方法     Node result = localService.getRemoteNode(1);     assertEquals(1, result.getNum());     assertEquals(&quot;Node from remote service&quot;, result.getName()); &#125;\n\n\n重置mock对象：\n12//重置mock，清除所有的调用记录和返回规则Mockito.reset(remoteService);\n\n\n校验mock对象0调用和未被验证的调用\n1234567891011121314151617181920212223/** * 校验mock对象0调用和未被验证的调用 */@Test(expected = NoInteractionsWanted.class)public void testInteraction() &#123;    verifyZeroInteractions(remoteService); //目前还未被调用过，执行不报错    Node target = new Node(1, &quot;target&quot;);    when(remoteService.getRemoteNode(anyInt())).thenReturn(target);    localService.getRemoteNode(1);    localService.getRemoteNode(2);    verify(remoteService, times(2)).getRemoteNode(anyInt());    // 参数1和2的两次调用都会被上面的anyInt()校验到，所以没有未被校验的调用了    verifyNoMoreInteractions(remoteService);    reset(remoteService);    localService.getRemoteNode(1);    localService.getRemoteNode(2);    verify(remoteService, times(1)).getRemoteNode(1);    // 参数2的调用不会被上面的校验到，所以执行会抛异常    verifyNoMoreInteractions(remoteService);&#125;\n\n\nPowerMock的使用\nPowerMock的使用与Mockito有一些不同，首先是测试类上的@RunWith注解需要修改为：\n@RunWith(PowerMockRunner.class)\n第二是需要使用到@PrepareForTest注解（PrepareFotTest注解会修改传入参数类的字节码，通过修改字节码达到模拟final、static、私有方法、系统类等的功能），此注解可写在类上也可写在方法上：\n@PrepareForTest(RemoteServiceImpl.class)\n\n\nmock new关键字\n1234567891011121314151617181920212223242526//LocalServiceImpl @Override public Node getLocalNode(int num, String name) &#123;     return new Node(num, name); &#125; /**  * mock new关键字  */ @Test @PrepareForTest(LocalServiceImpl.class) //PrepareForTest修改local类的字节码以覆盖new的功能 public void testNew() throws Exception &#123;     Node target = new Node(1, &quot;target&quot;);     //当传入任意int且name属性为&quot;name&quot;时，new对象返回为target     //当参数条件使用了any系列方法时，剩余的参数都得使用相应的模糊匹配规则，如eq(&quot;name&quot;)代表参数等于&quot;name&quot;     //剩余还有isNull(), isNotNull(), isA()等方法     PowerMockito.whenNew(Node.class).withArguments(anyInt(), eq(&quot;name&quot;)).thenReturn(target);     Node result = localService.getLocalNode(2, &quot;name&quot;);     assertEquals(target, result); //返回值为target     assertEquals(1, result.getNum());     assertEquals(&quot;target&quot;, result.getName());     //未指定name为&quot;test&quot;的返回值，默认返回null     Node result2 = localService.getLocalNode(1, &quot;test&quot;);     assertNull(result2); &#125;\n\n\nmock final方法\n1234567891011121314151617181920//RemoteServiceImpl @Override public final Node getFinalNode() &#123;     return new Node(1, &quot;final node&quot;); &#125; /**  * mock final方法  */ @Test @PrepareForTest(RemoteServiceImpl.class) //final方法在RemoteServiceImpl类中 public void testFinal() &#123;     Node target = new Node(2, &quot;mock&quot;);     PowerMockito.when(remoteService.getFinalNode()).thenReturn(target); //指定返回值     Node result = remoteService.getFinalNode(); //直接调用final方法，返回mock后的值     assertEquals(target, result); //验证返回值     assertEquals(2, result.getNum());     assertEquals(&quot;mock&quot;, result.getName()); &#125;\n\n\nmock static方法\n1234567891011121314151617181920//Node public static Node getStaticNode() &#123;     return new Node(1, &quot;static node&quot;); &#125; /**  * mock static方法  */ @Test @PrepareForTest(Node.class) //static方法定义在Node类中 public void testStatic() &#123;     Node target = new Node(2, &quot;mock&quot;);     PowerMockito.mockStatic(Node.class); //mock static方法前需要加这一句     PowerMockito.when(Node.getStaticNode()).thenReturn(target); //指定返回值     Node result = Node.getStaticNode(); //直接调用static方法，返回mock后的值     assertEquals(target, result); //验证返回值     assertEquals(2, result.getNum());     assertEquals(&quot;mock&quot;, result.getName()); &#125;\n\n\nmock private方法\n12345678910111213141516171819202122232425262728//RemoteServiceImpl @Override public Node getPrivateNode() &#123;     return privateMethod(); &#125; //RemoteServiceImpl private Node privateMethod() &#123;     return new Node(1, &quot;private node&quot;); &#125; /**  * mock 私有方法  */ @Test @PrepareForTest(RemoteServiceImpl.class) //private方法定义在RemoteServiceImpl类中 public void testPrivate() throws Exception &#123;     Node target = new Node(2, &quot;mock&quot;);     //按照真实代码调用privateMethod方法     PowerMockito.when(remoteService.getPrivateNode()).thenCallRealMethod();     //私有方法无法访问，类似反射传递方法名和参数，此处无参数故未传     PowerMockito.when(remoteService, &quot;privateMethod&quot;).thenReturn(target);     Node result = remoteService.getPrivateNode();     assertEquals(target, result); //验证返回值     assertEquals(2, result.getNum());     assertEquals(&quot;mock&quot;, result.getName()); &#125;\n\n\nmock 系统类方法\n1234567891011121314151617181920//RemoteServiceImpl @Override public Node getSystemPropertyNode() &#123;     return new Node(System.getProperty(&quot;abc&quot;)); &#125; /**  * mock 系统类方法  */ @Test @PrepareForTest(RemoteServiceImpl.class) //类似new关键字，系统类方法的调用在类RemoteServiceImpl中，所以这里填的是RemoteServiceImpl public void testSystem() &#123;     PowerMockito.mockStatic(System.class); //调用的是系统类的静态方法，所以要加这一句     PowerMockito.when(System.getProperty(&quot;abc&quot;)).thenReturn(&quot;mock&quot;); //设置System.getProperty(&quot;abc&quot;)返回&quot;mock&quot;     PowerMockito.when(remoteService.getSystemPropertyNode()).thenCallRealMethod(); //设置mock对象调用实际方法     Node result = remoteService.getSystemPropertyNode(); //按代码会返回一个name属性为&quot;mock&quot;的对象     assertEquals(0, result.getNum()); //int默认值为0     assertEquals(&quot;mock&quot;, result.getName()); //remoteService对象中调用System.getProperty(&quot;abc&quot;)返回的是上面设置的&quot;mock&quot; &#125;\n\n\n参考\nMockito与PowerMock的使用基础教程\npowermock官网\n","plink":"https://zinki.github.io/2021/09/15/PowerMock基础教程/"},{"title":"线程池及异步使用","date":"2021-08-29T11:30:00.000Z","date_formatted":{"ll":"2021年8月29日","L":"2021/08/29","MM-DD":"08-29"},"updated":"2024-10-11T02:20:25.402Z","content":"异步执行程序在实践中经常使用，除Spring自带@Async注解外，可以通过自定义线程池来实现，自由度更高。\njava\n/**\n* 线程池核心线程数\n*/\nprivate static int CORE_POOL_SIZE = 10;\nprivate static ThreadPoolExecutor threadPoolExecutor;\n\nstatic &#123;\n    threadPoolExecutor = new ThreadPoolExecutor(CORE_POOL_SIZE, CORE_POOL_SIZE\n            , CardConstants.TEN, TimeUnit.SECONDS,\n            new LinkedBlockingQueue&lt;&gt;(),new ThreadFactoryBuilder().setNamePrefix(&quot;async-&quot;).build());\n&#125;\n\n\n/**\n * 异步执行方法\n * @param runnable\n * @return\n */\npublic static void execute(Runnable runnable) &#123;\n    threadPoolExecutor.execute(runnable);\n&#125;\n\n\n调试时注意到进程在执行完成后不会消亡\n\n### 原因\n\nJVM退出的条件是当前不存在用户线程，而线程池默认的ThreadFactory创建的线程是用户线程。\n\n首先我们需要了解线程池在什么情况下会自动关闭。**ThreadPoolExecutor** 类（这是我们最常用的线程池实现类）的源码注释中有这么一句话：\n\n&gt; A pool that is no longer referenced in a program and has no remaining threads will be shutdown automatically.\n&gt; \n&gt; 没有引用指向且没有剩余线程的线程池将会自动关闭。\n\n由于核心线程一直存在，所以线程池不会关闭。\n\n### 解决办法\n\n1. 手动关闭线程池 `threadPoolExecutor.shutdown();`\n\n2. 核心线程数量设置为0，超时时间后线程池会自动关闭\n\n3. 设置属性`allowCoreThreadTimeOut `来实现\n\n### 参考\n\n[Java 线程池会自动关闭吗](https://segmentfault.com/a/1190000021225019)\n\n[使用线程池时候当程序结束时候记得调用shutdown关闭线程池](https://cloud.tencent.com/developer/article/1330497)\n\n","plink":"https://zinki.github.io/2021/08/29/线程池及异步使用/"},{"title":"Git批量更新脚本","date":"2021-08-19T08:10:00.000Z","date_formatted":{"ll":"2021年8月19日","L":"2021/08/19","MM-DD":"08-19"},"updated":"2024-10-10T08:03:05.462Z","content":"随着本地项目越来越多，手动项目更新导致很多项目不是最新的，调试会出现问题，故参考网上博客写了批量更新脚本以方便批量操作。\nWindows脚本\n1234567891011@echo offset pa=%cd%echo %pa%for /d %%s in (*)do (\techo.\techo.\techo %%s git...pull....\tcd %pa%\\%%s\tgit pull)pause\nShell脚本\n1234567891011121314151617181920212223242526#!/bin/bash# 获取 git 仓库路径for LINE in $(find `pwd` -type d -name &quot;.git&quot;);do echo &quot;$LINE&quot;;cd &quot;$LINE&quot;cd ..# 切换分支branch_name=&quot;release&quot;if [ &quot;$(git branch --show-current)&quot; = &quot;$branch_name&quot; ] || [ &quot;$(git branch --show-current)&quot; = &quot;master&quot; ];then\techo &quot;Branch already switch.&quot;else\tif [ `git branch --list &quot;$branch_name&quot;` ]\tthen\t\techo &quot;switch branch name $branch_name.&quot;\t\tgit checkout $branch_name\telse\t\techo &quot;switch branch name master.&quot;\t\tgit checkout master\tfifi# 更新git pull;done\n参考\n【Git/GitHub学习笔记】一键更新多个git仓库至远程\n","plink":"https://zinki.github.io/2021/08/19/git批量更新脚本/"},{"title":"Aria2-Mac配置指南","date":"2021-07-20T10:30:00.000Z","date_formatted":{"ll":"2021年7月20日","L":"2021/07/20","MM-DD":"07-20"},"updated":"2024-10-10T08:03:05.437Z","content":"Aria2是一个轻量级、支持多种协议的命令行下载工具。\n\n支持的协议包括HTTP(S), FTP, BitTorrent, Metalink\naria2可以并发的进行下载，并尝试将下载带宽利用率最大化\n分片与续传，自动中止并替换慢的线程\n另外，Aria2可以实现百度网盘，迅雷等离线下载\n\n安装\n1$ brew install aria2\n配置\n1234$ cd ~$ mkdir .aria2$ cd .aria2$ touch aria2.conf\naria2有两个模式，第一个没有后台在命令行里运行的，第二个就是 rpc 模式。\n可以设置aria2.conf文件如下:\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546#用户名#rpc-user=user#密码#rpc-passwd=passwd#上面的认证方式不建议使用,建议使用下面的token方式#设置加密的密钥#rpc-secret=token#允许rpcenable-rpc=true#允许所有来源, web界面跨域权限需要rpc-allow-origin-all=true#允许外部访问，false的话只监听本地端口rpc-listen-all=true#RPC端口, 仅当默认端口被占用时修改#rpc-listen-port=6800#最大同时下载数(任务数), 路由建议值: 3max-concurrent-downloads=5#断点续传continue=true#同服务器连接数max-connection-per-server=5#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要min-split-size=10M#单文件最大线程数, 路由建议值: 5split=10#下载速度限制max-overall-download-limit=0#单文件速度限制max-download-limit=0#上传速度限制max-overall-upload-limit=0#单文件速度限制max-upload-limit=0#断开速度过慢的连接#lowest-speed-limit=0#验证用，需要1.16.1之后的release版本#referer=*#文件保存路径, 默认为当前启动位置dir=/Users/xxx/Downloads#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本#disk-cache=0#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)#enable-mmap=true#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长#所需时间 none &lt; falloc ? trunc « prealloc, falloc和trunc需要文件系统和内核支持file-allocation=prealloc\n启动\n1$ aria2c --conf-path=&quot;/Users/xxxxxx/.aria2/aria2.conf&quot; -D\n关闭\n1在终端输入 ps aux|grep aria2 获取到进程号，然后使用 kill number 回车即可杀掉它\nAria2支持WebUI,谷歌插件等，可以酌情配置\n参考\nAria2官网\nAria2配置示例\nAria2WebUI\n","plink":"https://zinki.github.io/2021/07/20/Aria2-Mac配置指南/"},{"title":"证书及密钥相关概念","date":"2021-06-20T07:40:00.000Z","date_formatted":{"ll":"2021年6月20日","L":"2021/06/20","MM-DD":"06-20"},"updated":"2024-10-10T08:03:05.477Z","content":"根据非对称密码学的原理，每个证书持有人都有一对公钥和私钥，这两把密钥可以互为加解密。\n公钥是公开的，不需要保密，而私钥是由证书持有人自己特有，并且必须妥善保管和注意保密。数字证书则是由证书认证机构（CA）对证书申请者真实身份验证之后，用CA的根证书对申请人的一些基本信息以及申请人的公钥进行签名（相当于加盖发证书机构的公章）后形成的一个数字文件。\n数字证书就是经过CA认证过的公钥，因此数字证书和公钥一样是公开的。可以这样说，数字证书就是经过CA认证过的公钥，而私钥一般情况都是由证书持有者在自己本地生成或委托受信的第三方生成的，由证书持有者自己负责保管或委托受信的第三方保管。\n证书概述\n证书主要包括颁发者和被办法者的信息,以及被颁发者的公钥，和CA机构对这些信息的认证。\n主要内容：\n版本\n识别用于该证书的 X.509 标准的版本，这可以影响证书中所能指定的信息。迄今为止，已定义的版本有三个。\n序列号\n发放证书的实体有责任为证书指定序列号，以使其区别于该实体发放的其它证书。此信息用途很多。例如，如果某一证书被撤消，其序列号将放到证书撤消清单 (CRL) 中。\n签名算法标识符\n用于识别 CA 签写证书时所用的算法。\n签发人姓名\n签写证书的实体的 X.500 名称。它通常为一个 CA。 使用该证书意味着信任签写该证书的实体（注意：有些情况下（例如根或顶层 CA 证书），签发人会签写自己的证书）。\n有效期\n每个证书均只能在一个有限的时间段内有效。该有效期以起始日期和时间及终止日期和时间表示，可以短至几秒或长至一世纪。所选有效期取决于许多因素，例如用于签写证书的私钥的使用频率及愿为证书支付的金钱等。它是在没有危及相关私钥的条件下，实体可以依赖公钥值的预计时间。\n主体名\n证书可以识别其公钥的实体名。此名称使用 X.500 标准，因此在Internet中应是唯一的。它是实体的特征名 (DN)，例如，\nCN=Java Duke，OU=Java Software Division，O=Sun Microsystems Inc，C=US\n（这些指主体的通用名、组织单位、组织和国家）。\n主体公钥信息\n这是被命名实体的公钥，同时包括指定该密钥所属公钥密码系统的算法标识符及所有相关的密钥参数。\nPEM DER 只是编码方式，注意并不指定是证书的编码方式，也可以是密钥的编码方式\n各种名词和文件后缀\n\nX.509 - 这是一种证书标准,主要定义了证书中应该包含哪些内容.\n两种编码方式：\nPEM - Privacy Enhanced Mail,打开看文本格式,以-----BEGIN...开头, -----END...结尾,内容是BASE64编码.\n查看PEM格式证书的信息:openssl x509 -in certificate.pem -text -noout Apache和NIX服务器偏向于使用这种编码格式.\nDER - Distinguished Encoding Rules,打开看是二进制格式,不可读.\n\n查看DER格式证书的信息:openssl x509 -in certificate.der -inform der -text -nooutJava和Windows服务器偏向于使用这种编码格式.\n各种文件拓展名：\n\nCRT - CRT应该是certificate的三个字母,其实还是证书的意思,常见于*NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码\nCER - 还是certificate,还是证书,常见于Windows系统,同样的,可能是PEM编码,也可能是DER编码,大多数应该是DER编码.\nKEY - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.\nCSR - Certificate Signing Request,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个公钥(当然还附带了一些别的信息),在生成这个申请的时候,同时也会生成一个私钥\nPFX/P12 - predecessor of PKCS#12,对nix服务器来说,一般CRT和KEY是分开存放在不同文件中的,但Windows的IIS则将它们存在一个PFX文件中,(因此这个文件包含了证书及私钥)这样会不会不安全？应该不会,PFX通常会有一个&quot;提取密码&quot;\n总结起来：crt cer约等于x509证书，key保存公钥或私钥，csr是证书签名请求，pfx包含证书和私钥\nPKCS系列\n当我发现还有PKCS系列时，我很凌乱， PKCS系列是 Public-Key Cryptography Standards ，是RSA制定的一系列的标准，注意前面写的什么文件后缀啥的，都不算是标准，只有X509和PKCS可以称为标准， PKCS中经常使用的就是：PKCS1 PKCS8 PKCS12\n• PKCS#1：定义RSA公开密钥算法加密和签名机制，主要用于组织PKCS#7中所描述的数字签名和数字信封。\n• PKCS#8：描述私有密钥信息格式，该信息包括公开密钥算法的私有密钥以及可选的属性集等。注意pkcs8不只是能表示RSA，所以比PKCS1更具有通用性\n• PKCS#12：描述个人信息交换语法标准。描述了将用户公钥、私钥、证书和其他相关信息打包的语法。\n总结：PKCS1,8,12都可以在某些情况下当作文件格式，PKCS1描述基础的密钥格式，PKCS8也描述密钥，但格式和1不同，PKCS12等价于PFX文件，包含证书和私钥\n\nOpenSSL\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647生成PKCS#1的公私钥openssl genrsa -out pkcs1_private.pem 1024openssl rsa -in pkcs1_private.pem -RSAPublicKey_out -out pkcs1_public.pem查看私钥 openssl rsa -in rsa_private_key.pem -text -noout查看公钥openssl rsa -pubin -in  rsa_public_key.pem  -text# 由PKCS#1的私钥，生成PKCS#8的公私钥openssl pkcs8 -topk8 -inform PEM -in pkcs1_private.pem -outform PEM -nocrypt -out from_pkcs1_private_to_pkcs8_private.pemopenssl rsa -in pkcs1_private.pem -pubout -out from_pkcs1_private_to_pkcs8_public.pem# 由PKCS#8的私钥，生成PKCS#1的公私钥openssl rsa -in from_pkcs1_private_to_pkcs8_private.pem -out from_pkcs8_private_to_pkcs1_private.pemopenssl rsa -in from_pkcs1_private_to_pkcs8_private.pem -RSAPublicKey_out -out from_pkcs8_private_to_pkcs1_public.pem# 由PKCS1公钥生成PKCS#8公钥:openssl rsa -RSAPublicKey_in -in pkcs1_public.pem -pubout -out from_pkcs1_public_to_pkcs8_public.pem# 由PKCS8公钥生成PKCS#1公钥:openssl rsa -pubin -in from_pkcs1_private_to_pkcs8_public.pem -RSAPublicKey_out -out from_pkcs8_public_to_pkcs1_public.pem产生证书请求 注意PKCS1 8都可以openssl req -new -key private_key.pem -out rsaCerReq.csr产生证书 注意PKCS1 8都可以openssl x509 -req -days 3650 -in rsaCerReq.csr -signkey private_key.pem -out rsaCert.crt从证书获得公钥：openssl x509 -in rsaCert.crt  -noout  -pubkey  &gt; public_key.pem生成PKCS12openssl pkcs12 -export -inkey serverprikey.pem -in server.pem -password pass:&quot;123456&quot; -out server_nocret.pfx从PKCS12获得证书和私钥openssl pkcs12 -in server_nocret.pfx -nocerts -nodes  -out alicekey.pemopenssl pkcs12 -in server_nocret.pfx  -nokeys  -out cert.pem查看pkcs12内容 -nodes:因为私钥在在输出前会输出加密结果，所以需要nodes来保证不用打密码和不加密openssl pkcs12 -in server_nocret.pfx -nocerts -nodes  -out alicekey.pem`\nRSA\n\n随机找两个质数 P 和 Q ,定义n= p*q\n计算 n 的欧拉函数 m= φ(n) =(p-1)*(1-1),为什么是这样我就不懂了 ，即表示在小于n的数中有多少个与n构成互质,\n随机选择一个整数 e，条件是1&lt; e &lt; m，且 e 与 m 互质。\n计算d : e*d % m=1 ,虽然是二元一次方程，但通过拓展欧几里得算法可以得出，反正这个算法我也不懂，能算出来就能算出来吧\n公钥 （n,e） 私钥（n,d）\n为什么难以破解：在已知 公钥 N E 的情况下，想要知道 私钥的额D　就需要知道ｍ，而 m=(p-1)(Q-1),想要知道P Q就只能对 N 进行分解，而大整数的因式分解是难以破解的，所以保证了安全\nPKCS的结构\n之前我一直奇怪为什么私钥可以转换出公钥，以为是RSA算法的原理所导致，但看起来原理并不满足私钥算出公钥的操作，所以我觉得问题出在PKCS内容上：\nPKCS1 的公钥结构：\n\n1234RSAPublicKey ::= SEQUENCE &#123;    modulus           INTEGER,  -- n    publicExponent    INTEGER   -- e&#125;\nPKCS1 的私钥结构：\n123456789101112RSAPrivateKey ::= SEQUENCE &#123;  version           Version,  modulus           INTEGER,  -- n  publicExponent    INTEGER,  -- e  privateExponent   INTEGER,  -- d  prime1            INTEGER,  -- p  prime2            INTEGER,  -- q  exponent1         INTEGER,  -- d mod (p-1)  exponent2         INTEGER,  -- d mod (q-1)  coefficient       INTEGER,  -- (inverse of q) mod p  otherPrimeInfos   OtherPrimeInfos OPTIONAL&#125;\nPKCS1 公钥：\n123456789PublicKeyInfo ::= SEQUENCE &#123;  algorithm       AlgorithmIdentifier,  PublicKey       BIT STRING&#125;AlgorithmIdentifier ::= SEQUENCE &#123;  algorithm       OBJECT IDENTIFIER,  parameters      ANY DEFINED BY algorithm OPTIONAL&#125;\nPKCS8私钥\n12345678910PrivateKeyInfo ::= SEQUENCE &#123;  version         Version,  algorithm       AlgorithmIdentifier,  PrivateKey      BIT STRING&#125;AlgorithmIdentifier ::= SEQUENCE &#123;  algorithm       OBJECT IDENTIFIER,  parameters      ANY DEFINED BY algorithm OPTIONAL&#125; \n可以看出PKCS1 的私钥包含了密钥产生的所有元素，所以能算出公钥就不奇怪了，至于PKCS8 看起来不包含，但为什么也可以，我想应该只是结构不同，内容应该都是有的\n参考\n关于X509证书和密钥的概念\n","plink":"https://zinki.github.io/2021/06/20/证书及密钥相关概念/"},{"title":"SnowFlakeID生成算法","date":"2021-06-10T11:50:00.000Z","date_formatted":{"ll":"2021年6月10日","L":"2021/06/10","MM-DD":"06-10"},"updated":"2024-10-11T08:02:34.463Z","content":"\n据国家大气研究中心的查尔斯·奈特称，一般的雪花大约由10^19个水分子组成。在雪花形成过程中，会形成不同的结构分支，所以说大自然中不存在两片完全一样的雪花，每一片雪花都拥有自己漂亮独特的形状。雪花算法表示生成的id如雪花般独一无二。\nsnowflake是Twitter开源的分布式ID生成算法，结果是一个long型的ID。其核心思想是：使用41bit作为毫秒数，10bit作为机器的ID（5个bit是数据中心，5个bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每毫秒可以产生 4096 个 ID），最后还有一个符号位，永远是0。\n\nsnowflake算法所生成的ID结构：\n\n\n第一位\n\n占用1bit，其值始终是0，没有实际作用。\n\n时间戳\n\n占用41bit，精确到毫秒，总共可以容纳约69 年的时间。\n\n工作机器id\n\n占用10bit，其中高位5bit是数据中心ID（datacenterId），低位5bit是工作节点ID（workerId），做多可以容纳1024个节点。\n\n序列号\n\n占用12bit，这个值在同一毫秒同一节点上从0开始不断累加，最多可以累加到4095。\nSnowFlake算法在同一毫秒内最多可以生成多少个全局唯一ID呢？只需要做一个简单的乘法：\n同一毫秒的ID数量 = 1024 X 4096 = 4194304\n这个数字在绝大多数并发场景下都是够用的。\nSnowFlake算法的优点：\n\n\n生成ID时不依赖于DB，完全在内存生成，高性能高可用。\n\n\nID呈趋势递增，后续插入索引树的时候性能较好。\n\n\nSnowFlake算法的缺点：\n依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序。\n\n时钟为什么会发生回拨？机器本地时钟可能会因为各种原因发生不准的情况，网络中提供了NTP服务来做时间校准，做校准的时候就会发生时钟的跳跃或者回拨的问题\n\n解决方案：\n\n\n定义时钟回拨后等待最大值\n1234567891011121314151617181920/*** 时钟回拨最大值 3 毫秒，不建议大于 5 毫秒 */private final static long MAX_BACKWARD_MS =3;// 当前时间戳小于上次时间戳，出现时钟回拨 if (currStamp &lt; lastStamp) &#123;    // 偏移量     long offset = lastStamp - currStamp;    if (offset &lt;= MAX_BACKWARD_MS) &#123;        // 休眠等待         LockSupport.parkNanos (TimeUnit.MICROSECONDS.toNanos (offset));        // 重新获取当前值         currStamp = getNewStamp ();        // 如果仍然小于上次时间戳，可以直接抛异常或者采用扩展字段 extension        if (currStamp &lt; lastStamp) &#123;            throw new RuntimeException (&quot;Clock moved backwards.  Refusing to generate id&quot;);        &#125;    &#125;&#125;\n\n\n​利用拓展位\n由于 SnowFlake 最后序列号占用 12 位 bit，一毫秒可以生成 4096 个 ID，一般系统用不到这么大的并发量的的话，可以拿出几位当成时钟回拨扩展位，或者其他几部分也可以拿出几位来用于扩展。在此拿出序列号的 2 位用于时钟回拨的扩展\n\n\n参考\n讲讲雪花算法，越详细越好\n分布式 ID 方案 --SnowFlake（雪花算法）\n","plink":"https://zinki.github.io/2021/06/10/SnowFlakeID生成算法/"},{"title":"Netty线程模型","date":"2021-05-11T07:40:00.000Z","date_formatted":{"ll":"2021年5月11日","L":"2021/05/11","MM-DD":"05-11"},"updated":"2024-10-11T08:01:36.768Z","content":"Netty 是一个 NIO 客户端服务器框架，可以快速轻松地开发网络应用程序，例如协议服务器和客户端。它极大地简化和精简了 TCP 和 UDP 套接字服务器等网络编程。\n\n传统阻塞IO模型存在以下问题：\n\n每个连接都需要独立线程处理，当并发数大时，创建线程数多，占用资源\n采用阻塞IO模型，连接建立后，若当前线程没有数据可读，线程会阻塞在读操作上，造成资源浪费\n\n针对于存在的问题可以采取以下方案：\n\n基于线程池思想，避免为每个连接创建线程，连接完成后将业务处理交给线程池处理。\n基于IO复用模型，多个连接共用同一个阻塞对象，不用等待所有的连接。遍历到有新数据可以处理时，操作系统会通知程序，线程跳出阻塞状态，进行业务逻辑处理。\n\n\nReactor线程模型就是基于IO复用和线程池的结合，其核心是I/O多路复用和事件驱动。\n\nReactor单线程模型\n由于Reactor模式使用的是异步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独立处理所有IO相关的操作。从架构层面看，一个NIO线程确实可以完成其承担的职责。例如，通过Acceptor类接收客户端的TCP连接请求消息，链路建立成功之后，通过Dispatch将对应的ByteBuffer派发到指定的Handler上进行消息解码。用户线程可以通过消息编码通过NIO线程将消息发送给客户端。\n\n对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用场景却不合适，主要原因如下：\n\n用一个线程处理请求，对于多核资源机器来说是有点浪费的；\n一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送；\n当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈；\n可靠性问题：一旦NIO线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。\n为了解决这些问题，演进出了Reactor多线程模型。\n\nReactor多线程模型\nRector多线程模型与单线程模型最大的区别就是换成了线程池处理，也就是Reactor线程只处理连接事件和读写事件，业务处理交给线程池处理，充分利用多核机器的资源、提高性能并且增加可靠性。其特点如下：\n\n有专门一个NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求；\n网络IO操作-读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送；\n1个NIO线程可以同时处理N条链路，但是1个链路只对应1个NIO线程，防止发生并发操作问题。\n\n\n在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极个别特殊场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如并发百万客户端连接，或者服务端需要对客户端握手进行安全认证，但是认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型-主从Reactor多线程模型。\n主从Reactor多线程模型\n主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO（mainReactor）线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到IO线程池（subreactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。\n\n工作流程大致如下：\n\n从主线程池中随机选择一个Reactor线程作为Acceptor线程，用于绑定监听端口，接收客户端连接；\nAcceptor线程接收客户端连接请求之后创建新的SocketChannel，将其注册到主线程池的其它Reactor线程上，由其负责接入认证、IP黑白名单过滤、握手等操作；\n步骤2完成之后，业务层的链路正式建立，将SocketChannel从主线程池的Reactor线程的多路复用器上摘除，重新注册到Sub线程池的线程上，用于处理I/O的读写操作\n\n使用netty而不用原生NIO原因:\n\nNIO的类库和API繁杂，使用麻烦\n需要具备其他的额外技能做铺垫，例如熟悉Java多线程编程。这是因为NIO编程涉及到Reactor模式，你必须对多线程和网路编程非常熟悉，才能编写出高质量的NIO程序。\n可靠性能力补齐，工作量和难度都非常大。例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题，NIO编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。\nJDK NIO的BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询，最终导致CPU 100%。官方声称在JDK1.6版本的update18修复了该问题，但是直到JDK1.7版本该问题仍旧存在，只不过该BUG发生概率降低了一些而已，它并没有被根本解决。\n\n参考\n\nNetty官网\nReactor线程模型\n\n","plink":"https://zinki.github.io/2021/05/11/Netty线程模型/"},{"title":"一致性Hash原理","date":"2021-04-25T10:30:00.000Z","date_formatted":{"ll":"2021年4月25日","L":"2021/04/25","MM-DD":"04-25"},"updated":"2024-10-11T08:05:40.786Z","content":"\n在维基百科中，是这么定义的:\n一致哈希是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n个关键字重新映射，其中K是关键字的数量， n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。\n\n\n使用Hash时遇到的问题\n在上述hash取模的过程中，我们虽然不需要对所有Redis服务器进行遍历而提升了性能。但是，使用Hash算法缓存时会出现一些问题，Redis服务器变动时，所有缓存的位置都会发生改变。 比如，现在我们的Redis缓存服务器增加到了8台，我们计算的公式从hash(product.png) % 6 = 5变成了hash(product.png) % 8 = ? 结果肯定不是原来的5了。\n再者，6台的服务器集群中，当某个主从群出现故障时，无法进行缓存，那我们需要把故障机器移除，所以取模数又会从6变成了5。我们计算的公式也会变化。\n由于上面hash算法是使用取模来进行缓存的，为了规避上述情况，Hash一致性算法就诞生了\n一致性Hash算法原理\n一致性Hash算法也是使用取模的方法，不过，上述的取模方法是对服务器的数量进行取模，而一致性的Hash算法是对2的32方取模。即一致性Hash算法将整个Hash空间组织成一个虚拟的圆环，Hash函数的值空间为0~2^32-1(一个32位无符号整型)，整个哈希环如下：\n\n整个圆环以顺时针方向组织，圆环正上方的点代表0，0点右侧的第一个点代表1，以此类推。\n第二步，我们将各个服务器使用Hash进行一个哈希，具体可以选择服务器的IP或主机名作为关键字进行哈希，这样每台服务器就确定在了哈希环的一个位置上，比如我们有三台机器，使用IP地址哈希后在环空间的位置如图所示\n\n现在，我们使用以下算法定位数据访问到相应的服务器：\n将数据Key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针查找，遇到的服务器就是其应该定位到的服务器。\n例如，现在有ObjectA，ObjectB，ObjectC三个数据对象，经过哈希计算后，在环空间上的位置如下：\n\n根据一致性算法，Object -&gt; NodeA，ObjectB -&gt; NodeB, ObjectC -&gt; NodeC\n一致性Hash算法的容错性和可扩展性\n现在，假设我们的Node C宕机了，我们从图中可以看到，A、B不会受到影响，只有Object C对象被重新定位到Node A。所以我们发现，在一致性Hash算法中，如果一台服务器不可用，受影响的数据仅仅是此服务器到其环空间前一台服务器之间的数据（这里为Node C到Node B之间的数据），其他不会受到影响。如图所示：\n\n另外一种情况，现在我们系统增加了一台服务器Node X，如图所示：\n\n此时对象ObjectA、ObjectB没有受到影响，只有ObjectC重新定位到了新的节点X上。 如上所述：\n一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，有很好的容错性和可扩展性。\n数据倾斜问题\n在一致性Hash算法服务节点太少的情况下，容易因为节点分布不均匀面造成数据倾斜（被缓存的对象大部分缓存在某一台服务器上）问题，如图特例：\n\n这时我们发现有大量数据集中在节点A上，而节点B只有少量数据。为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。\n具体操作可以为服务器IP或主机名后加入编号来实现，实现如图所示：\n\n数据定位算法不变，只需要增加一步：虚拟节点到实际点的映射。所以加入虚拟节点之后，即使在服务节点很少的情况下，也能做到数据的均匀分布。\n\n每个节点的可虚拟节点数，及总的虚拟节点数，应该有已被实践过的参考范围，而不应该是越多越好。同时，随着实际节点数的变化，对应的总的虚拟节点数也应该是动态的，而不是线性的\n\n\nredis，memcache的第三方Java Api，及Guava中都有一致性hash的工具类，可以直接使用，也不用纠结于合理的虚拟节点的数目该怎么取，例如Guava中\n\n1234567891011//guava源码说明public static int consistentHash(HashCode hashCode, int buckets) &#123;   return consistentHash(hashCode.padToLong(), buckets); &#125; //入参 buckets 是实际的集群节点，例如 buckets=3，表示有3台机器 1,2,3  当然通过这三个数字，也要能找到对应的机器信息（IP，端口等） //入参 HashCode 这个类中有相应static函数，见下方，可以把实际查找的Key(无论是 int,long,String,byte[]) 转化为HashCode对象。 //返回值：int, 就是经过一致性hash处理后的buckets 中的一个值。注意该值范围是 0~（buckets-1），类似数组下标从0开始一样。 HashCode.fromBytes() HashCode.fromInt() HashCode.fromLong() HashCode.fromString()\n参考\n一致性Hash原理与实现\n","plink":"https://zinki.github.io/2021/04/25/一致性Hash原理/"},{"title":"Integer取值陷阱","date":"2021-04-11T05:00:00.000Z","date_formatted":{"ll":"2021年4月11日","L":"2021/04/11","MM-DD":"04-11"},"updated":"2024-10-10T08:03:05.446Z","content":"Java中Integer类型1000!=1000,而100==100\n原因是Integer.java有一个内部私有类IntegerCache.java，它缓存了从-128到127之间的所有的整数对象。\n1234Integer a= 100,b=100;Integer c= 1000,d=1000;System.out.println(a == b);System.out.println(c == d);\n所以事情就成了，所有的小整数在内部缓存，然后当我们声明类似Integer c = 100;\n的时候，它实际上在内部做的是：\nInteger i = Integer.valueOf(100);\n现在，如果我们去看valueOf()方法，我们可以看到：\n12345public static Integer valueOf(int i) &#123;    if (i &gt;= IntegerCache.low &amp;&amp; i    return IntegerCache.cache[i + (-IntegerCache.low)];    return new Integer(i);&#125;\nIntegerCache是一个私有静态内部类\n123456789101112131415161718192021222324private static class IntegerCache &#123;    static final int low = -128;    static final int high;    static final Integer cache[];    static &#123;        //high value may be configured by property        int h = 127;        String integerCacheHighPropValue =            sun.misc.VM.getSavedProperty(            &quot;java.lang.Integer.IntegerCache.high&quot;);        if(integerCacheHighPropValue != null) &#123;            int i = parseInt(integerCacheHighPropValue);            i = Math.max(i, 127);            //Maximum array size is Integer.MAX_VALUE            h = Math.min(i, Integer.MAX_VALUE - (-low) -1);        &#125;        high = h;        cache = new Integer[(high - low) + 1];        int j = low;        for(int k = 0; k &lt; cache.length; k++)            cache[k] = new Integer(j++);    &#125;    private IntegerCache() &#123;&#125;&#125;\n\n如果值的范围在-128到127之间，它就从高速缓存返回实例。\n合乎逻辑的理由是，在此范围内的小整数使用率比大整数要高，因此，使用相同的底层对象是有价值的，可以减少潜在的内存占用。\n\n\n对于==，如果作用于基本数据类型的变量，则直接比较其存储的值是否相等；\n如果作用于引用类型的变量，则比较的是所指向的对象的地址\n对于equals方法，注意：equals方法不能作用于基本数据类型的变量\n如果没有对equals方法进行重写，则比较的是引用类型的变量所指向的对象的地址；\n诸如String、Date等类对equals方法进行了重写的话，比较的是所指向的对象的内容。\n\n","plink":"https://zinki.github.io/2021/04/11/Integer取值陷阱/"},{"title":"线程池设置线程名称","date":"2021-03-20T07:30:00.000Z","date_formatted":{"ll":"2021年3月20日","L":"2021/03/20","MM-DD":"03-20"},"updated":"2024-10-11T02:20:40.325Z","content":"为什么要使用线程池？\n避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以根据项目灵活地控制并发的数目。\n基于业务需要，需要支持针对特定线程进行操作，所以给线程设置名称很重要。\nCustomizableThreadFactory\nSpring 框架提供的 CustomizableThreadFactory。\njava\nExecutorService exec = new ThreadPoolExecutor(1, 1,\n0L, TimeUnit.MILLISECONDS,\nnew LinkedBlockingQueue(10),springThreadFactory);\nexec.submit(() -&gt; {\nlogger.info(“–记忆中的颜色是什么颜色—”);\n});\n12345678910111213### ThreadFactoryBuilderGoogle guava 工具类 提供的 ThreadFactoryBuilder ,使用链式方法创建。ThreadFactory guavaThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;retryClient-pool-&quot;).build();```javaExecutorService exec = new ThreadPoolExecutor(1, 1,        0L, TimeUnit.MILLISECONDS,        new LinkedBlockingQueue&lt;Runnable&gt;(10),guavaThreadFactory );exec.submit(() -&gt; &#123;    logger.info(&quot;--记忆中的颜色是什么颜色---&quot;);&#125;);\nBasicThreadFactory\nApache commons-lang3 提供的 BasicThreadFactory.ThreadFactory basicThreadFactory = new BasicThreadFactory.Builder().namingPattern(“basicThreadFactory-”).build();\n123456ExecutorService exec = new ThreadPoolExecutor(1, 1,        0L, TimeUnit.MILLISECONDS,        new LinkedBlockingQueue&lt;Runnable&gt;(10),basicThreadFactory );exec.submit(() -&gt; &#123;    logger.info(&quot;--记忆中的颜色是什么颜色---&quot;);&#125;);\n总结\n最终本质都是 给 java.lang.Thread#name 设置名称,详情源码感兴趣的可以自行查看。\n12final Thread thread = new Thread();thread.setName(name);\n\n以上方法其实存在局限性，只能设置线程前缀且固定，后来选择从线程池取出线程重命名解决。\n\n参考\nJava线程池中三种方式创建 ThreadFactory 设置线程名称\n","plink":"https://zinki.github.io/2021/03/20/线程池设置线程名称/"},{"title":"Kafka相关知识","date":"2021-02-17T13:10:00.000Z","date_formatted":{"ll":"2021年2月17日","L":"2021/02/17","MM-DD":"02-17"},"updated":"2024-10-11T08:01:02.762Z","content":"Kafka是一种分布式的，基于发布/订阅的消息系统。\n\n相关名词解释\n\nproducer：消息生产者，发布消息到 kafka 集群的终端或服务。\nbroker：kafka 集群中包含的服务器。\ntopic：每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。\npartition：partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。\nconsumer：从 kafka 集群中消费消息的终端或服务。\nConsumer group：high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 中的一个 Consumer 消费，但可以被多个 consumer group 消费。\nreplica：partition 的副本，保障 partition 的高可用。\nleader：replica 中的一个角色， producer 和 consumer 只跟 leader 交互。\nfollower：replica 中的一个角色，从 leader 中复制数据。\ncontroller：kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。\nzookeeper：kafka 通过 zookeeper 来存储集群的 meta 信息。\n\nkafka 在 zookeeper 中的存储结构如下图所示：\n\nproducer delivery guarantee\n一般情况下存在三种情况：\n\nAt most once 消息可能会丢，但绝不会重复传输\nAt least one 消息绝不会丢，但可能会重复传输\nExactly once 每条消息肯定会被传输一次且仅传输一次\n当 producer 向 broker 发送消息时，一旦这条消息被 commit，由于 replication 的存在，它就不会丢。但是如果 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那 Producer 就无法判断该条消息是否已经 commit。虽然 Kafka 无法确定网络故障期间发生了什么，但是 producer 可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了 Exactly once，但目前还并未实现。所以目前默认情况下一条消息从 producer 到 broker 是确保了 At least once，可通过设置 producer 异步发送实现At most once。\n\nconsumer delivery guarantee\n如果将 consumer 设置为 autocommit，consumer 一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那 Kafka 确保了 Exactly once。\n但实际使用中应用程序并非在 consumer 读取完数据就结束了，而是要进行进一步处理，而数据处理与 commit 的顺序在很大程度上决定了consumer delivery guarantee：\n\n读完消息先 commit 再处理消息。\n这种模式下，如果 consumer 在 commit 后还没来得及处理消息就 crash 了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once\n读完消息先处理再 commit。\n这种模式下，如果在处理完消息之后 commit 之前 consumer crash 了，下次重新开始工作时还会处理刚刚未 commit 的消息，实际上该消息已经被处理过了。这就对应于 At least once。\n如果一定要做到 Exactly once，就需要协调 offset 和实际操作的输出。\n精典的做法是引入两阶段提交。如果能让 offset 和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer 拿到数据后可能把数据放到 HDFS，如果把最新的 offset 和数据本身一起写到 HDFS，那就可以保证数据的输出和 offset 的更新要么都完成，要么都不完成，间接实现 Exactly once。（目前就 high-level API而言，offset 是存于Zookeeper 中的，无法存于HDFS，而SimpleConsuemr API的 offset 是由自己去维护的，可以将之存于 HDFS 中）\n\n总之，Kafka 默认保证At least once，并且允许通过设置 producer 异步提交来实现 At most once。而 Exactly once 要求与外部存储系统协作，幸运的是 kafka 提供的 offset 可以非常直接非常容易得使用这种方式\nKafka拓扑结构\n\n如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\nTopic &amp; Partition\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹\n每个日志文件都是一个log entrie序列，每个log entrie包含一个4字节整型数值（值为N+5），1个字节的&quot;magic value&quot;，4个字节的CRC校验码，其后跟N个字节的消息体。每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：\n1234message length ： 4 bytes (value: 1+4+n)&quot;magic&quot; value ： 1 byte crc ： 4 bytes payload ： n bytes \n这个log entries并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以.kafka为后缀。另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围，如下图所示:\n\n因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。\n\nISR（in-sync replicas）副本同步\n\n","plink":"https://zinki.github.io/2021/02/17/Kafka相关知识/"},{"title":"如何删除服务器攻击脚本","date":"2020-12-11T07:30:00.000Z","date_formatted":{"ll":"2020年12月11日","L":"2020/12/11","MM-DD":"12-11"},"updated":"2024-10-10T08:03:05.465Z","content":"阿里云上的redis因为端口暴露被攻击，本地有份攻击脚本需要删除。\n删除时报Operation not permitted，用sudo也不行\n解决方法\n上面我们执行的chmod命令，其底层实现是chattr命令，用此命的功能更为强大，甚至可以锁定文件，即使root用户也操作不了此文件。\nchattr是用来更改文件属性，lsattr可用来查看文件的属性，执行命令lsattr /webapps/.usr.ini便可以看到当前文件的属性；\n可以发现当前文件有个i属性，查阅命令帮助文档可以看到有i属性的文件是不能修改的，更不可被删除，即使是root用户也不可。\n既然知道了文件不能删除的原因是加了i属性，所以相应的解决方案就是把文件的i属性去除，然后再删除。\n1234//去除i属性chattr -i webapps  //删除文件夹rm -rf webapps      \n","plink":"https://zinki.github.io/2020/12/11/如何删除服务器攻击脚本/"},{"title":"Onedrive如何备份","date":"2020-11-27T13:30:00.000Z","date_formatted":{"ll":"2020年11月27日","L":"2020/11/27","MM-DD":"11-27"},"updated":"2024-10-10T08:03:05.455Z","content":"方法场景：我需要在 OneDrive 中创建一个 “备份同步” 文件夹，来同步在 D 盘的 “OneNote” 笔记本备份。\n第一步\n打开 OneDrive 文件夹，复制路径：\nC:\\Users\\用户名\\OneDrive\n第二步\n打开需要添加同步的本地文件夹，复制路径：\nD:\\Personal\\OneNote备份\n第三步\n以管理员权限运行 cmd，“备份同步” 为要创建的文件夹：\n1mklink /d C:\\Users\\用户名\\OneDrive\\备份同步 D:\\Personal\\OneNote备份\n参考\n如何利用OneDrive同步任意文件夹？\n","plink":"https://zinki.github.io/2020/11/27/Onedrive如何备份/"},{"title":"SSH超时问题","date":"2020-10-20T02:00:00.000Z","date_formatted":{"ll":"2020年10月20日","L":"2020/10/20","MM-DD":"10-20"},"updated":"2024-10-10T08:03:05.457Z","content":"新电脑提交github时报超时，本来以为公司网络问题，经过查询得知可以切换端口解决\n12$ ssh -t git@github.comssh: connect to host github.com port 22: Connection timed out\n测试端口可用性\n12$ ssh -T -p 443 git@ssh.github.comConnection reset by 20.205.243.160 port 443\n可行的话编辑 ~/.ssh/config文件\n123Host github.comHostname ssh.github.comPort 443\n事实证明确实是公司防火墙导致，没办法，只能切换成https方式push\n注：\ngithub在2021.8.13移除了密码认证的支持，建议使用personal access token代替密码认证\n###参考\nUsing SSH over the HTTPS port\n","plink":"https://zinki.github.io/2020/10/20/SSH超时问题/"},{"title":"Spring事件监听机制","date":"2020-09-10T02:11:00.000Z","date_formatted":{"ll":"2020年9月10日","L":"2020/09/10","MM-DD":"09-10"},"updated":"2024-10-10T08:03:05.459Z","content":"使用 @TransactionalEventListener 结合 Spring事件监听机制可以实现触发时间效果 \n在项目中，往往需要执行数据库操作后，发送消息或事件来异步调用其他组件执行相应的操作，例如：\n用户注册后发送激活码；\n但是，数据库的操作如果还未完成，此时异步调用的方法查询数据库发现没有数据，这就会出现问题。\n为了解决上述问题，Spring为我们提供了两种方式：\n\n@TransactionalEventListener注解\n事务同步管理器TransactionSynchronizationManager\n以便我们可以在事务提交后再触发某一事件\n\n@TransactionalEventListener底层也是这样实现的\n","plink":"https://zinki.github.io/2020/09/10/Spring事件监听机制/"},{"title":"文件名乱码问题解决","date":"2020-07-20T02:10:00.000Z","date_formatted":{"ll":"2020年7月20日","L":"2020/07/20","MM-DD":"07-20"},"updated":"2024-10-10T08:03:05.472Z","content":"低版本SpringMvc有个问题可能导致文件名乱码，即FormHttpMessageConverter内部对文件名解析使用US-ASCII且写死\n1234567private byte[] getAsciiBytes(String name) &#123;    try &#123;        return name.getBytes(&quot;US-ASCII&quot;);    &#125; catch (UnsupportedEncodingException var3) &#123;        throw new IllegalStateException(var3);    &#125;&#125;\n具体做法:\n1234567891011121314@Beanpublic MyFormHttpMessageConverter converter() &#123;    return new MyFormHttpMessageConverter();&#125;List&lt;HttpMessageConverter&lt;?&gt;&gt; newList = new ArrayList&lt;&gt;();for (HttpMessageConverter&lt;?&gt; httpMessageConverter : list) &#123;    if(httpMessageConverter instanceof FormHttpMessageConverter) &#123;        newList.add(converter());    &#125;else &#123;        newList.add(httpMessageConverter);    &#125;&#125;restTemplate.setMessageConverters(newList);","plink":"https://zinki.github.io/2020/07/20/文件名乱码问题解决/"},{"title":"Java集合相关","date":"2020-06-11T11:50:00.000Z","date_formatted":{"ll":"2020年6月11日","L":"2020/06/11","MM-DD":"06-11"},"updated":"2024-10-11T08:00:23.879Z","content":"Java集合框架主要包括两种类型的容器，一种是集合（Collection），存储元素集合，另一种是图（Map），存储键/值对映射。\nJava集合介绍\nJava的所有集合类都位于 java.util 包，其中提供了一个表示和操作对象集合的统一构架，包含大量集合接口，以及这些接口的实现类和操作它们的算法。\nJava集合可以分为：\n\nSet：代表无序、不可重复\nList：代表有序、重复的集合\nQueue：代表一种队列集合实现\nMap：代表具有映射关系的集合\n\njava集合体系间的继承关系\nJava集合主要有两个接口派生而出：Collection和Map，这个两个接口是Java集合框架的根接口。\nHashSet、TreeSet、ArrayList、LinkedList是经常用到的实现类\n\nHashMap、TreeMap是经常用到的实现类\n\n问题\n\nArrays.asList生成的list增删数据会报异常\n\n123Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException    at java.util.AbstractList.add(AbstractList.java:148)    at com.design.test.Main.main(Main.java:15)\n出现这个异常的原因是通过Arrays.asList转换数组生成的ArrayList和java.util.ArrayList不一样，它是定义在Arrays里面，和java.util.ArrayList都是继承并实现了AbstractList抽象类。\n123456private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;    implements RandomAccess, java.io.Serializable&#123;    private static final long serialVersionUID = -2764017481108945198L;    private final E[] a;&#125;\n不同的是Arrays.asList生成的ArrayList并没有重写AbstractList的add,remove等方法，所以调用add,remove等方法时会报错\n解决方法是重新构造一个java.util.ArrayList或者是LinkedList\n1234public static void main(String[] args) &#123;        String[] array = new String[]&#123;&quot;1&quot;, &quot;2&quot;&#125;;        List&lt;String&gt; list =  new ArrayList&lt;&gt;(Arrays.asList(array));&#125;\n\nfail-fast\n所谓快速失败就是在并发集合中，其进行迭代操作时，若有其他线程对其进行结构性的修改，这时迭代器会立马感知到，并且立即抛出ConcurrentModificationException异常，而不是等到迭代完成之后才告诉你\n\n参考\nJava集合\n","plink":"https://zinki.github.io/2020/06/11/Java集合相关/"},{"title":"接口慢查询分析","date":"2020-05-15T09:10:00.000Z","date_formatted":{"ll":"2020年5月15日","L":"2020/05/15","MM-DD":"05-15"},"updated":"2024-10-11T08:04:10.712Z","content":"线上页面打不开定位到接口内一条慢SQL，经过优化得到接口本地测试响应时间90秒，放到UAT环境测试还是打不开\n通过show processlist命令看到SQL执行过程中会不断发起新的查询\n\n查询日志可以看出在过六七十秒后会重新请求接口\n经Google得到可能是Nginx的问题\n浏览器的Http请求重发机制\n123  server &#123;   send_timeout 60s;&#125;\n由上图可以看出两次请求间隔确实是60秒，所以是Nginx的问题。\n至于接口优化方面，尝试过SQL优化和程序优化两种方式，SQL优化不太可行，程序优化方向中发现查询前面数据集很快，选择把WHERE条件在程序中过滤，整体响应时间缩短到90秒左右，忽略掉查询结果到内存的时间，实际差不多有80秒耗费在程序IO上了。\n\n后来让大佬看过之后，同样选择程序优化，只是把中间过滤条件单独拉出来查询，同样的条件只耗时6秒多\n\n\n由此可以得出：\n1. IO和SQL优化同样重要，优化中应尽量杜绝大批量数据的IO操作\n2. 查询条件尽可能将范围收窄\n\n","plink":"https://zinki.github.io/2020/05/15/接口慢查询分析/"},{"title":"Service Mesh浅析","date":"2020-02-06T09:20:00.000Z","date_formatted":{"ll":"2020年2月6日","L":"2020/02/06","MM-DD":"02-06"},"updated":"2024-10-11T08:02:28.182Z","content":"服务网格是一个用于处理服务间通信的基础设施层。服务网格保证请求在云原生应用组成的复杂服务拓扑中可靠地传递。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成，它们与应用程序部署在一起，但对应用程序透明。\n\n微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。\n\nService Mesh定义\nService Mesh功能在于处理服务间通信，职责是实现请求的可靠传递。在实践中，Service Mesh通常由服务与轻量级网络代理（Sidecar，与服务部署在一起）组合而成.Sidecar中文翻译为边车，它在原有的客户端和服务端之间加了一个代理，但对应用程序透明。如下图所示为两个微服务之间通过Sidecar互相调用的情形：\n\n当微服务（Service）集群扩大到一定规模后，就会形成网格状（Mesh），即形成了Service Mesh形态：\n\nService Mesh会接管整个网络，在服务之间转发所有的请求。在这种情况下，业务服务不再负责处理请求的具体逻辑，只负责完成业务处理。服务间通讯的环节就从服务里面剥离出来，呈现出一个抽象的基础设施层。对应的服务间通讯相关的治理功能，如流量路由（根据权重或参数分流、负载均衡、黑白名单）、流量治理（熔断、限流、容错）、请求认证鉴权、调用拓扑等均在下沉的Service Mesh层实现，微服务研发者专注于业务研发本身即可。\n容器化与Service Mesh\n在基于Envoy+Istio方案中， 容器化是Service Mesh高效落地的基础。容器化+Kubernetes编排不仅为微服务本身带来灵活部署调度、扩缩容、高可用等诸多能力，对Service Mesh架构下Sidecar注入、生命周期管理、流量拦截、安全管理等也提供了十分重要的特性。简而言之，容器化与Service Mesh具备天生的亲和性。\nService Mesh架构本身并未限定业务微服务本身必须容器化,但 从微服务业务长期规划、Service Mesh核心价值最大化、压缩迁移成本等方面考虑，容器化+Service Mesh一定是微服务业务演进的重要方向。\n注册中心的选择\n在基于Envoy+Istio方案下， Kubernetes基于ETCD的注册中心机制是社区注册中心的默认方案。对于其他注册中心，可以通过Istio的MCP机制接入（Consul、Eureka、ZooKeeper等）。\n值得注意的是，Service Mesh架构下服务注册、发现与传统服务框架存在较大差异：\n传统服务框架下，微服务的注册通常通过服务框架SDK将微服务注册到注册中心，通过SDK中的发现方法从注册中心发现服务与实例列表，即 通过客户端SDK完成注册发现。\n在Service Mesh架构下，控制面组件（如Istio Pilot）负责对接注册中心。服务在创建Kubernetes Service、Deployment时会完成自动注册；服务的发现则是由控制面组件拉取或监听注册中心，将获取到的服务与实例信息转换为统一服务模型，再通过GRPC推送到Sidecar，这样Sidecar就获取到了服务与实例信息，即 通过控制面组件完成服务发现。通过控制面组件完成服务发现模式下，控制面组件可以通过实现不同注册中心的适配器，同时获取多种注册中心的服务与实例信息，即 可实现多注册中心服务的互相发现。示意图如下：\n\n虽然Istio Pilot提供了对接多种注册中心能力， Kubernetes基于ETCD的注册中心机制依然是推荐的容器化+Service Mesh下的注册中心选择。原因不仅是这是Kubernetes的原生机制，能力完整性与健壮性强，在实践过程中，通过MCP机制实现各注册中心的对接并不像想象那样平滑：控制面组件对注册中心进行定时拉取或监听，对于不同注册中心会选择不同的策略：如果对接的注册中心没有提供增量式拉取获取监听的机制，控制面组件每次对注册中心全局的信息获取会是巨大的压力\n参考\n微服务实践：我们离Service Mesh还有多远\n","plink":"https://zinki.github.io/2020/02/06/Service Mesh浅析/"},{"title":"B树和B+树","date":"2020-01-12T09:20:00.000Z","date_formatted":{"ll":"2020年1月12日","L":"2020/01/12","MM-DD":"01-12"},"updated":"2024-10-10T08:03:05.438Z","content":"我们都知道二叉查找树的查找的时间复杂度是Ｏ(log N),其查找效率已经足够高了，那为什么还有Ｂ树和Ｂ＋树的出现呢？难道它两的时间复杂度比二叉查找树还小吗？\n答案当然不是，Ｂ树和Ｂ＋树的出现是因为另外一个问题，那就是磁盘IO；众所周知，IO操作的效率很低，那么，当在大量数据存储中，查询时我们不能一下子将所有数据加载到内存中，只能逐一加载磁盘页，每个磁盘页对应树的节点。造成大量磁盘IO操作（最坏情况下为树的高度）。平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。\n所以，我们为了减少磁盘IO的次数，就你必须降低树的深度，将“瘦高”的树变得“矮胖”。一个基本的想法就是：\n\n每个节点存储多个元素\n摒弃二叉树结构，采用多叉树\n\n这样就引出来了一个新的查找树结构–多路查找树。 根据AVL给我们的启发，一颗平衡多路查找树(B-树)自然可以使得数据的查找效率保证在O(logN)这样的对数级别上.\n一个m阶的B树具有如下几个特征：B树中所有结点的孩子结点最大值称为B树的阶，通常用m表示。一个结点有k个孩子时，必有k-1个关键字才能将子树中所有关键字划分为k个子集。\n123451. 根结点至少有两个子女。2. 每个中间节点都包含k-1个元素和k个孩子，其中 ceil（m/2） ≤ k ≤ m3. 每一个叶子节点都包含k-1个元素，其中 ceil（m/2） ≤ k ≤ m4. 所有的叶子结点都位于同一层。5. 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域划分\nB+树是B树的变种，有着比B树更高的查询效率。一个m阶的B+树具有如下几个特征：\n123451. 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。2. 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。3. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。\n\n所谓卫星数据，指的是索引元素所指向的数据记录，比如数据库的某一行。在B树中，无论中间节点还是叶子节点都带有卫星数据。\n\nB+树优势\n\n单一节点存储更多的元素（这样该节点下分支变多了，树变矮胖了），使得查询的IO次数更少。\n所有查询都要查找到叶子节点，查询性能稳定。\n所有叶子节点形成有序链表，便于范围查询。\n\nB+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。\n为了克服B+树的弱点，HBase引入了LSM树的概念，即Log-Structured Merge-Trees。\nLSM树本质上就是在读写之间取得平衡，和B+树相比，它牺牲了部分读性能，用来大幅提高写性能。\n它的原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的\n\n注:(批处理是应对内存碎片化的有效方案,也可以大幅提升插入效率,但对于查询和数据处理不是很友好,只能在读写性能之间取一个平衡)\n\n极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。\n参考\n简单剖析B树（B-Tree）与Ｂ+树\n","plink":"https://zinki.github.io/2020/01/12/B树和B+树/"},{"title":"OOP-KLASS二分模型","date":"2019-12-10T05:10:00.000Z","date_formatted":{"ll":"2019年12月10日","L":"2019/12/10","MM-DD":"12-10"},"updated":"2024-10-10T08:03:05.454Z","content":"HotSpot是基于c++实现，而c++是一门面向对象的语言，本身具备面向对象基本特征，所以Java中的对象表示，最简单的做法是为每个Java类生成一个c++类与之对应。\n但HotSpot JVM并没有这么做，而是设计了一个OOP-Klass Model。这里的 OOP 指的是 Ordinary Object Pointer （普通对象指针），它用来表示对象的实例信息，看起来像个指针实际上是藏在指针里的对象。而 Klass 则包含元数据和方法信息，用来描述Java类。\n之所以采用这个模型是因为HotSopt JVM的设计者不想让每个对象中都含有一个vtable（虚函数表），所以就把对象模型拆成klass和oop，其中oop中不含有任何虚函数，而Klass就含有虚函数表，可以进行method dispatch。\nOOP-Klass 模型是对象在JVM中的表示\n\nOOP\nKlass是在class文件在加载过程中创建的，OOP则是在Java程序运行过程中new对象时创建的。\n\n一个OOP对象包含以下几个部分：\n\ninstanceOopDesc，也叫对象头\n\n\n\nMark Word，主要存储对象运行时记录信息，如hashcode, GC分代年龄，锁状态标志，线程ID，时间戳等\n元数据指针，即指向方法区的instanceKlass实例\n\n\n\n实例数据\n\n\nKlass\nKlass简单的说是Java类在HotSpot中的c++对等体，用来描述Java类。\n\nKlass主要有两个功能：\n\n实现语言层面的Java类\n实现Java对象的分发功能\n\n那Klass是什么时候创建的呢？\n一般jvm在加载class文件时，会在方法区创建instanceKlass，表示其元数据，包括常量池、字段、方法等。\n当 C、 C++和 Delphi 等程序被编译成二进制程序后 , 原来所定义的高级数据结构都不复存在了 , 当Windows/Linux等操作系统 (宿主机) 加载这些二进制程序时, 是不会加载这些语言中所定义的高级数据结构的 宿主机压根儿就不知道原来定义了哪些数据结构 哪此类所有的数据结构都被转换为对特定内存段偏移地址. 例如 C 中的 struct结构体, 被编译后不复存在, 汇编和机器语言中没有与之对应的数据结构的概念, CPU 更不知道何为结构体. C++和Delphi 中的类概念被编后也不复存在, 所谓的类最终变成内存首地址. 而 JVM虚拟机在加载字节码程序时, 会记录字节码中所定义的所有类型的原始信息 (元数据), JVM知道程序中包含了哪些类, 以及每个类中所关联的字段、方法、类等信息.这是 JVM虚拟机与操作系统最大的区别所在\nJVM最终就自然而然地演化出了OOP-KLASS 这种二分模型, KLASS 用于保存类元信息, 而 OOP 用于表示 JVM所创建的类实例对象口 KLASS 信息被保存在 PERM 永久区, 而 OOP则被分配在 HEAP 堆区.同时 JVM为了支持反射等技术, 必须在 OOP 中保存一个指针, 用于指向其所属的类型KLASS, 这样Java开发者便能够基于反射技术, 在 Java 程序运行期获取 Java 的类型信息\n参考\n揭秘Java虚拟机\n对象在jvm中的表示：OOP-Klass模型\n","plink":"https://zinki.github.io/2019/12/10/OOP-KLASS二分模型/"},{"title":"大数据日知录笔记","date":"2019-11-16T02:10:00.000Z","date_formatted":{"ll":"2019年11月16日","L":"2019/11/16","MM-DD":"11-16"},"updated":"2024-10-11T08:03:47.053Z","content":"\n\n硬件成本的快速下降,使得电子设备的无处不在成为可能,数据无处不在,无时不在.\nIBM用3V(Volume,Velocity,Variety)来描述大数据的特点,后来又增加了Value这个维度,即价值密度低的数据成为大数据,需要从低价值的原始海量数据中进行深度挖掘和计算,总结出具有高价值的数据.\nCAP/ACID/BASE三者的关系\nACID和BASE原则是在明确提出CAP理论之前关于如何对待可用性和强一致性的两种完全不同的设计哲学.ACID更强调数据一致性,这是传统数据库设计思路.而BASE更强调可用性,弱化数据强一致性的概念,这是互联网时代对于大规模分布式数据系统的一种需求,尤其是其中的软状态和最终一致性,这两者是在容忍分区情形下强调可用性的具体手段.\n布隆过滤器是由Howard Bloom在1970年提出的二进制向量数据结构,具有很好的空间和时间效率,尤其是空间效率极高,经常用于检测某个元素是否在巨量数据集合中的成员.\nBF可以高效地表征集合数据. 其使用长度为m的位数组来存储集合信息. 同时使用k个相互独立的哈希函数将数据映射到位数组空间.\n其基本思想如下:首先将长度为m的位数组元素全部置为0 对于集合S中的某个成员a,分别使k个哈希函数对其计算. 如果\n\n则将位数组的第x位置为1,对于成员a来说, 经过k个哈希函数计算后. 可能会将位数组中的W\n位(w&lt;=k)设置为1.对于集合中的其他成员也如此处理,这样即可完成位数组空间的集合表示\n算法流程如下:\n\n因为BF使用位数组和哈希函数来表征集合. 并不需要实际存储集合数据本身内容,所以空间利用率非常高. 但是有个潜在问题. 即在查询某个成员是否属于集合时,会发生误判(False Resitive)\nSkipList由Wil1iam Pugh于1990年提出,这是一种可替代平衡树的数据结构.不像平衡树需要强制保持树的平衡. SkipList 依靠随机生成数以一定概率来保持数据的平衡分布。 尽管在最坏情况下skipList的效率要低于平衡树. 但是大多数情况下其效率仍然常,其插入、删除、查找数据的时间复杂度都是O(log(N)).\nLSM树(Log-structured Merge-tree)的本质是将大量的随机写操作转换成批量的序列写. 这样可以极大地提升磁盘数据写入速度, 所以LSM树非常适合对写操作效率有高要求的应用场景.但是其对应付出的代价是读效率有所降低. 这往往可以引入Bloom Filter或者缓存等优化措施来 对读性能进行改善.\nMerkle哈希树由Ralph Merkle于l979年发音 . 因故得此名.一般还将其称为Merkle树或哈\n希树(Hash Tree). Merkle树最初用于高效Lamport签名验证.后来被广泛应用在分布式领域,主要用来在海量数据下快速定位少量变化的数据内容(变化原因可能是损毁、篡改或正常变化.\n比特币也引用了Merkle树对交易进行验证.\nSnappy是Google开源出的高效数据压缩与解压缩算法库, 其目标并非是最高的数据压缩率, 而\n是在合理的的压缩率基础上追求尽可能快的压缩和解压缩速度, 其压缩和解压缩速度极快, 可以在单核处埋器上达到250MB/S的压缩效率和500MB/s的解压缩效率。与此同时,snappy相比其他压缩方案占用CPU时间更少.\n数据压缩与解压缩本质上是通过增加CPU计算时间成本采换取较小的存储成本以及网络和I/O传输成本.如果只是追求存储成本最小化.Snappy这种技术方案是不适用的, 但是对于很多情形,\n在合理压缩率情况下追求最高的压缩和解压缩速度比单纯追求最小的存储成本更重要。\n与霍夫曼编码这种统计编码不同, LZ77是一种动态词典编码 (Dictionary Coding). 词典编码的基本思路是: 文本中的词用它在词典中表示位置的号码代替的无损数据压缩方法, 一般分为静态词典方法和动态词典方法两种\nKafka通过消息副本机制提供了高可用的消息服务，其副本管理单位不是Topic消息队列，而是Topic的数据分片（Partition）。在配置文件里可以指定数据分片的副本个数，在多个副本里，其中一个作为主副本（Leader），其他作为次级副本（Slave）。所以针对这个数据分片的消息读/写请求都由主副本负责响应，次级副本只是以主副本数据消费者的方式从主副本同步数据；当主副本发生故障时，Kafka将其中某个次级副本提升为主副本，以此来达到整个消息系统的高可用性。\nKafka未使用类似Zab或Paxos协议的多数投票机制来保证主备数据的一致性，而是提出一种称为ISR（In-Sync Replicas）的机制保证数据一致性。原因是如果副本个数是2f+1，那么多数投票机制最多允许f歌副本发生故障，即如果需要1个副本容错，至少要保持3个数据副本，如果需要2个副本容错，至少要维护5个数据副本。考虑到消息系统的应用场景，只允许1个副本容错过于脆弱，至少要支持2个副本容错，即至少要维护5个数据副本，效率太低。\nISR的运行机制如下：将所有次级副本数据分到两个集合，其中一个被称为ISR集合，这个集合备份数据的特点是即时和主副本数据保持一致，而另外一个备份数据允许其消息队列落后于主副本的数据。在做主备切换时，只允许从ISR集合中选择候选主副本，这样可保证切换后新的主副本数据状态和老的主副本保持一致。在数据分片进行消息写入时，只有ISR集合内所有备份都写成功才能认为这次写入操作成功。在具体实现时，Kafka利用Zookeeper来保存每个ISR集合的信息，当ISR集合内成员变化时，相关构件也便于通知。通过这种方式，如果设定ISR集合大小为f+1，那么最多可允许f个副本故障。\n使用磁盘读/写根本且普适的原则是：尽可能避免随机读/写，同时尽可能利用顺序读/写，即连续读/写整块数据。\nKafka高效处理大批量消息的重要原因是将读/写操作尽可能转换为顺序读/写，比如类似于Log文件方式的文件尾部追加写。另外，Kafka涉及将文件内容通过网络进行传输，为提升效率，Kafka采用Linux操作系统的SendFile调用。为了避免多次数据复制，操作系统可以直接将数据从内核页缓存中复制到网卡缓存，这样可以加大整个过程的速度。\n分布式系统中一个重要的研究内容是如何将数据通知到网络中的多个接收方，一般称为多传播通信。\nGossip原意是谣言或小道消息，Gossip协议被称为感染协议（Epidemic Protocol）。\nGossip协议用来尽快将本地更新数据通知到网络中的所有其他节点，更新模型可分为3种：\n全部通知模型，反熵模型，散布谣言模型。\nGFS在实际存储时首先会将不同大小的文件切割成固定大小的数据块，每一块称称为一个Chunk，通常设定大小为64MB。\n\nGFS系统化内部需要维护文件名称到其对应的多个Chunk之间的映射关系，Chunk服务器负责对Chunk的实际存储，同时响应GFS客户端对自己负责的Chunk的读/写操作。\n\nGoogle的云存储平台有个显著的特点，就是大量采用主从结构，即单一的主控服务器和众多的存储服务器，主控服务器主要从事系统元数据存储管理及整个分布式系统的管理，比如负载均衡，数据在存储服务器之间迁移，检测新加入的机器及失效机器等工作。\n采用主从结构的好处是整个系统存在一个全局的主控节点，管理相对简单，缺点是因为主控节点是唯一的，很多服务请求都需经过主控服务器，很容易称为整个系统的瓶颈，另外，存在单点失效问题，如果主控服务器瘫痪，整个系统不可用。\n为了增加存储系统的可靠性和数据的可用性，经常使用数据备份来达到这一点，通常的做法是对数据做3备份，但数据备份带来的缺点是增加存储成本。常见的解决方案是对于热点数据，在大规模存储系统中仍然保留3个备份，对于冷数据，只保留1分数据，通过纠删码保证数据的可靠性。\n纠删码通过对原始数据进行校验并保留校验数据，以增加冗余的方式保证数据的可恢复性。极大距离可分码（Maximum Distance Separable Codes，MDS）是一种常用的纠删码，其将数据文件切割为等长的n个数据块，并根据这n个数据块生成m个冗余的校验信息，使得n+m块数据中即使任意m块数据损失，也可通过剩下n块数据对m块损失的数据进行重构，以此俩完成数据容错功能。\n和传统的MMP架构（并行数据库系统）相比，MapReduce更适合非结构化数据的ETL处理累操作，且其可拓展性及容错性明显占优，但单机处理效率低。尽管MR提供了简洁的API和完善的容错处理机制，使得大规模兵法处理海量数据称为可能，但从发展趋势看，相对复杂的任务转换为MR任务开发效率不够高，所以有逐步封装到下层的趋势，即在上层系统提供更简洁的API，在底层由系统自动转换为大量MR任务。\nDAG是有向无环图（Directed Acyclic Graph）的简称。在大数据处理中，DAG计算常常指的是将计算任务在内部分解成为若干个子任务，将这些子任务之间的逻辑关系或顺序构建成DAG（有向无环图）结构。DAG计算模型可以认为是对MR计算机制的一种拓展。\nHive是Facebook设计并开源的构建在Hadoop基础之上额度数据仓库解决方案，与传统数据仓库相比，Hive能处理超大规模的数据且有更好的容错性。Hive的本质思想是为Hadoop存储的数据增加模式（schema），并为用户提供sql语言，Hive将类sql语言转换为一系列MR任务来实现数据的处理，以此手段达到便利操作数据仓库的目的。\nHive的缺点是查询处理效率较低，是MR固有的一些特性导致的，主要是因为Hive和Hadoop绑定关系太紧密导致的。\n机器学习的目的是从数据中自动习得模型，对未知数据进行预测，近期学习的任务是从数据中学习决策函数fx–&gt;y，这个决策函数将输入变量x映射到输出空间的输出变量y中，即根据输入产生预测。\n参考\n大数据日知录\n","plink":"https://zinki.github.io/2019/11/16/大数据日知录笔记/"},{"title":"数据库相关知识","date":"2019-10-05T09:10:00.000Z","date_formatted":{"ll":"2019年10月5日","L":"2019/10/05","MM-DD":"10-05"},"updated":"2024-10-11T08:05:00.259Z","content":"SQL标准中规定的RR并不能消除幻读，但是MySQL的RR可以，靠的就是next-key lock，而next-key lock区别于普通行锁的核心，就是GAP锁。\nNext-Key锁由行锁 + Gap锁组成。\nGAP(间隙)锁的中心思想，就是不仅对第一次查询查出来的记录加锁，而且对查询条件这个范围加锁，从而避免了幻读。\n间隙锁是对索引记录中的一段连续区域的锁；当使用类似 SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE; 的 SQL 语句时，就会阻止其他事务向表中插入 id = 15 的记录，因为整个范围都被间隙锁锁定了。\nInnodb的实现方式是：\n\n事务以排他锁的形式修改原始数据\n把修改前的数据存放于undo log，通过回滚指针与主数据关联\n修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）\n\nInnoDB的MVCC,是通过在每行记录后面保存两个隐藏的列来实现的,这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值,而是系统版本号(可以理解为事务的ID)，每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID.\n理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。\n既然 InnoDB 中实现的锁是悲观的，那么不同事务之间就可能会互相等待对方释放锁造成死锁，最终导致事务发生错误；想要在 MySQL 中制造死锁的问题其实非常容易\n\nInnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务\n概括来讲，SQL的游标是一种临时的数据库对象，即可以用来存放在数据库表中的数据行副本，也可以指向存储在数据库中的数据行的指针。游标提供了在逐行的基础上操作表中数据的方法。\n游标的一个常见用途就是保存查询结果，以便以后使用。游标的结果集是由SELECT语句产生，如果处理过程需要重复使用一个记录集，那么创建一次游标而重复使用若干次，比重复查询数据库要快的多。\n数据量大的时候，尽量避免使用游标，游标使用时会对行加锁，可能会影响其他业务的正常进行。而且，数据量大时其效率也较低效。另外，内存也是其中一个限制。因为游标其实是相当于把磁盘数据整体放入了内存中，如果游标数据量大则会造成内存不足。\n\n对于复合索引,在查询使用时,最好将条件顺序按找索引的顺序,这样效率最高;\nselect * from table1 where col1=A AND col2=B AND col3=D\n如果使用 where col2=B AND col1=A 或者 where col2=B 将不会使用索引\n何时是用复合索引\n根据where条件建索引是极其重要的一个原则;\n注意不要过多用索引,否则对表更新的效率有很大的影响,因为在操作表的时候要化大量时间花在创建索引中\n复合索引会替代单一索引么\n如果索引满足窄索引的情况下可以建立复合索引,这样可以节约空间和时间\n\n解析器按照从右到左的顺序处理FROM子句中的表名，FROM子句中写在最后的表(基础表 driving table)将被最先处理，在FROM子句中包含多个表的情况下,你必须选择记录条数最少的表作为基础表。如果有3个以上的表连接查询, 那就需要选择交叉表(intersection table)作为基础表, 交叉表是指那个被其他表所引用的表。\nWHERE子句中的连接顺序：\n采用自下而上的顺序解析WHERE子句,根据这个原理,表之间的连接必须写在其他WHERE条件之前,那些可以过滤掉最大数量记录的条件必须写在WHERE子句的末尾\nmybatis缓存机制\n一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效\n二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。\n参考\n浅入浅出MySQ和InnoDB\n","plink":"https://zinki.github.io/2019/10/05/数据库相关知识/"},{"title":"class文件基本结构","date":"2019-09-11T13:00:00.000Z","date_formatted":{"ll":"2019年9月11日","L":"2019/09/11","MM-DD":"09-11"},"updated":"2024-10-10T08:03:05.462Z","content":"构成class文件的基本数据单位是字节，可以把整个class文件当成一个字节流来处理。稍大一些的数据由连续多个字节构成，这些数据在class文件中以大端（big-endian）方式存储。为了描述class文件格式，Java虚拟机规范定义了u1、u2和u4三种数据类型来表示1、2和4字节无符号整数\n\nclass文件以8字节为基本单位来进行存储，中间没有任何分隔符；\n\n\n当数据项需要占用的空间大于8字节时，会按照高位在前的方式来进行分割；\n\n\nclass文件只有两种数据类型：无符号数、表；\n\n\n无符号数属于基本数据类型，以u1、u2、u4、u8分别代表1个字节、2个字节、4个字节和8个字节的无符号数；\n\n\n表是由多个无符号数或者其它表作为数据项构成的符合数据类型，表名习惯性都以_info 结尾\n\nclass文件中相同类型的多条数据一般按表（table）的形式存储（包括接下来要讲的常量池，属性表，接口索引集合，字段表集合，方法表集合）,表由表头和表项（item）构成，表头是 u2 或 u4 整数。假设表头是 n，后面就紧跟着 n 个表项数据。\nclass文件的结构描述:\n123456789101112131415161718ClassFile &#123;  u4 magic;    //魔数  u2 minor_version;    //次版本号  u2 major_version;    //主版本号  u2 constant_pool_count;    //常量池大小  cp_info constant_pool[constant_pool_count-1]; //常量池  u2 access_flags;    //类访问标志,表明class文件定义的是类还是接口，访问级别是public还是private，等  u2 this_class;    //  u2 super_class;    //  u2 interfaces_count;    //本类实现的接口数量  u2 interfaces[interfaces_count];    //实现的接口,存放在数组中  u2 fields_count;        //本来中含有字段数  field_info fields[fields_count];    //数组中存放这各个字段  u2 methods_count;        //本类中含有的方法数  method_info methods[methods_count];    //数组中存放着各个方法  u2 attributes_count;            //本类中含有的属性数量;  attribute_info attributes[attributes_count];    //数组中存放着各个属性&#125;\n很多文件格式都会规定满足该格式的文件必须以某几个固定字节开头，这几个字节主要起标识作用，叫作魔数（magic number）。例如 PDF 文件以 4 字节“%PDF”（0x25、0x50、0x44、0x46）开头，ZIP 文件以 2 字节“PK”（0x50、0x4B）开头。class 文件的魔数是“0xCAFEBABE”。\n参考\nHow do you crash a JVM?\n","plink":"https://zinki.github.io/2019/09/11/class文件基本结构/"},{"title":"Int绝对值问题","date":"2019-08-29T10:00:00.000Z","date_formatted":{"ll":"2019年8月29日","L":"2019/08/29","MM-DD":"08-29"},"updated":"2024-10-10T08:03:05.462Z","content":"刷题用到Math.abs()，提交报错了，输入-2147483648时运行异常，检查了下取绝对值后还是原值，尝试取负值也一样\nMath实现源码如下：\n123public static int abs(int a) &#123;    return (a &lt; 0) ? -a : a;&#125;\nint的范围是Integer.MIN_VALUE（-2^31）到Integer.MAX_VALUE（2^31-1）\n-2147483648的绝对值应该是2147483648,但是int类型最大值就是232-1为2147483647\n\n在二进制里，是用0和1来表示正负的，最高位为符号位，最高位为1代表负数，最高位为0代表正数。\n\nJava中32位的int\n最大值为：2147483647， 二进制： 01111111111111111111111111111111\n最小值为：-2147483648，二进制： 10000000000000000000000000000000\n而二进制正负转换的方式是反码+1，反码就是正码的所有位数的0和1对换。\n-2147483648的二进制正码：10000000000000000000000000000000\n-2147483648的二进制反码：01111111111111111111111111111111\n-2147483648的二进制反码+1：10000000000000000000000000000000\n所以绕回来了。\n解决这个问题的办法就是转成Long类型计算\n","plink":"https://zinki.github.io/2019/08/29/int绝对值问题/"},{"title":"HashMap初始化容量","date":"2019-07-30T13:00:00.000Z","date_formatted":{"ll":"2019年7月30日","L":"2019/07/30","MM-DD":"07-30"},"updated":"2024-10-10T08:03:05.444Z","content":"HashMap初始化容量为2的次幂\nhashMap源码获取元素的位置：\n1234static int indexFor(int h, int length) &#123;    // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;;    return h &amp; (length-1);&#125;\n解释：\n\nh:为插入元素的hashcode\n\n\nlength:为map的容量大小\n\n\n&amp;：与操作 比如 1101 &amp; 1011=1001\n\n如果length为2的次幂  则length-1 转化为二进制必定是11111……的形式，在于h的二进制与操作效率会非常的快，\n而且空间不浪费；\n如果length不是2的次幂，比如length为15，则length-1为14，对应的二进制为1110，在于h与操作，最后一位都为0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！这样就会造成空间的浪费\n","plink":"https://zinki.github.io/2019/07/30/HashMap初始化容量/"},{"title":"如何实现分布式锁","date":"2019-07-05T02:00:00.000Z","date_formatted":{"ll":"2019年7月5日","L":"2019/07/05","MM-DD":"07-05"},"updated":"2024-10-10T08:03:05.466Z","content":"在分布式定时任务实现原理中最重要的就是分布式锁，而分布式锁是控制分布式系统之间同步访问共享资源的一种方式，在分布式系统中常常需要协调它们的动作。如果在不同的系统或者同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下便需要用到分布式锁。\n分布式锁有3种实现方式，如下所述。\n\n\n基于数据库的实现方式\n该实现方式完全依靠数据库的唯一索引来实现， 当想要获得锁时，便向数据库中插入一条记录，成功插入则获得锁，执行完成后删除对应的行数据来释放锁。\n\n\n基于Redis的实现方式\n这基于Redis的setnx命令实现的，当缓存里的key不存在时，才会设置成功,并且返回true,否则直接返回false。如果返回true,则表示获取到了锁，否则获取锁失败。为了防止死锁，我们再使用expire命令对这个key设置一个超时时间。\n\n\n12345678910111213141516171819202122232425262728293031323334@Aspect@Component@Slf4jpublic class RepeatSubmitAspect &#123;    @Autowired    private RedisUtils redisUtils;    @Pointcut(&quot;@annotation(noRepeatSubmit)&quot;)    public void pointCut(NoRepeatSubmit noRepeatSubmit) &#123;    &#125;    @Around(&quot;pointCut(noRepeatSubmit)&quot;)    public Object around(ProceedingJoinPoint pjp, NoRepeatSubmit noRepeatSubmit) throws Throwable &#123;        log.info(&quot;请求参数,&#123;&#125;&quot;,JSON.toJSONString(pjp.getArgs()));        Integer lockSeconds = noRepeatSubmit.lockTime();        HttpServletRequest request = RequestUtils.getRequest();        String key = CACHE_PREFIX + request.getServletPath() + BizConstant.COLON + JSON.toJSONString(pjp.getArgs());        Boolean flag = redisUtils.getRedisTemplate().opsForValue().setIfAbsent(key, key, lockSeconds, TimeUnit.SECONDS);        if (flag) &#123;            return pjp.proceed();        &#125; else &#123;            log.error(key, &quot;短时间内不可重复提交&quot;);            throw new RuntimeException(&quot;短时间内不可重复提交&quot;);        &#125;    &#125;&#125;\n\n基于ZooKeeper的实现方式\nZooKeeper是一个为分布式应用提供-致性服务的开源组件，它内部是一一个分层的文件系统目录树结构，规定在同一个目录下只能有一个唯一文件名。 ZooKeeper 的节点有如下几种类型。\n\n\n永久节点:节点创建后，不会因为会话失效而消失。\n\n\n临时节点:与永久节点相反，如果客户端连接失效，则立即删除节点。\n\n\n顺序节点:在指定创建这类节点时，ZooKeeper会自动在节点名后加一个数字后缀，并且是有序的。\n在创建一个节点时，还可以注册一个该节点的监视器(watcher)， 在节点状态发生改变时，监视器会被触发，同时ZooKeeper会向客户端发送一条通知 (仅会发送一次)。\n\n根据ZooKeeper的这些特性，实现分布式锁的步骤如下。\n(1)创建一个锁目录lock。\n(2)如果线程A需要获得锁，就在lock目录下创建临时顺序节点。\n(3)再查询锁目录下所有的子节点，寻找比自己小的兄弟节点，如果不存在，则说明当前线程的顺序号最小，因此可以获得锁。\n(4)线程B如果也想获取锁，则同样需要查询所有节点，判断自己是不是最小的节点，如果不是，则设置监听比自己值小的节点(只关注比自己值小的节点)。\n(5)线程A在处理完后，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是，则获得锁。\n1234567891011121314151617181920public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123;    try &#123;        return interProcessMutex.acquire(timeout, unit);    &#125; catch (Exception e) &#123;        log.error(e.getMessage(), e);    &#125;    return true;&#125;public boolean unlock() &#123;    try &#123;        interProcessMutex.release();    &#125; catch (Throwable e) &#123;        log.error(e.getMessage(), e);    &#125; finally &#123;        executorService.schedule(new Cleaner(client, path),         delayTimeForClean, TimeUnit.MILLISECONDS);    &#125;    return true;&#125;","plink":"https://zinki.github.io/2019/07/05/如何实现分布式锁/"},{"title":"ElasticSearch相关知识","date":"2019-06-15T11:00:00.000Z","date_formatted":{"ll":"2019年6月15日","L":"2019/06/15","MM-DD":"06-15"},"updated":"2024-10-10T08:03:05.442Z","content":"Elasticsearch的核心概念如下：\n\nCluster: 集群，由一个或多个Elasticsearch 节点组成。\n\n\nNode: 节点，组成Elasticsearch集群的服务单元，同一个集群内节点的名字不能重复。通常在一个节点上分配一个或者多个分片。\n\n\nShards: 分片，当索引上的数据量太大的时候，我们通常会将-一个索引.上的数据进行水平拆分，拆分出来的每个数据块叫作-一个分片。 在一个多分片的索引中写入数据时，通过路由来确定具体写入那一一个分片中，所以在创建索引时需要指定分片的数量，并且分片的数量一旦确定就不能更改。分片后的索引带来了规模上(数据水平切分)和性能上(并行执行)的提升。每个分片都是Lucene中的一个索引文件，每个分片必须\n有一个主分片和零到多个副本分片。\n\n\nReplicas: 备份也叫作副本，是指对主分片的备份。主分片和备份分片都可以对外提供查询服务，写操作时先在主分片上完成，然后分发到备份上。当主分片不可用时，会在备份的分片中选举出-一个作为主分片，所以备份不仅可以提升系统的高可用性能，还可以提升搜索时的并发性能。但是若副本太多的话，在写操作时会增加数据同步的负担。\n\n\nIndex: 索引，由一个和多个分片组成，通过索引的名字在集群内进行唯一标识。\n\n\nType: 类别，指索引内部的逻辑分区，通过Type的名字在索引内进行唯一标识。在查询时如果没有该值，则表示在整个索引中查询。\n\n\nDocument: 文档，索引中的每一 条数据叫一个文档，类似于关系型数据库中的-条数据，通过_ id 在Type内进行唯一标识。\n\n\nSettings: 对集群中索引的定义，比如一个索引默认的分片数、副本数等信息。\n\n\nMapping: 类似于关系型数据库中的表结构信息，用于定义索引中字段(Field) 的存储类型、分词方式、是否存储等信息。Elasticsearch 中的mapping是可以动态识别的。如果没有特殊需求，则不需要手动创建mapping,因为Elasticsearch会自动根据数据格式识别它的类型，但是当需要对某些字段添加特殊属性(比如:定义使用其他分词器、是否分词、是否存储等)时，就需要手动设置mapping了。一个索引的mapping一旦创建，若已经存储了数据，就不可修改了。\n\n\nAnalyzer: 字段的分词方式的定义。一个analyzer 通常由一个tokenizer、 零到多个Filter组成。比如默认的标准Analyzer包含一个标准的tokenizer 和三个filter: Standard TokenFilter、Lower Case Token Filter、Stop Token Filter。\n\nElasticsearch的节点的分类如下:\n\n主节点(Master Node):也叫作主节点，主节点负责创建索引、删除索引、分配分片、追踪集群中的节点状态等工作。Elasticsearch 中的主节点的工作量相对较轻。用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而并不需要经过主节点转发。通过在配置文件中设置node.master =true来设置该节点成为候选主节点(但该节点并不一-定是主节点，主节点是集群在候选节点中选举出来的)，在Elasticsearch集群中只有候选节点才有选举权和被选举权。其他节点是不参与选举工作的。\n\n\n数据节点 (Data Node):数据节点，负责数据的存储和相关具体操作，比如索引数据的创建、修改、删除、搜索、聚合。所以，数据节点对机器配置要求比较高，首先需要有足够的磁盘空间来存储数据，其次数据操作对系统CPU、Memory和I/O的性能消耗都很大。通常随着集群的扩大，需要增加更多的数据节点来提高可用性。通过在配置文件中设置node.data=true来设置该节点成为数据节点。\n\n\n客户端节 点(Client Node):就是既不做候选主节点也不做数据节点的节点，只负责请\n求的分发、汇总等，也就是下面要说到的协调节点的角色。其实任何一个节点都可以完成这样的工作，单独增加这样的节点更多地是为了提高并发性。\n可在配置文件中设置该节点成为数据节点:\n\n12node.master =falsenode.data=false\n\n户端节点(Client Node):就是既不做候选主节点也不做数据节点的节点，只负责请求的分发、汇总等，也就是下面要说到的协调节点的角色。其实任何一个节点都可以完成这样的工作，单独增加这样的节点更多地是为了提高并发性。\n可在配置文件中设置该节点成为数据节点:\n\n12node. master =falsenode.data=false\n\n部落节点(Tribe Node):部落节点可以跨越多个集群，它可以接收每个集群的状态，\n然后合并成一个全局集群的状态，它可以读写所有集群节点上的数据，在配置文件中通过如下设置使节点成为部落节点:\n\n12345tribe:    one:        cluster .name:cluster one    two:        cluster. name:cluster two\n因为Tribe Node要在Elasticsearch 7.0以后移除，所以不建议使用。\n\n协调节 点(Coordinating Node): 协调节点，是一种角色，而不是真实的Elasticsearch的节点，我们没有办法通过配置项来配置哪个节点为协调节点。集群中的任何节点都可以充当协调节点的角色。当一个节点A收到用户的查询请求后，会把查询语句分发到其他的节点，然后合并各个节点返回的查询结果，最后返回一个完整的数据集给用户。在这个过程中，节点A扮演的就是协调节点的角色。由此可见，协调节点会对CPU、Memory和I/O要求比较高。\n\nElasticsearch默认的堆内存大小是1GB,由于Elasticsearch是-一个比较耗内存的应用，所以对于大部分应用来说，这个值太小。我们可以通过一些方式来改变堆内存的大小。如果是通过解压安装包安装的Elasticsearch， 则在Elasticsearch 安装包下的config 文件夹中包含一个jvm.option文件，打开该文件，添加如下命令来设置Elasticsearch的堆大小:\n12345-Xms5g-Xmx5g或者-Xms5000m-Xmx5000m\n该命令表示堆的初始大小(Xms)和可分配的最大内存(Xmx)都是5GB。建议在设置堆大小时让初始大小和最大可分配的值一-样，这样就可以避免在运行时因为改变堆内存的大小而导致系统资源浪费。\n也可以通过设置环境变量的方式设置堆的大小。比如:\n1export ES HEAP SIZE=5g\n在启动Elasticsearch时设置堆的大小:\n1. /bin/elasticsearch -Xmx5g  -Xms5g\n这种设置方式并不是一劳永逸的，在每次启动Elasticsearch时都需要添加-Xmx5g -Xms5g参数。\n如果服务器有足够多的内存，那么是否给堆内存分配的内存越大越好?虽然内存对Elasticsearch来说是非常重要的，但是答案是否定的!因为Elasticsearch堆内存的分配要考虑以下两个原则。\n\n\n最好不要超过物理内存的50%。因为Elasticsearch 底层是Lucene实现的。由于Lucene段的不变性，所以我们不用考虑数据的变化，这对缓存来说是非常友好的。操作系统可以把这些文件缓存在操作系统的文件缓存系统(Filesystem Cache)中而非堆内存中，如果我们设置的堆内存过大，导致系统可用的内存太小，就会严重影响Lucene的全文本查询性能。\n\n\n堆内存的大小最好不要超过32GB。在Java中，所有对象都分配在堆上，并且每个对象头都通过-一个Klass Pointer 指针指向它的类元数据，而这个指针在64位的操作系统上为64位，在32位的系统上为32位。32位的操作系统的最大寻址空间为4GB(232)，64位的操作系统可以使用更多的内存(264)。 但是在64位的操作系统上，因为指针本身变大了，所以会有更大的空间浪费在指针本身上，更糟糕的是，更大的指针在主内存和各级缓存(例如LLC、LI等)之间移动数据时，会占用更多的带宽。\nJava使用内存指针压缩(Compressed Oops)技术来解决这个问题。它的指针不再表示对象在内存中的精确位置，而是表示偏移量。这意味着32位的指针可以引用4GB个Byte，而不是4GB个bit。也就是说，堆内存为32GB的物理内存，也可以用32位的指针表示。\n\n\n所以，在越过那个神奇的边界–32GB 时，指针就会切回为普通对象的指针，每个对象的指针都变长了，就会浪费更多的内存，降低了CPU的性能，还要让GC应对大的内存。事实上，当内存到达40~50GB时，有效的内存才相当于使用内存对象指针压缩技术时的32GB内存，所以在大内存的服务器上设置的堆大小要小于32GB，比如可以设置为31GB:\n12-Xms31g-Xmx31g\n虽然32GB是一个很重要的分割线，但是随着硬件成本的下降，现在有大内存的服务器愈发常见，比如一台有128GB内存的服务器。这时我们需要根据以下业务场景来考虑内存的分配情况。\n\n\n如果业务场景是以全文检索为主的，则依然可以给Elasticsearch 分配小于32GB的堆内存，而把剩下的大部分内存空间留给Lucene，让Luccene通过操作系统的文件缓存系统来缓存更多的segment,使Lucene带来极速的全文检索。\n\n\n如果在业务场景中有很多的排序和聚合，而且大部分聚合计算是在数字、日期、地理点等非分词的字符串上的，则聚合计算将在内存友好的doc values (非堆内存).上完成!我们依然可以为Elasticsearch 分配小于32GB的堆内存，其余部分为操作系统的缓存使用doc values。\n\n\n如果在业务场景中有很多排序和聚合，并且是在分词的字段上进行的，则不幸的是，我们需要fielddata来缓存。但是和doc values不同，fielddata 是分配在堆内存上的，这时就需要分配更多的堆内存了，但是让一个节点拥有太大的堆内存，并不是一种明智的选择。可以考虑在同一台服务上部署多个节点，使得每个节点的内存分配不超过32GB，不会有太多的资源浪费。\n\n\n使用ES构建mapping时,不是string类型的属性,不允许分词操作\n常用命令\n1234567curl -u elastic:elastic -XPOST &#x27;http://10.113.9.95:9200/user_label_1/user_label_1/1787395/_update&#x27; -d &#x27;&#123;&quot;doc&quot;:&#123;&quot;user_id&quot;:&quot;1787395&quot;,&quot;is_pay_member&quot;:&quot;1&quot;,&quot;vip_staff_id&quot;:&quot;cs6426&quot;&#125;&#125;&#x27;curl -u elastic:elastic -XPUT &#x27;http://10.113.9.95:9200/user_label_1/user_label_1/id&#x27; -d &#x27;&#123;&quot;user_id&quot;:&quot;10085&quot;,&quot;vip_staff_id&quot;:&quot;cs6428&quot;&#125;&#x27;curl  -u elastic:elastic -XDELETE http://10.113.9.95:9200/user_label_1/user_label_1/10085/ curl -u elastic:elastic -XGET http://10.113.9.95:9200/user_label_1/user_label_1/_search?q=user_id:10085\n","plink":"https://zinki.github.io/2019/06/15/ElasticSearch相关知识/"},{"title":"Zookeeper相关知识","date":"2019-05-21T02:00:00.000Z","date_formatted":{"ll":"2019年5月21日","L":"2019/05/21","MM-DD":"05-21"},"updated":"2024-10-10T08:03:05.461Z","content":"ZooKeeper是一个分布式开源框架，提供了协调分布式应用的基本服务，它向外部应用暴露一组通用服务——分布式同步（Distributed Synchronization）、命名服务（Naming Service）、集群维护（Group Maintenance）等，简化分布式应用协调及其管理的难度，提供高性能的分布式服务。ZooKeeper本身可以以Standalone模式安装运行，不过它的长处在于通过分布式ZooKeeper集群（一个Leader，多个Follower），基于一定的策略来保证ZooKeeper集群的稳定性和可用性，从而实现分布式应用的可靠性。\nZookeeper 为分布式系统提供了高效可靠且易于使用的协同服务，它可以为分布式应用提供相当多的服务，诸如统一命名服务，配置管理，状态同步和组服务等。Zookeeper 接口简单，开发人员不必过多地纠结在分布式系统编程难于处理的同步和一致性问题上，你可以使用 Zookeeper 提供的现成(off-the-shelf)服务来实现分布式系统的配置管理，组管理，Leader 选举等功能。\n一般而言，Zookeeper 应用程序分为两部分，其中一部分维护与服务器端的连接，另外一部分监视 Znode 节点的数据。在本程序中，Executor 类负责维护 Zookeeper连接，DataMonitor 类监视 Zookeeper 目录树中的数据， 同时，Executor 包含了主线程和程序主要的执行逻辑，它负责少量的用户交互，以及与可执行程序的交互，该可执行程序接受你向它传入的参数，并且会根据被监视的 Znode 节点的状态变化停止或重启。\nzookeeper是以Fast Paxos算法为基础，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fase Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交proposer，具体的可以看一下Fast Paxos算法。\n简单的选举算法可以依赖很多计算机硬件因素作为选举因子，比如IP地址、CPU核数、内存大小、自定义序列号等等，比如采用自定义序列号\nZookeeper通过心跳检测客户端是否存活,心跳出现超时可能是master挂了，但是也可能是master，Zookeeper之间网络出现了问题，这种情况就是假死，Zookeeper认为其挂掉了然后通知其他节点进行切换，这样slaver中就有一个成为了master，但是原本的master并未死掉,client也获得master切换的消息，但是仍然会有一些延时,导致短时间内出现数据同步问题,这种情况叫作脑裂\n避免方法是在slaver切换的时候不在检查到老的master出现问题后马上切换，而是在休眠一段足够的时间，确保老的master已经获知变更并且做了相关的shutdown清理工作了然后再注册成为master就能避免这类问题了，这个休眠时间一般定义为与Zookeeper定义的超时时间就够了，但是这段时间内系统不可用了。\n拜占庭问题\n原始问题起源于东罗马帝国（拜占庭帝国）。拜占庭帝国国土辽阔，为了防御目的，每支军队都分隔很远，将军之间只能依靠信差传信。在战争的时候，拜占庭军队内所有司令和将军必需达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，在军队内有可能存有叛徒和敌军的间谍，左右将军们的决定又扰乱整体军队的秩序。因此表决的结果并不一定能代表大多数人的意见。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，拜占庭问题就此形成。\n三模冗余系统简称TMR(Triple Modular Redundancy)，是最常用的一种容错设计技术．三个模块同时执行相同的操作，以多数相同的输出作为表决系统的正确输出，通常称为三取二,三个模块相互独立\nZooKeeper并没有完全采用Paxos算法，而是使用了一种称为ZooKeeper Atomic Broadcast（ZAB，ZooKeeper原子消息广播协议）的协议作为其数据一致性的核心算法。\nZooKeeper具有以下两大特性\n客户端如果对 ZooKeeper 的一个数据节点注册 Watcher 监听, 那么当该数据节点的内容或是其子节点列表发生变更时- Z00Keeper服务器就会向订阅的客户端发送变更通知。\n对在 ZooKeeper上创建的临时节点, 一旦客户端与服务器之间的会话失效, 那么该临时节点也就被自动清除。\nJava Api基本操作\n1234567891011121314151617181920212223242526272829303132// 创建一个与服务器的连接 ZooKeeper zk = new ZooKeeper(&quot;localhost:&quot; + CLIENT_PORT,        ClientBase.CONNECTION_TIMEOUT, new Watcher() &#123;            // 监控所有被触发的事件            public void process(WatchedEvent event) &#123;                System.out.println(&quot;已经触发了&quot; + event.getType() + &quot;事件！&quot;);            &#125;        &#125;); // 创建一个目录节点 zk.create(&quot;/testRootPath&quot;, &quot;testRootData&quot;.getBytes(), Ids.OPEN_ACL_UNSAFE,   CreateMode.PERSISTENT); // 创建一个子目录节点 zk.create(&quot;/testRootPath/testChildPathOne&quot;, &quot;testChildDataOne&quot;.getBytes(),   Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT); System.out.println(new String(zk.getData(&quot;/testRootPath&quot;,false,null))); // 取出子目录节点列表 System.out.println(zk.getChildren(&quot;/testRootPath&quot;,true)); // 修改子目录节点数据 zk.setData(&quot;/testRootPath/testChildPathOne&quot;,&quot;modifyChildDataOne&quot;.getBytes(),-1); System.out.println(&quot;目录节点状态：[&quot;+zk.exists(&quot;/testRootPath&quot;,true)+&quot;]&quot;); // 创建另外一个子目录节点 zk.create(&quot;/testRootPath/testChildPathTwo&quot;, &quot;testChildDataTwo&quot;.getBytes(),   Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT); System.out.println(new String(zk.getData(&quot;/testRootPath/testChildPathTwo&quot;,true,null))); // 删除子目录节点 zk.delete(&quot;/testRootPath/testChildPathTwo&quot;,-1); zk.delete(&quot;/testRootPath/testChildPathOne&quot;,-1); // 删除父目录节点 zk.delete(&quot;/testRootPath&quot;,-1); // 关闭连接 zk.close();","plink":"https://zinki.github.io/2019/05/21/Zookeepe相关知识/"},{"title":"JVM调优","date":"2019-04-15T07:10:00.000Z","date_formatted":{"ll":"2019年4月15日","L":"2019/04/15","MM-DD":"04-15"},"updated":"2024-10-10T08:03:05.447Z","content":"根据Java虚拟机规范，JVM将内存划分为：\n\nNew（年轻代）\nTenured（年老代）\n永久代（Perm）\n\n其中New和Tenured属于堆内存，堆内存会从JVM启动参数（-Xmx:3G）指定的内存中分配，Perm不属于堆内存，有虚拟机直接分配，但可以通过-XX:PermSize -XX:MaxPermSize等参数调整其大小。\n\n年轻代（New）：年轻代用来存放JVM刚分配的Java对象\n\n\n年老代（Tenured)：年轻代中经过垃圾回收没有回收掉的对象将被Copy到年老代\n\n\n永久代（Perm）：永久代存放Class、Method元信息，其大小跟项目的规模、类、方法的量有关，一般设置为128M就足够，设置原则是预留30%的空间。\n\nNew又分为几个部分：\n\nEden：Eden用来存放JVM刚分配的对象\nSurvivor1\nSurvivro2：两个Survivor空间一样大，当Eden中的对象经过垃圾回收没有被回收掉时，会在两个Survivor之间来回Copy，当满足某个条件，比如Copy次数，就会被Copy到Tenured。显然，Survivor只是增加了对象在年轻代中的逗留时间，增加了被垃圾回收的可能性。\n\n垃圾回收算法都基于标记-清除（复制）算法\n还有一个问题是，垃圾回收动作何时执行？\n• 当年轻代内存满时，会引发一次普通GC，该GC仅回收年轻代。需要强调的时，年轻代满是指Eden代满，Survivor满不会引发GC\n• 当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代\n• 当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载\n另一个问题是，何时会抛出OutOfMemoryException，并不是内存被耗空的时候才抛出\n• JVM98%的时间都花费在内存回收\n• 每次回收的内存小于2%\n满足这两个条件将触发OutOfMemoryException，这将会留给系统一个微小的间隙以做一些Down之前的操作，比如手动打印Heap Dump。\nQ：为什么崩溃前垃圾回收的时间越来越长？\nA:根据内存模型和垃圾回收算法，垃圾回收分两部分：内存标记、清除（复制），标记部分只要内存大小固定时间是不变的，变的是复制部分，因为每次垃圾回收都有一些回收不掉的内存，所以增加了复制量，导致时间延长。所以，垃圾回收的时间也可以作为判断内存泄漏的依据\nQ：为什么Full GC的次数越来越多？\nA：因此内存的积累，逐渐耗尽了年老代的内存，导致新对象分配没有更多的空间，从而导致频繁的垃圾回收\nQ:为什么年老代占用的内存越来越大？\nA:因为年轻代的内存无法被回收，越来越多地被Copy到年老代\n对程序及JVM进行调优。从以下几个方面进行：\n• 线程池：解决用户响应时间长的问题\n• 连接池\n• JVM启动参数：调整各代的内存比例和垃圾回收算法，提高吞吐量\n• 程序算法：改进程序逻辑算法提高性能\nJava线程池\n大多数JVM6上的应用采用的线程池都是JDK自带的线程池，之所以把成熟的Java线程池进行罗嗦说明，是因为该线程池的行为与我们想象的有点出入。Java线程池有几个重要的配置参数：\n• corePoolSize：核心线程数（最新线程数）\n• maximumPoolSize：最大线程数，超过这个数量的任务会被拒绝，用户可以通过RejectedExecutionHandler接口自定义处理方式\n• keepAliveTime：线程保持活动的时间\n• workQueue：工作队列，存放执行的任务\nJava线程池需要传入一个Queue参数（workQueue）用来存放执行的任务，而对Queue的不同选择，线程池有完全不同的行为：\n• SynchronousQueue： 一个无容量的等待队列，一个线程的insert操作必须等待另一线程的remove操作，采用这个Queue线程池将会为每个任务分配一个新线程\n• LinkedBlockingQueue ： 无界队列，采用该Queue，线程池将忽略 maximumPoolSize参数，仅用corePoolSize的线程处理所有的任务，未处理的任务便在LinkedBlockingQueue中排队\n• ArrayBlockingQueue： 有界队列，在有界队列和 mmaximumPoolSizeaximumPoolSize的作用下，程序将很难被调优：更大的Queue和小的将导致CPU的低负载；小的Queue和大的池，Queue就没起动应有的作用。\n    其实我们的要求很简单，希望线程池能跟连接池一样，能设置最小线程数、最大线程数，当最小数&lt;任务&lt;最大数时，应该分配新的线程处理；当任务&gt;最大数时，应该等待有空闲线程再处理该任务。\n    但线程池的设计思路是，任务应该放到Queue中，当Queue放不下时再考虑用新线程处理，如果Queue满且无法派生新线程，就拒绝该任务。设计导致“先放等执行”、“放不下再执行”、“拒绝不等待”。所以，根据不同的Queue参数，要提高吞吐量不能一味地增大maximumPoolSize。\n    当然，要达到我们的目标，必须对线程池进行一定的封装，幸运的是ThreadPoolExecutor中留了足够的自定义接口以帮助我们达到目标。我们封装的方式是：\n• 以SynchronousQueue作为参数，使maximumPoolSize发挥作用，以防止线程被无限制的分配，同时可以通过提高maximumPoolSize来提高系统吞吐量\n• 自定义一个RejectedExecutionHandler，当线程数超过maximumPoolSize时进行处理，处理方式为隔一段时间检查线程池是否可以执行新Task，如果可以把拒绝的Task重新放入到线程池，检查的时间依赖keepAliveTime的大小。\n连接池\n在使用org.apache.commons.dbcp.BasicDataSource的时候，因为之前采用了默认配置，所以当访问量大时，通过JMX观察到很多Tomcat线程都阻塞在BasicDataSource使用的Apache ObjectPool的锁上，直接原因当时是因为BasicDataSource连接池的最大连接数设置的太小，默认的BasicDataSource配置，仅使用8个最大连接。\n    我还观察到一个问题，当较长的时间不访问系统，比如2天，DB上的MySQL会断掉所以的连接，导致连接池中缓存的连接不能用。为了解决这些问题，我们充分研究了BasicDataSource，发现了一些优化的点：\n• Mysql默认支持100个链接，所以每个连接池的配置要根据集群中的机器数进行，如有2台服务器，可每个设置为60\n• initialSize：参数是一直打开的连接数\n• minEvictableIdleTimeMillis：该参数设置每个连接的空闲时间，超过这个时间连接将被关闭\n• timeBetweenEvictionRunsMillis：后台线程的运行周期，用来检测过期连接\n• maxActive：最大能分配的连接数\n• maxIdle：最大空闲数，当连接使用完毕后发现连接数大于maxIdle，连接将被直接关闭。只有initialSize &lt; x &lt; maxIdle的连接将被定期检测是否超期。这个参数主要用来在峰值访问时提高吞吐量。\n• initialSize是如何保持的？经过研究代码发现，BasicDataSource会关闭所有超期的连接，然后再打开initialSize数量的连接，这个特性与minEvictableIdleTimeMillis、timeBetweenEvictionRunsMillis一起保证了所有超期的initialSize连接都会被重新连接，从而避免了Mysql长时间无动作会断掉连接的问题。\nJVM参数\n在JVM启动参数中，可以设置跟内存、垃圾回收相关的一些参数设置，默认情况不做任何设置JVM会工作的很好，但对一些配置很好的Server和具体的应用必须仔细调优才能获得最佳性能。通过设置我们希望达到一些目标：\n• GC的时间足够的小\n• GC的次数足够的少\n• 发生Full GC的周期足够的长\n  前两个目前是相悖的，要想GC时间小必须要一个更小的堆，要保证GC次数足够少，必须保证一个更大的堆，我们只能取其平衡。\n\n针对JVM堆的设置一般，可以通过-Xms -Xmx限定其最小、最大值，为了防止垃圾收集器在最小、最大之间收缩堆而产生额外的时间，我们通常把最大、最小设置为相同的值\n\n\n年轻代和年老代将根据默认的比例（1：2）分配堆内存，可以通过调整二者之间的比率NewRadio来调整二者之间的大小，也可以针对回收代，比如年轻代，通过 -XX:newSize -XX:MaxNewSize来设置其绝对大小。同样，为了防止年轻代的堆收缩，我们通常会把-XX:newSize -XX:MaxNewSize设置为同样大小\n\n\n年轻代和年老代设置多大才算合理？这个我问题毫无疑问是没有答案的，否则也就不会有调优。我们观察一下二者大小变化有哪些影响\n\n• 更大的年轻代必然导致更小的年老代，大的年轻代会延长普通GC的周期，但会增加每次GC的时间；小的年老代会导致更频繁的Full GC\n• 更小的年轻代必然导致更大年老代，小的年轻代会导致普通GC很频繁，但每次的GC时间会更短；大的年老代会减少Full GC的频率\n• 如何选择应该依赖应用程序对象生命周期的分布情况：如果应用存在大量的临时对象，应该选择更大的年轻代；如果存在相对较多的持久对象，年老代应该适当增大。但很多应用都没有这样明显的特性，在抉择时应该根据以下两点：\n\n本着Full GC尽量少的原则，让年老代尽量缓存常用对象，JVM的默认比例1：2也是这个道理\n通过观察应用一段时间，看其他在峰值时年老代会占多少内存，在不影响Full\n\nGC的前提下，根据实际情况加大年轻代，比如可以把比例控制在1：1。但应该给年老代至少预留1/3的增长空间\n\n在配置较好的机器上（比如多核、大内存），可以为年老代选择并行收集算法： -XX:+UseParallelOldGC ，默认为Serial收集\n\n\n线程堆栈的设置：每个线程默认会开启1M的堆栈，用于存放栈帧、调用参数、局部变量等，对大多数应用而言这个默认值太了，一般256K就足用。理论上，在内存不变的情况下，减少每个线程的堆栈，可以产生更多的线程，但这实际上还受限于操作系统。\n\n\n可以通过下面的参数打Heap Dump信息\n\n123456• -XX:HeapDumpPath• -XX:+PrintGCDetails• -XX:+PrintGCTimeStamps• -Xloggc:/usr/aaa/dump/heap_trace.txt    通过下面参数可以控制OutOfMemoryError时打印堆的信息• -XX:+HeapDumpOnOutOfMemoryError","plink":"https://zinki.github.io/2019/04/15/JVM调优/"},{"title":"Hadoop伪分布式部署","date":"2019-01-09T07:00:00.000Z","date_formatted":{"ll":"2019年1月9日","L":"2019/01/09","MM-DD":"01-09"},"updated":"2024-10-10T08:03:05.443Z","content":"Hadoop can also be run on a single-node in a pseudo-distributed mode where each Hadoop daemon runs in a separate Java process.\n\n配置\n123456789101112131415etc/hadoop/core-site.xml:&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;fs.defaultFS&lt;/name&gt;        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;etc/hadoop/hdfs-site.xml:&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\nSSH免密码\nNow check that you can ssh to the localhost without a passphrase:\n1$ ssh localhost\nIf you cannot ssh to localhost without a passphrase, execute the following commands:\n123$ ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsa$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys$ chmod 0600 ~/.ssh/authorized_keys\n执行\n\nFormat the filesystem:\n\n1$ bin/hdfs namenode -format\n\nStart NameNode daemon and DataNode daemon:\n\n1$ sbin/start-dfs.sh\nThe hadoop daemon log output is written to the $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs).\n\nBrowse the web interface for the NameNode; by default it is available at:\n\n\n○ NameNode - http://localhost:9870/\n\n\nMake the HDFS directories required to execute MapReduce jobs:\n\n12$ bin/hdfs dfs -mkdir /user$ bin/hdfs dfs -mkdir /user/&lt;username&gt;\n\nCopy the input files into the distributed filesystem:\n\n123$ bin/hdfs dfs -mkdir input$ bin/hdfs dfs -put etc/hadoop/*.xml input\n\nRun some of the examples provided:\n\n1$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#x27;dfs[a-z.]+&#x27;\n\nExamine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them:\n\n12$ bin/hdfs dfs -get output output$ cat output/*\nor\nView the output files on the distributed filesystem:\n1$ bin/hdfs dfs -cat output/*\n\nWhen you’re done, stop the daemons with:\n\n1$ sbin/stop-dfs.sh\n参考\nHadoop: Setting up a Single Node Cluster.\n","plink":"https://zinki.github.io/2019/01/09/Hadoop伪分布式部署/"},{"title":"网络相关知识","date":"2018-12-11T11:05:00.000Z","date_formatted":{"ll":"2018年12月11日","L":"2018/12/11","MM-DD":"12-11"},"updated":"2024-10-11T08:05:06.523Z","content":"网络分为三类:局域网(LAN),广域网(WAN),城域网(MAN Metropolitan Area Network )\n对于主机或路由来说,IP地址是一串32位的二进制代码,常常每八位用等效十进制表示\nURL统一资源定位符用来表示从因特网上得到资源位置和访问资源的方法\n一般形式是: &lt;协议&gt;://&lt;主机&gt;:&lt;端口&gt;/&lt;路径&gt;\nIP地址是一种逻辑地地址，用来标识网络中一个个主机，IP有唯一性，即每台机器的IP在全世界是唯一的，IPv4有32位地址，IPv6有128位地址。\nIP地址=网络地址+主机地址，（又称：主机号和网络号组成）ip地址的结构使我们可以在Internet上很方便的寻址。\n子网掩码是用来判断任意两台计算机的ip地址是否属于同一子网络的根据。最为简单的理解就是两台计算机各自的ip地址与子网掩码进行and运算后，得出的结果是相同的，则说明这两台计算机是处于同一个子网络上的，可以进行直接的通讯。\n网关是不同网络之间进行通信的关口\nTCP/IP模型及与OSI参考模型的对应关系\n\n计算机网络分为应用层，传输层，网络层，链路层，物理层，每一层都有其作用\n\n应用层：包含大量应用普遍需要的协议（如HTTP FTP SMTP DNS等）；应用传递的数据包叫做报文。\n\n\n传输层：负责从应用层接收消息，并传输应用层的message，到达目的后将消息上交给应用。传输层的数据包叫做segment（段）此层协议有TCP UDP。\n\n\n网络层：源Host的传输层协议负责将segment交给网络层，网络层负责将segment传输到目的host的传输层，网络层的数据包叫做datagram（数据报）此层协议有IP。\n\n\n链路层：网络层负责在源和目的之间传递数据，链路层负责将packet从一个节点传输到下一个节点。链路层传输数据的单位叫做Frame（帧）此层协议有Ethernet、WiFi、PPP协议。\n\n\n物理层：Link层负责将一个Frame从一个Node传递到下一个Node，物理层负责将Frame中的每一位(bit)从链路的一端传输到另一端，物理层传输数据的单位叫做bit（比特）。\n\n\n用户使用客户端访问远程主机上的服务器,用户只知道服务器名字,而TCP/IP协议簇需要服务器IP建立连接,这时需要把主机名映射到IP地址\n这里用到了name space,为实现无二义性,将每一个地址映射到唯一的名字,获得层次name space,设计了domain name space,表示DNS服务器也会服从树状结构\n域名的树状结构\n\nIPV4中，0.0.0.0地址被用于表示一个无效的，未知的或者不可用的目标。\n\n在服务器中，0.0.0.0指的是本机上的所有IPV4地址，如果一个主机有两个IP地址，192.168.1.1 和 10.1.2.1，并且该主机上的一个服务监听的地址是0.0.0.0,那么通过两个ip地址都能够访问该服务。\n\n\n在路由中，0.0.0.0表示的是默认路由，即当路由表中没有找到完全匹配的路由的时候所对应的路由。\n\n用途总结：\n\n\n当一台主机还没有被分配一个IP地址的时候，用于表示主机本身。（DHCP分配IP地址的时候）\n\n\n用作默认路由，表示”任意IPV4主机”。\n\n\n用来表示目标机器不可用。\n\n\n用作服务端，表示本机上的任意IPV4地址。\n\n\n127.0.0.1属于{127,}集合中的一个，而所有网络号为127的地址都被称之为回环地址，所以回环地址！=127.0.0.1,它们是包含关系，即回环地址包含127.0.0.1。\n回环地址：所有发往该类地址的数据包都应该被loop back。\n用途:\n\n\n回环测试,通过使用ping 127.0.0.1 测试某台机器上的网络设备，操作系统或者TCP/IP实现是否工作正常。\n\n\nDDos攻击防御：网站收到DDos攻击之后，将域名A记录到127.0.0.1，即让攻击者自己攻击自己。\n\n\n大部分Web容器测试的时候绑定的本机地址。\n\n\n","plink":"https://zinki.github.io/2018/12/11/网络相关知识/"},{"title":"Copy-On-Write实现原理","date":"2018-11-21T09:00:00.000Z","date_formatted":{"ll":"2018年11月21日","L":"2018/11/21","MM-DD":"11-21"},"updated":"2024-10-10T08:03:05.440Z","content":"Copy-On-Write简称COW，是一种用于程序设计中的优化策略。\nCOW基本思路是从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。从JDK1.5开始Java并发包里提供了两个使用CopyOnWrite机制实现的并发容器,它们是CopyOnWriteArrayList和CopyOnWriteArraySet。CopyOnWrite容器非常有用，可以在非常多的并发场景中使用到。\n什么是CopyOnWrite容器\nCopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。\n写时复制是指：在并发访问的情景下，当需要修改JAVA中Containers的元素时，不直接修改该容器，而是先复制一份副本，在副本上进行修改。修改完成之后，将指向原来容器的引用指向新的容器(副本容器)。由于不会修改原始容器，只修改副本容器。因此，可以对原始容器进行并发地读。其次，实现了读操作与写操作的分离，读操作发生在原始容器上，写操作发生在副本容器上。\n\n因为CopyOnWrite的写时复制机制会导致内存占用比较大\n\n\n数据一致性问题：读操作的线程可能不会立即读取到新修改的数据，因为修改操作发生在副本上。但最终修改操作会完成并更新容器，因此这是最终一致性。\n\nCopyOnWriteArrayList.add实现\n1234567891011121314public boolean add(E e) &#123;    final ReentrantLock lock = this.lock;    lock.lock();    try &#123;        Object[] elements = getArray();        int len = elements.length;        Object[] newElements = Arrays.copyOf(elements, len + 1);        newElements[len] = e;        setArray(newElements);        return true;    &#125; finally &#123;        lock.unlock();    &#125;&#125;\nCopyOnWriteArrayList.get实现\n123public E get(int index) &#123;    return get(getArray(), index);&#125;\nCOW在Docker中的应用\nCOW一方面带来了容器启动的快捷，另一方也造成了容器镜像大小的增加。每一次 RUN 命令都会在镜像上增加一层，每一层都会占用磁盘空间。举个例子，在 Ubuntu 14.04 基础镜像中运行 RUN apt-get upgrade 会在保留基础层的同时再创建一个新层来放所有新的文件，而不是修改老的文件，因此，新的镜像大小会超过直接在老的文件系统上做更新时的文件大小。因此，为了减少镜像大小起见，所有文件相关的操作，比如删除，释放和移动等，都需要尽可能地放在一个 RUN 指令中进行。\n比如说，通过将上面的示例 Dockerfile 修改为：\n12345FROM ubuntu:14.04MAINTAINER sammy &quot;sammy@sammy.com&quot;RUN apt-get update &amp;&amp; apt-get -y install ntpEXPOSE 5555CMD [&quot;/usr/sbin/ntpd&quot;]\n结果产生的镜像，不仅层数少了一层（7 -&gt; 6），而且大小减少了 0.001M ：），因为这个例子比较特殊，文件都是添加，而没有更新，因此size 的下降非常小\n参考\n聊聊并发-Java中的Copy-On-Write容器\n","plink":"https://zinki.github.io/2018/11/21/Copy-On-Write实现原理/"},{"title":"CAS实现原理","date":"2018-10-13T12:00:00.000Z","date_formatted":{"ll":"2018年10月13日","L":"2018/10/13","MM-DD":"10-13"},"updated":"2024-10-10T08:03:05.439Z","content":"CAS 指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令，在大多数处理器架构，包括IA32、Space中采用的都是CAS指令\nCAS的语义是“我认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少”，CAS是项乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。\nCAS无锁算法的C实现如下：\n123456789int compare_and_swap (int* reg, int oldval, int newval) &#123;  ATOMIC();  int old_reg_val = *reg;  if (old_reg_val == oldval)      *reg = newval;  END_ATOMIC();  return old_reg_val;&#125;\n虽然使用CAS可以实现非阻塞式的原子性操作，但是会产生ABA问题\n\n\n现有一个用单向链表实现的堆栈，栈顶为A。这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B：head.compareAndSet(A,B);\n\n\n在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再依次入栈D、C、A，而对象B此时处于游离状态。\n\n\n此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B。但实际上B.next为null，此时堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，C、D被丢掉了。\n\n\n以上就是由于ABA问题带来的隐患，各种乐观锁的实现中通常都会用版本戳version来对记录或对象标记，避免并发操作带来的问题。\n","plink":"https://zinki.github.io/2018/10/13/CAS实现原理/"},{"title":"自定义SQL打印","date":"2018-09-20T09:10:00.000Z","date_formatted":{"ll":"2018年9月20日","L":"2018/09/20","MM-DD":"09-20"},"updated":"2024-10-10T08:03:05.476Z","content":"mybatis打印日志格式默认占位符，不方便排查SQL问题\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192import org.apache.ibatis.cache.CacheKey;import org.apache.ibatis.executor.Executor;import org.apache.ibatis.mapping.BoundSql;import org.apache.ibatis.mapping.MappedStatement;import org.apache.ibatis.mapping.ParameterMapping;import org.apache.ibatis.mapping.ParameterMode;import org.apache.ibatis.plugin.*;import org.apache.ibatis.reflection.MetaObject;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.ResultHandler;import org.apache.ibatis.session.RowBounds;import org.apache.ibatis.type.TypeHandlerRegistry;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import org.springframework.util.StringUtils;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.Properties;@Component@Intercepts(&#123;        @Signature(type = Executor.class, method = &quot;query&quot;, args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&#125;),        @Signature(type = Executor.class, method = &quot;query&quot;, args = &#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&#125;),        @Signature(type = Executor.class, method = &quot;update&quot;, args = &#123;MappedStatement.class, Object.class&#125;)&#125;)public class SqlInterceptor implements Interceptor &#123;    private static ThreadLocal&lt;SimpleDateFormat&gt; dateTimeFormatter = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123;        @Override        protected SimpleDateFormat initialValue() &#123;            return new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);        &#125;    &#125;;    @Override    public Object intercept(Invocation invocation) throws Throwable &#123;        Object result = null;        //捕获掉异常，不要影响业务        try &#123;            MappedStatement mappedStatement = (MappedStatement) invocation.getArgs()[0];            Object parameter = null;            if (invocation.getArgs().length &gt; 1) &#123;                parameter = invocation.getArgs()[1];            &#125;            String sqlId = mappedStatement.getId();            BoundSql boundSql = mappedStatement.getBoundSql(parameter);            Configuration configuration = mappedStatement.getConfiguration();            long startTime = System.currentTimeMillis();            try &#123;                result = invocation.proceed();            &#125; finally &#123;                long endTime = System.currentTimeMillis();                long sqlCostTime = endTime - startTime;                String sql = this.getSql(configuration, boundSql);                this.formatSqlLog(sqlId, sql, sqlCostTime, result);            &#125;            return result;        &#125; catch (Exception e) &#123;            return result;        &#125;    &#125;    @Override    public Object plugin(Object target) &#123;        if (target instanceof Executor) &#123;            return Plugin.wrap(target, this);        &#125;        return target;    &#125;    @Override    public void setProperties(Properties properties) &#123;    &#125;    /**     * 获取完整的sql语句     *     * @param configuration     * @param boundSql     * @return     */    private String getSql(Configuration configuration, BoundSql boundSql) &#123;        // 输入sql字符串空判断        String sql = boundSql.getSql();        if (StringUtils.isEmpty(sql)) &#123;            return &quot;&quot;;        &#125;        return formatSql(sql, configuration, boundSql);    &#125;    /**     * 将占位符替换成参数值     *     * @param sql     * @param configuration     * @param boundSql     * @return     */    private String formatSql(String sql, Configuration configuration, BoundSql boundSql) &#123;        //美化sql        sql = beautifySql(sql);        //填充占位符, 目前基本不用mybatis存储过程调用,故此处不做考虑        Object parameterObject = boundSql.getParameterObject();        List&lt;ParameterMapping&gt; parameterMappings = boundSql.getParameterMappings();        TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry();        List&lt;String&gt; parameters = new ArrayList&lt;&gt;();        if (parameterMappings != null) &#123;            MetaObject metaObject = parameterObject == null ? null : configuration.newMetaObject(parameterObject);            for (int i = 0; i &lt; parameterMappings.size(); i++) &#123;                ParameterMapping parameterMapping = parameterMappings.get(i);                if (parameterMapping.getMode() != ParameterMode.OUT) &#123;                    //  参数值                    Object value;                    String propertyName = parameterMapping.getProperty();                    //  获取参数名称                    if (boundSql.hasAdditionalParameter(propertyName)) &#123;                        // 获取参数值                        value = boundSql.getAdditionalParameter(propertyName);                    &#125; else if (parameterObject == null) &#123;                        value = null;                    &#125; else if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) &#123;                        // 如果是单个值则直接赋值                        value = parameterObject;                    &#125; else &#123;                        value = metaObject == null ? null : metaObject.getValue(propertyName);                    &#125;                    if (value instanceof Number) &#123;                        parameters.add(String.valueOf(value));                    &#125; else &#123;                        StringBuilder builder = new StringBuilder();                        builder.append(&quot;&#x27;&quot;);                        if (value instanceof Date) &#123;                            builder.append(dateTimeFormatter.get().format((Date) value));                        &#125; else if (value instanceof String) &#123;                            builder.append(value);                        &#125;                        builder.append(&quot;&#x27;&quot;);                        parameters.add(builder.toString());                    &#125;                &#125;            &#125;        &#125;        for (String value : parameters) &#123;            sql = sql.replaceFirst(&quot;\\\\?&quot;, value);        &#125;        return sql;    &#125;    /**     * 格式化sql日志     *     * @param sqlId     * @param sql     * @param costTime     * @return     */    private void formatSqlLog(String sqlId, String sql, long costTime, Object obj) &#123;        String sqlLog = &quot;==&gt; &quot; + sql;        StringBuffer result = new StringBuffer();        if (obj instanceof List) &#123;            List list = (List) obj;            int count = list.size();            result.append(&quot;&lt;==      Total: &quot; + count);        &#125; else if (obj instanceof Integer) &#123;            result.append(&quot;&lt;==      Total: &quot; + obj);        &#125;        result.append(&quot;      Spend Time ==&gt; &quot; + costTime + &quot; ms&quot;);        Logger log = LoggerFactory.getLogger(sqlId);        log.info(sqlLog);        log.info(result.toString());    &#125;    public static String beautifySql(String sql) &#123;        sql = sql.replaceAll(&quot;[\\\\s\\n ]+&quot;, &quot; &quot;);        return sql;    &#125;&#125;\n参考\nMybatis打印替换占位符后的完整Sql\n","plink":"https://zinki.github.io/2018/09/20/自定义SQL打印/"},{"title":"IO相关知识","date":"2018-09-05T02:10:00.000Z","date_formatted":{"ll":"2018年9月5日","L":"2018/09/05","MM-DD":"09-05"},"updated":"2024-10-11T08:00:12.652Z","content":"select/poll/epoll区别\n基本Linux I/O模型的简单矩阵\n\nselect，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的.\n异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间\nepoll是Linux内核的IO模型。我想一定有人想问，AIO听起来比NIO更加高大上，为什么不使用AIO？AIO其实也有应用，但是有一个问题就是，Linux是不支持AIO的，AIO框架在windows下使用windows IOCP技术，在Linux下使用epoll多路复用IO技术模拟异步IO.因此基于AIO的程序运行在Linux上的效率相比NIO反而更低。而Linux是最主要的服务器OS，因此相比AIO，目前NIO的应用更加广泛。\nselect\n1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);\nselect 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。\npoll\n1234567int poll (struct pollfd *fds, unsigned int nfds, int timeout);不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。struct pollfd &#123;    int fd; /* file descriptor */    short events; /* requested events to watch */    short revents; /* returned events witnessed */&#125;;\npollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。\n从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。\nepoll\nepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。\n\nepoll操作过程\nepoll操作过程需要三个接口，分别如下：\n\n123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\nint epoll_create(int size);\n创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。\n当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)函数是对指定描述符fd执行op操作。\n12345678- epfd：是epoll_create()的返回值。- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。- fd：是需要监听的fd（文件描述符）- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：struct epoll_event &#123;  __uint32_t events;  /* Epoll events */  epoll_data_t data;  /* User data variable */&#125;;\nevents可以是以下几个宏的集合：\n1234567EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里\nint epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);\n等待epfd上的io事件，最多返回maxevents个事件。\n参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。\n\n工作模式\n\nepoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下：\n　　LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。\n　　ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。\n\nLT模式\nLT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。\n\n\nET模式\nET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)\nET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n\n参考\nLinux IO模式及 select、poll、epoll详解\n","plink":"https://zinki.github.io/2018/09/05/IO相关知识/"},{"title":"IOC实现原理","date":"2018-08-26T02:10:00.000Z","date_formatted":{"ll":"2018年8月26日","L":"2018/08/26","MM-DD":"08-26"},"updated":"2024-10-10T08:03:05.445Z","content":"控制反转（Inversion of Control，英文缩写为IOC）是框架的重要特征，做到控制反转需要一个容器来实现，就是我们所说的IoC容器，最常见的IoC容器是Spring。\n控制反转从字面意思看来不是很好理解，其实就是将创建管理对象的工作交给容器来做。在以前的编程中，创建一个对象需要显式的new出来，但是控制反转是在容器初始化（或者某个指定时间节点）时通过反射机制创建好对象，在使用时去容器中获取。将对象的控制权反过来交给容器管理，所以称之为“控制反转”。\nIoC容器是怎么实现的呢？\nIoC容器的底层实现其实是工厂模式，通过工厂模式和反射机制，根据XML中给出的类名生成相应的对象。其实IoC容器的实现很简单，就是一个HashMap，接下来，我们实现一个简单的IoC容器：\n1.读取配置文件，并初始化容器\n配置文件可以是XML或者properties文件，下面代码是读取两种配置文件创建实例，并放到容器中（容器的实现是HashMap）：\n（1）读取xml配置文件，创建实例放进容器的实现：\n12345678910111213141516171819202122232425262728293031323334public class ClassPathXMLApplicationContext implements ApplicationContext &#123;    private Map iocContainer = new HashMap&lt;&gt;();    public ClassPathXMLApplicationContext() &#123;        try &#123;            DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();            DocumentBuilder documentBuilder = factory.newDocumentBuilder();            String filePath = this.getClass().getResource(&quot;/&quot;).getPath() + &quot;/applicationContext.xml&quot;;            filePath = URLDecoder.decode(filePath, &quot;UTF-8&quot;);            Document document = documentBuilder.parse(filePath);            NodeList beans = document.getElementsByTagName(&quot;bean&quot;);            for(int index = 0;index&lt;beans.getLength();index++)&#123;                Element element = (Element) beans.item(index);                String id = element.getAttribute(&quot;id&quot;);                String clz = element.getAttribute(&quot;class&quot;);                Class clas = Class.forName(clz);                Object object = clas.newInstance();                iocContainer.put(id,object);            &#125;        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public Object getBean(String beanId)&#123;        return iocContainer.get(beanId);    &#125;    ...&#125;\n读取XML创建容器\n（2）读取properties文件，创建实例放进容器的实现：\n1234567891011121314151617181920212223242526272829public class PropertiesApplicationContext implements ApplicationContext &#123;    private Map iocContainer = new HashMap&lt;&gt;();    public PropertiesApplicationContext() &#123;        try &#123;            String filePath = this.getClass().getResource(&quot;/&quot;).getPath() + &quot;/applicationContext.properties&quot;;            filePath = URLDecoder.decode(filePath, &quot;UTF-8&quot;);            Properties properties = new Properties();            FileInputStream fileInputStream = new FileInputStream(filePath);            properties.load(fileInputStream);            Enumeration&lt;?&gt; enumeration = properties.propertyNames();            while (enumeration.hasMoreElements())&#123;                String beanName = (String) enumeration.nextElement();                String clz = properties.getProperty(beanName);                iocContainer.put(beanName,Class.forName(beanName).newInstance());            &#125;        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;    public Object getBean(String beanId)&#123;        return iocContainer.get(beanId);    &#125;...&#125;\n读取properties创建容器\n2.ApplicationContextFactory工厂的实现（调用初始化容器的方法）\n通过工厂创建应用上下文中配置的对象，在此工厂中判断是否存在XML或prop文件，并初始化容器：\n1234567891011121314151617181920212223242526272829public class ApplicationContextFactory &#123;    public static ApplicationContext getApplicationContext() &#123;        ApplicationContext context = null;        try &#123;            String xmlFilePath = ApplicationContextFactory.class.getResource(&quot;/&quot;).getPath() + &quot;/applicationContext.xml&quot;;            xmlFilePath = URLDecoder.decode(xmlFilePath, &quot;UTF-8&quot;);            File xmlFile = new File(xmlFilePath);            String propertiesFilePath = ApplicationContextFactory.class.getResource(&quot;/&quot;).getPath() + &quot;/applicationContext.properties&quot;;            propertiesFilePath = URLDecoder.decode(propertiesFilePath, &quot;UTF-8&quot;);            File propertiesFile = new File(propertiesFilePath);            if(xmlFile.exists())&#123;                context = new ClassPathXMLApplicationContext();            &#125;else if(propertiesFile.exists())&#123;                context = new PropertiesApplicationContext();            &#125;else &#123;                context = null;            &#125;        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;        return context;    &#125;&#125;\n3.容器的使用\n通过工厂创建完容器就可以使用了，调用getBean(String beanId)方法获取容器中的对象实例：\n123456789public class ApplicationContextTest &#123;    public static void main(String[] args)&#123;        ApplicationContext context = ApplicationContextFactory.getApplicationContext();        System.out.println(context);    &#125;&#125;\n依赖注入（DI，Dependency Injection）和依赖查找（Dependency Lookup）是什么？\n依赖注入和依赖查找是IoC的两种主要实现方式，我直接把依赖查找给扔了没去理解他，一般会把IoC和DI放在一起说。\n其实可以把DI和IoC理解为同一件事，都是把创建实例的控制权交给容器来操作，只是两种叫法的角度不同：\n\n控制反转是从代码操作对象的角度来看，将操作对象的控制权反转交给了容器；\n依赖注入是从容器的角度看，我把你需要的对象或属性注入到你代码中去。\n\n","plink":"https://zinki.github.io/2018/08/26/IOC实现原理/"},{"title":"AOP实现原理","date":"2018-08-10T05:10:00.000Z","date_formatted":{"ll":"2018年8月10日","L":"2018/08/10","MM-DD":"08-10"},"updated":"2024-10-11T01:37:00.515Z","content":"AOP是目前Spring框架中的核心之一，在应用中具有非常重要的作用，也是Spring其他组件的基础。它是一种面向切面编程的思想\nAOP的拦截功能是由java中的动态代理来实现的。说白了，就是在目标类的基础上增加切面逻辑，生成增强的目标类（该切面逻辑或者在目标类函数执行之前，或者目标类函数执行之后，或者在目标类函数抛出异常时候执行。不同的切入时机对应不同的Interceptor的种类，如BeforeAdviseInterceptor，AfterAdviseInterceptor以及ThrowsAdviseInterceptor等）。\n那么动态代理是如何实现将切面逻辑（advise）织入到目标类方法中去的呢？下面我们就来详细介绍并实现AOP中用到的两种动态代理。\nAOP的源码中用到了两种动态代理来实现拦截切入功能：jdk动态代理和cglib动态代理。两种方法同时存在，各有优劣。jdk动态代理是由java内部的反射机制来实现的，cglib动态代理底层则是借助asm来实现的。总的来说，反射机制在生成类的过程中比较高效，而asm在生成类之后的相关执行过程中比较高效（可以通过将asm生成的类进行缓存，这样解决asm生成类过程低效问题）。还有一点必须注意：jdk动态代理的应用前提，必须是目标类基于统一的接口。如果没有上述前提，jdk动态代理不能应用。由此可以看出，jdk动态代理有一定的局限性，cglib这种第三方类库实现的动态代理应用更加广泛，且在效率上更有优势。\njdk动态代理实现AOP拦截\n1、为目标类（target）定义统一的接口类Service，这个是jdk动态代理必须的前提。\n1234567891011121314151617181920[java] view plain copypackage jdkproxy;  /**  * 该类是所有被代理类的接口类，jdk实现的代理要求被代理类基于统一的接口  *   * @author typ  *   */  public interface Service &#123;      /**      * add方法      */      public void add();      /**      * update方法      */      public void update();  &#125;  \n2、目标类AService，我们的实验目标就是在AService中add和update方法的前后实现拦截，加入自定义切面逻辑advise\n12345678910111213141516171819202122232425262728[java] view plain copypackage jdkproxy;  /**  * 被代理类，即目标类target  *   * @author typ  *   */  public class AService implements Service &#123;      /*      * (non-Javadoc)      *       * @see jdkproxy.Service#add()      */      public void add() &#123;          System.out.println(&quot;AService add&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;);      &#125;      /*      * (non-Javadoc)      *       * @see jdkproxy.Service#update()      */      public void update() &#123;          System.out.println(&quot;AService update&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot;);      &#125;  &#125;  \n3、实现动态代理类MyInvocationHandler，实现InvocationHandler接口，并且实现接口中的invoke方法。仔细看invoke方法，就是在该方法中加入切面逻辑的。目标类方法的执行是由mehod.invoke(target,args)这条语句完成。\n12345678910111213141516171819202122232425262728293031323334[java] view plain copypackage jdkproxy;  import java.lang.reflect.InvocationHandler;  import java.lang.reflect.Method;  /**  * @author typ  *  */  public class MyInvocationHandler implements InvocationHandler &#123;      private Object target;      MyInvocationHandler() &#123;          super();      &#125;      MyInvocationHandler(Object target) &#123;          super();          this.target = target;      &#125;      public Object invoke(Object proxy, Method method, Object[] args)              throws Throwable &#123;          // 程序执行前加入逻辑，MethodBeforeAdviceInterceptor          System.out.println(&quot;before-----------------------------&quot;);          // 程序执行          Object result = method.invoke(target, args);          // 程序执行后加入逻辑，MethodAfterAdviceInterceptor          System.out.println(&quot;after------------------------------&quot;);          return result;      &#125;  &#125;  \n4、测试类，其中增强的目标对象是由Proxy.newProxyInstance(aService.getClass().getClassLoader(), aService.getClass().getInterfaces(), handler);来生成的。\n1234567891011121314151617181920212223242526272829303132[java] view plain copypackage jdkproxy;  import java.lang.reflect.Proxy;  /**  * @author typ  *  */  public class Test &#123;      public static void main(String[] args) &#123;          Service aService = new AService();          MyInvocationHandler handler = new MyInvocationHandler(aService);          // Proxy为InvocationHandler实现类动态创建一个符合某一接口的代理实例          Service aServiceProxy = (Service) Proxy.newProxyInstance(aService                  .getClass().getClassLoader(), aService.getClass()                  .getInterfaces(), handler);          // 由动态生成的代理对象来aServiceProxy 代理执行程序，其中aServiceProxy 符合Service接口          aServiceProxy.add();          System.out.println();          aServiceProxy.update();          // 以下是对B的代理          // Service bService = new BService();          // MyInvocationHandler handler = new MyInvocationHandler(bService);          // Service bServiceProxy = (Service) Proxy.newProxyInstance(bService          // .getClass().getClassLoader(), bService.getClass()          // .getInterfaces(), handler);          // bServiceProxy.add();          // System.out.println();          // bServiceProxy.update();      &#125;  &#125;  \n自此，jdk动态代理来实现AOP拦截机制的代码已经实现，下面我们看一下拦截的结果，程序输出结果如下：\n123456before-----------------------------AService add&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;after------------------------------before-----------------------------AService update&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;after------------------------------\n可以看到，在目标类AService的add和update方法前后已经加入了自定义的切面逻辑，AOP拦截机制生效了。\ncglib动态代理实现AOP拦截\n1、目标类，cglib不需要定义目标类的统一接口\n1234567891011121314151617ß[java] view plain copypackage cglibproxy;  /**  * 被代理类，即目标对象target  *   * @author typ  *   */  public class Base &#123;      /**      * 一个模拟的add方法      */      public void add() &#123;          System.out.println(&quot;add ------------&quot;);      &#125;  &#125;  \n2、实现动态代理类CglibProxy，需要实现MethodInterceptor接口，实现intercept方法。该代理中在add方法前后加入了自定义的切面逻辑，目标类add方法执行语句为proxy.invokeSuper(object, args);\n123456789101112131415161718192021222324252627[java] view plain copypackage cglibproxy;  import java.lang.reflect.Method;  import net.sf.cglib.proxy.MethodInterceptor;  import net.sf.cglib.proxy.MethodProxy;  /**  * 此为代理类，用于在pointcut处添加advise  *   * @author typ  *   */  public class CglibProxy implements MethodInterceptor &#123;      public Object intercept(Object object, Method method, Object[] args,              MethodProxy proxy) throws Throwable &#123;          // 添加切面逻辑（advise），此处是在目标类代码执行之前，即为MethodBeforeAdviceInterceptor。          System.out.println(&quot;before-------------&quot;);          // 执行目标类add方法          proxy.invokeSuper(object, args);          // 添加切面逻辑（advise），此处是在目标类代码执行之后，即为MethodAfterAdviceInterceptor。          System.out.println(&quot;after--------------&quot;);          return null;      &#125;  &#125;  \n3、获取增强的目标类的工厂Factory，其中增强的方法类对象是有Enhancer来实现的，代码如下所示：\n12345678910111213141516171819202122232425262728[java] view plain copypackage cglibproxy;  import net.sf.cglib.proxy.Enhancer;  /**  * 工厂类，生成增强过的目标类（已加入切入逻辑）  *   * @author typ  *   */  public class Factory &#123;      /**      * 获得增强之后的目标类，即添加了切入逻辑advice之后的目标类      *       * @param proxy      * @return      */      public static Base getInstance(CglibProxy proxy) &#123;          Enhancer enhancer = new Enhancer();          enhancer.setSuperclass(Base.class);          //回调方法的参数为代理类对象CglibProxy，最后增强目标类调用的是代理类对象CglibProxy中的intercept方法          enhancer.setCallback(proxy);          // 此刻，base不是单纯的目标类，而是增强过的目标类          Base base = (Base) enhancer.create();          return base;      &#125;  &#125;  \n4、测试类\n123456789101112131415[java] view plain copypackage cglibproxy;  /**  * @author typ  *  */  public class Test &#123;      public static void main(String[] args) &#123;          CglibProxy proxy = new CglibProxy();          // base为生成的增强过的目标类          Base base = Factory.getInstance(proxy);          base.add();      &#125;  &#125;  \n自此，cglib动态代理实现的AOP拦截机制已经基本实现，下面我们来看一下拦截的效果如何，程序执行结果如下：\n123before-------------add ------------after--------------\n可以看到，在目标类Base的add方法前后已经加入了自定义的切面逻辑，AOP拦截机制生效了。\n此外，需要说明一下的是，cglib动态代理用到了第三方类库，需要在项目中引入两个jar包：cglib.jar和asm.jar。\njava动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。\n1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP\n2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP\n3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换\n","plink":"https://zinki.github.io/2018/08/10/AOP实现原理/"},{"title":"AUFS DOCKER基础技术","date":"2018-08-10T05:10:00.000Z","date_formatted":{"ll":"2018年8月10日","L":"2018/08/10","MM-DD":"08-10"},"updated":"2024-10-11T07:58:15.267Z","content":"AUFS是一种Union File System，所谓UnionFS就是把不同物理位置的目录合并mount到同一个目录中。UnionFS的一个最主要的应用是，把一张CD/DVD和一个硬盘目录给联合 mount在一起，然后，你就可以对这个只读的CD/DVD上的文件进行修改（当然，修改的文件存于硬盘上的目录里）。\n\nAUFS又叫Another UnionFS，后来叫Alternative UnionFS，后来可能觉得不够霸气，叫成Advance UnionFS。是个叫Junjiro Okajima（岡島順治郎）在2006年开发的，AUFS完全重写了早期的UnionFS 1.x，其主要目的是为了可靠性和性能，并且引入了一些新的功能，比如可写分支的负载均衡。AUFS在使用上全兼容UnionFS，而且比之前的UnionFS在稳定性和性能上都要好很多，后来的UnionFS 2.x开始抄AUFS中的功能。但是他居然没有进到Linux主干里，就是因为Linus不让，基本上是因为代码量比较多，而且写得烂（相对于只有3000行的union mount和10000行的UnionFS，以及其它平均下来只有6000行代码左右的VFS，AUFS居然有30000行代码），所以，岡島不断地改进代码质量，不断地提交，不断地被Linus拒掉，所以，到今天AUFS都还进不了Linux主干（今天你可以看到AUFS的代码其实还好了，比起OpenSSL好N倍，要么就是Linus对代码的质量要求非常高，要么就是Linus就是不喜欢AUFS）。\n不过，好在有很多发行版都用了AUFS，比如：Ubuntu 10.04，Debian6.0, Gentoo Live CD支持AUFS，所以，也OK了。\n好了，扯完这些闲话，我们还是看一个示例吧（环境：Ubuntu 14.04）\n1234567891011121314151617181920$ tree.├── fruits│   ├── apple│   └── tomato└── vegetables    ├── carrots    └── tomato# 创建一个mount目录$ mkdir mnt# 把水果目录和蔬菜目录union mount到 ./mnt目录中$ sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt#  查看./mnt目录$ tree ./mnt./mnt├── apple├── carrots└── tomato\n我们可以看到在./mnt目录下有三个文件，苹果apple、胡萝卜carrots和蕃茄tomato。水果和蔬菜的目录被union到了./mnt目录下了。\n我们来修改一下其中的文件内容：\n12345678910$ echo mnt &gt; ./mnt/apple$ cat ./mnt/applemnt$ cat ./fruits/applemnt上面的示例，我们可以看到./mnt/apple的内容改了，./fruits/apple的内容也改了。$ echo mnt_carrots &gt; ./mnt/carrots$ cat ./vegetables/carrots$ cat ./fruits/carrotsmnt_carrots\n上面的示例，我们可以看到，我们修改了./mnt/carrots的文件内容，./vegetables/carrots并没有变化，反而是./fruits/carrots的目录中出现了carrots文件，其内容是我们在./mnt/carrots里的内容。\n也就是说，我们在mount aufs命令中，我们没有指它vegetables和fruits的目录权限，默认上来说，命令行上第一个（最左边）的目录是可读可写的，后面的全都是只读的。（一般来说，最前面的目录应该是可写的，而后面的都应该是只读的）\n所以，如果我们像下面这样指定权限来mount aufs，你就会发现有不一样的效果（记得先把上面./fruits/carrots的文件删除了）：\n123456$ sudo mount -t aufs -o dirs=./fruits=rw:./vegetables=rw none ./mnt$ echo &quot;mnt_carrots&quot; &gt; ./mnt/carrots$ cat ./vegetables/carrotsmnt_carrots$ cat ./fruits/carrotscat: ./fruits/carrots: No such file or directory\n现在，在这情况下，如果我们要修改./mnt/tomato这个文件，那么究竟是哪个文件会被改写？\n12345$ echo &quot;mnt_tomato&quot; &gt; ./mnt/tomato$ cat ./fruits/tomatomnt_tomato$ cat ./vegetables/tomatoI am a vegetable\n可见，如果有重复的文件名，在mount命令行上，越往前的就优先级越高。\n那么，这种UnionFS有什么用？\n历史上，有一个叫Knoppix的Linux发行版，其主要用于Linux演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把CD/DVD上的image运行在一个可写的存储设备上（比如一个U盘上），其实，也就是把CD/DVD这个文件系统和USB这个可写的系统给联合mount起来，这样你对CD/DVD上的image做的任何改动都会在被应用在U盘上，于是乎，你可以对CD/DVD上的内容进行任意的修改，因为改动都在U盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的template，和另一个你的working directory给union在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个ad hoc snapshot。\nDocker把UnionFS的想像力发挥到了容器的镜像。你是否还记得我在介绍Linux Namespace上篇中用mount namespace和chroot山寨了一镜像。现在当你看过了这个UnionFS的技术后，你是不是就明白了，你完全可以用UnionFS这样的技术做出分层的镜像来。\n下图来自Docker的官方文档Layer，其很好的展示了Docker用UnionFS搭建的分层镜像。\n\n关于docker的分层镜像，除了aufs，docker还支持btrfs, devicemapper和vfs，你可以使用 -s 或 –storage-driver= 选项来指定相关的镜像存储。在Ubuntu 14.04下，docker默认Ubuntu的 aufs（在CentOS7下，用的是devicemapper，关于devicemapper，我会以以后的文章中讲解）你可以在下面的目录中查看相关的每个层的镜像：\n123456789101112#ls /sys/fs/aufs/si_b71b209f85ff8e75/br0      br2      br4      br6      brid1    brid3    brid5    xi_pathbr1      br3      br5      brid0    brid2    brid4    brid6# cat /sys/fs/aufs/si_b71b209f85ff8e75/*/var/lib/docker/aufs/diff/87315f1367e5703f599168d1e17528a0500bd2e2df7d2fe2aaf9595f3697dbd7=rw/var/lib/docker/aufs/diff/87315f1367e5703f599168d1e17528a0500bd2e2df7d2fe2aaf9595f3697dbd7-init=ro+wh/var/lib/docker/aufs/diff/d0955f21bf24f5bfffd32d2d0bb669d0564701c271bc3dfc64cfc5adfdec2d07=ro+wh/var/lib/docker/aufs/diff/9fec74352904baf5ab5237caa39a84b0af5c593dc7cc08839e2ba65193024507=ro+wh/var/lib/docker/aufs/diff/a1a958a248181c9aa6413848cd67646e5afb9797f1a3da5995c7a636f050f537=ro+wh/var/lib/docker/aufs/diff/f3c84ac3a0533f691c9fea4cc2ceaaf43baec22bf8d6a479e069f6d814be9b86=ro+wh/var/lib/docker/aufs/diff/511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158=ro+wh/run/shm/aufs.xino\n你会看到只有最顶上的层（branch）是rw权限，其它的都是ro+wh权限只读的。\n关于docker的aufs的配置，你可以在/var/lib/docker/repositories-aufs这个文件中看到。\nAUFS的一些特性\nAUFS有所有Union FS的特性，把多个目录，合并成同一个目录，并可以为每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经被mount好的目录。而且，他还能在多个可写的branch/dir间进行负载均衡。\n上面的例子，我们已经看到AUFS的mount的示例了。下面我们来看一看被union的目录（分支）的相关权限：\nrw表示可写可读read-write。\nro表示read-only，如果你不指权限，那么除了第一个外ro是默认值，对于ro分支，其永远不会收到写操作，也不会收到查找whiteout的操作。\nrr表示real-read-only，与read-only不同的是，rr标记的是天生就是只读的分支，这样，AUFS可以提高性能，比如不再设置inotify来检查文件变动通知。\n权限中，我们看到了一个术语：whiteout，下面我来解释一下这个术语。\n一般来说ro的分支都会有wh的属性，比如 “[dir]=ro+wh”。所谓whiteout的意思，如果在union中删除的某个文件，实际上是位于一个readonly的分支（目录）上，那么，在mount的union这个目录中你将看不到这个文件，但是read-only这个层上我们无法做任何的修改，所以，我们就需要对这个readonly目录里的文件作whiteout。AUFS的whiteout的实现是通过在上层的可写的目录下建立对应的whiteout隐藏文件来实现的。\n相关术语\nBranch – 就是各个要被union起来的目录（就是我在上面使用的dirs的命令行参数）\nBranch根据被union的顺序形成一个stack，一般来说最上面的是可写的，下面的都是只读的。\nBranch的stack可以在被mount后进行修改，比如：修改顺序，加入新的branch，或是删除其中的branch，或是直接修改branch的权限\nWhiteout 和 Opaque\n如果UnionFS中的某个目录被删除了，那么就应该不可见了，就算是在底层的branch中还有这个目录，那也应该不可见了。\nWhiteout就是某个上层目录覆盖了下层的相同名字的目录。用于隐藏低层分支的文件，也用于阻止readdir进入低层分支。\nOpaque的意思就是不允许任何下层的某个目录显示出来。\n在隐藏低层档的情况下，whiteout的名字是’.`wh.’。\n在阻止readdir的情况下，名字是’.wh…wh…opq’或者 ’.wh.__dir_opaque’。\n同一个内核版本的所有Linux系统的bootfs是相同的，而rootfs则是不同的。在Docker 中，基础镜像中的roofs会一直保持只读模式，Docker会利用union mount来在这个rootfs上增加更多的只读文件系统，最后它们看起来就像一个文件系统即容器的rootfs。\n关于 Docker的分层镜像，除了 aufs，docker还支持btrfs, devicemapper和vfs，你可以使用 -s 或 –storage-driver= 选项来指定相关的镜像存储。在Ubuntu 14.04下，Docker 默认 Ubuntu的 AUFS。因为 AUFS 还没有进入Linux 内核主干的原因，RedHat 上使用的是 devicemapper。\n镜像(image)是动态的容器的静态表示（specification），包括容器所要运行的应用代码以及运行时的配置。Docker 镜像包括一个或者多个只读层（ read-only layers ），因此，镜像一旦被创建就再也不能被修改了。\n一个运行着的Docker 容器是一个镜像的实例（ instantiation ）。从同一个镜像中运行的容器包含有相同的应用代码和运行时依赖。但是不像镜像是静态的，每个运行着的容器都有一个可写层（ writable layer ，也成为容器层 container layer），它位于底下的若干只读层之上。运行时的所有变化，包括对数据和文件的写和更新，都会保存在这个层中。因此，从同一个镜像运行的多个容器包含了不同的容器层。\n四种单节点网络模式\nBridge 模式\nDocker 容器默认使用 bridge 模式的网络。其特点如下：\n\n使用一个 linux bridge，默认为 docker0\n使用 veth 对，一头在容器的网络 namespace 中，一头在 docker0 上\n该模式下Docker Container不具有一个公有IP，因为宿主机的IP地址与veth pair的 IP地址不在同一个网段内\nDocker采用 NAT 方式，将容器内部的服务监听的端口与宿主机的某一个端口port 进行“绑定”，使得宿主机以外的世界可以主动将网络报文发送至容器内部\n外界访问容器内的服务时，需要访问宿主机的 IP 以及宿主机的端口 port\nNAT 模式由于是在三层网络上的实现手段，故肯定会影响网络的传输效率。\n容器拥有独立、隔离的网络栈；让容器和宿主机以外的世界通过NAT建立通信\n\niptables 的 SNTA 规则，使得从容器离开去外界的网络包的源 IP 地址被转换为 Docker 主机的IP地址：\n1234Chain POSTROUTING (policy ACCEPT)target     prot opt source               destinationMASQUERADE  all  --  172.17.0.0/16        0.0.0.0/0MASQUERADE  all  --  172.18.0.0/16        0.0.0.0/0\nHost 模式\nHost 模式并没有为容器创建一个隔离的网络环境。而之所以称之为host模式，是因为该模式下的 Docker 容器会和 host 宿主机共享同一个网络 namespace，故 Docker Container可以和宿主机一样，使用宿主机的eth0，实现和外界的通信。换言之，Docker Container的 IP 地址即为宿主机 eth0 的 IP 地址。其特点包括：\n\n这种模式下的容器没有隔离的 network namespace\n容器的 IP 地址同 Docker host 的 IP 地址\n需要注意容器中服务的端口号不能与 Docker host 上已经使用的端口号相冲突\nhost 模式能够和其它模式共存\n\nContainer 模式\nContainer 网络模式是 Docker 中一种较为特别的网络的模式。处于这个模式下的 Docker 容器会共享其他容器的网络环境，因此，至少这两个容器之间不存在网络隔离，而这两个容器又与宿主机以及除此之外其他的容器存在网络隔离。\nnone 模式\n网络模式为 none，即不为 Docker 容器构造任何网络环境。一旦Docker 容器采用了none 网络模式，那么容器内部就只能使用loopback网络设备，不会再有其他的网络资源。Docker Container的none网络模式意味着不给该容器创建任何网络环境，容器只能使用127.0.0.1的本机网络。\n原文链接：\n# DOCKER基础技术：AUFS\n","plink":"https://zinki.github.io/2018/08/10/AUFS DOCKER基础技术/"},{"title":"AUFS基本原理","date":"2018-07-29T11:30:00.000Z","date_formatted":{"ll":"2018年7月29日","L":"2018/07/29","MM-DD":"07-29"},"updated":"2024-10-11T07:58:30.806Z","content":"AUFS是一种Union File System，所谓UnionFS就是把不同物理位置的目录合并mount到同一个目录中。UnionFS的一个最主要的应用是，把一张CD/DVD和一个硬盘目录给联合 mount在一起，然后，你就可以对这个只读的CD/DVD上的文件进行修改（当然，修改的文件存于硬盘上的目录里）。\n\nAUFS 简介\nAUFS又叫Another UnionFS，后来叫Alternative UnionFS，后来可能觉得不够霸气，叫成Advance UnionFS。是个叫Junjiro Okajima（岡島順治郎）在2006年开发的，AUFS完全重写了早期的UnionFS 1.x，其主要目的是为了可靠性和性能，并且引入了一些新的功能，比如可写分支的负载均衡。AUFS在使用上全兼容UnionFS，而且比之前的UnionFS在稳定性和性能上都要好很多，后来的UnionFS 2.x开始抄AUFS中的功能。但是他居然没有进到Linux主干里，就是因为Linus不让，基本上是因为代码量比较多，而且写得烂（相对于只有3000行的union mount和10000行的UnionFS，以及其它平均下来只有6000行代码左右的VFS，AUFS居然有30000行代码），所以，岡島不断地改进代码质量，不断地提交，不断地被Linus拒掉，所以，到今天AUFS都还进不了Linux主干（今天你可以看到AUFS的代码其实还好了，比起OpenSSL好N倍，要么就是Linus对代码的质量要求非常高，要么就是Linus就是不喜欢AUFS）。\n不过，好在有很多发行版都用了AUFS，比如：Ubuntu 10.04，Debian6.0, Gentoo Live CD支持AUFS，所以，也OK了。\n示例\n好了，扯完这些闲话，我们还是看一个示例吧（环境：Ubuntu 14.04）\n1234567891011121314151617181920$ tree.├── fruits│   ├── apple│   └── tomato└── vegetables    ├── carrots    └── tomato# 创建一个mount目录$ mkdir mnt# 把水果目录和蔬菜目录union mount到 ./mnt目录中$ sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt#  查看./mnt目录$ tree ./mnt./mnt├── apple├── carrots└── tomato\n我们可以看到在./mnt目录下有三个文件，苹果apple、胡萝卜carrots和蕃茄tomato。水果和蔬菜的目录被union到了./mnt目录下了。\n我们来修改一下其中的文件内容：\n12345$ echo mnt &gt; ./mnt/apple$ cat ./mnt/applemnt$ cat ./fruits/applemnt\n上面的示例，我们可以看到./mnt/apple的内容改了，./fruits/apple的内容也改了。\n12345$ echo mnt_carrots &gt; ./mnt/carrots$ cat ./vegetables/carrots$ cat ./fruits/carrotsmnt_carrots\n上面的示例，我们可以看到，我们修改了./mnt/carrots的文件内容，./vegetables/carrots并没有变化，反而是./fruits/carrots的目录中出现了carrots文件，其内容是我们在./mnt/carrots里的内容。\n也就是说，我们在mount aufs命令中，我们没有指它vegetables和fruits的目录权限，默认上来说，命令行上第一个（最左边）的目录是可读可写的，后面的全都是只读的。（一般来说，最前面的目录应该是可写的，而后面的都应该是只读的）\n所以，如果我们像下面这样指定权限来mount aufs，你就会发现有不一样的效果（记得先把上面./fruits/carrots的文件删除了）：\n123456789$ sudo mount -t aufs -o dirs=./fruits=rw:./vegetables=rw none ./mnt$ echo &quot;mnt_carrots&quot; &gt; ./mnt/carrots$ cat ./vegetables/carrotsmnt_carrots$ cat ./fruits/carrotscat: ./fruits/carrots: No such file or directory\n现在，在这情况下，如果我们要修改./mnt/tomato这个文件，那么究竟是哪个文件会被改写？\n1234567$ echo &quot;mnt_tomato&quot; &gt; ./mnt/tomato$ cat ./fruits/tomatomnt_tomato$ cat ./vegetables/tomatoI am a vegetable\n可见，如果有重复的文件名，在mount命令行上，越往前的就优先级越高。\n用处\n那么，这种UnionFS有什么用？\n历史上，有一个叫Knoppix的Linux发行版，其主要用于Linux演示、光盘教学、系统急救，以及商业产品的演示，不需要硬盘安装，直接把CD/DVD上的image运行在一个可写的存储设备上（比如一个U盘上），其实，也就是把CD/DVD这个文件系统和USB这个可写的系统给联合mount起来，这样你对CD/DVD上的image做的任何改动都会在被应用在U盘上，于是乎，你可以对CD/DVD上的内容进行任意的修改，因为改动都在U盘上，所以你改不坏原来的东西。\n我们可以再发挥一下想像力，你也可以把一个目录，比如你的源代码，作为一个只读的template，和另一个你的working directory给union在一起，然后你就可以做各种修改而不用害怕会把源代码改坏了。有点像一个ad hoc snapshot。\nDocker把UnionFS的想像力发挥到了容器的镜像。你是否还记得我在介绍Linux Namespace上篇中用mount namespace和chroot山寨了一镜像。现在当你看过了这个UnionFS的技术后，你是不是就明白了，你完全可以用UnionFS这样的技术做出分层的镜像来。\n下图来自Docker的官方文档Layer，其很好的展示了Docker用UnionFS搭建的分层镜像。\n\n参考\nDOCKER基础技术：AUFS\n","plink":"https://zinki.github.io/2018/07/29/AUFS基本原理/"},{"title":"Transactional注解不起作用如何排查","date":"2018-07-17T11:00:00.000Z","date_formatted":{"ll":"2018年7月17日","L":"2018/07/17","MM-DD":"07-17"},"updated":"2024-10-10T08:03:05.460Z","content":"当@Transactional不起作用如何排查问题\n可以按照以下几个步骤逐一确认：\n\n\n首先要看数据库本身对应的库、表所设置的引擎是什么。MyIsam不支持事务，如果需要，则必须改为InnnoDB。\n\n\n@Transactional所注解的方法是否为public\n\n\n@Transactional所注解的方法所在的类，是否已经被注解@Service或@Component等。\n\n\n需要调用该方法，且需要支持事务特性的调用方是在在 @Transactional所在的类的外面。注意：类内部的其他方法调用这个注解了@Transactional的方法，事务是不会起作用的。\n\n\n注解为事务范围的方法中，事务的回滚仅仅对于unchecked的异常有效。对于checked异常无效。也就是说事务回滚仅仅发生在出现RuntimeException或Error的时候。\n\n\n如果希望一般的异常也能触发事务回滚，需要在注解了@Transactional的方法上，将@Transactional回滚参数设为：\n1@Transactional(rollbackFor=Exception.class)\n\n非springboot项目，需要检查spring配置文件xml中：\n\n\n扫描包范围是否配置好，否则不会在启动时spring容器中创建和加载对应的bean对象。\n\n1&lt;context:component-scan base-package=&quot;com.happybks&quot; &gt;&lt;/context:component-scan&gt;\n\n事务是否已经配置成开启\n\n1&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; proxy-target-class=&quot;true&quot;/&gt;\n\nspringboot项目有两个可选配置，默认已经支持事务了，可以写也可以不写。\n\n\nspringboot启动类，即程序入口类，需要注解@EnableTransactionManagement\n\n123456789@EnableTransactionManagement@SpringBootApplicationpublic class PetsApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(PetsApplication.class, args);\t&#125;&#125; \n\nspringboot配置文件application.yml中，可以配置上失败回滚：\n\n1234567891011121314spring:  profiles:    active: prod  datasource:    driver-class-name: com.mysql.jdbc.Driver    url: jdbc:mysql://127.0.0.1:3306/spbdb    username: root    password:  jpa:    hibernate:      ddl-auto:    show-sql: true  transaction:    rollback-on-commit-failure: true\n参考\n当@Transactional不起作用如何排查问题\n","plink":"https://zinki.github.io/2018/07/17/Transactional注解不起作用如何排查/"},{"title":"Java字节码相关知识","date":"2018-06-15T13:00:00.000Z","date_formatted":{"ll":"2018年6月15日","L":"2018/06/15","MM-DD":"06-15"},"updated":"2024-10-10T08:03:05.448Z","content":"字节码就是Java文件通过编译器编译成的.class文件\nJava是一门静态语言，通常，我们需要的class在编译的时候就已经生成了，为什么有时候我们还想在运行时动态生成class呢？\n因为在有些时候，我们还真得在运行时为一个类动态创建子类。比如，编写一个ORM框架，如何得知一个简单的JavaBean是否被用户修改过呢？\n以User为例：\n12345678910111213141516public class User &#123;    private String id;    private String name;public String getId() &#123;        return id;    &#125;public void setId(String id) &#123;        this.id = id;    &#125;public String getName() &#123;        return name;    &#125;public void setName(String name) &#123;        this.name = name;    &#125;&#125;\n其实UserProxy实现起来很简单，就是创建一个User的子类，覆写所有setXxx()方法，做个标记就可以了：\n1234567891011121314151617181920public class UserProxy extends User &#123;    private boolean dirty;public boolean isDirty() &#123;        return this.dirty;    &#125;public void setDirty(boolean dirty) &#123;        this.dirty = dirty;    &#125;@Override    public void setId(String id) &#123;        super.setId(id);        setDirty(true);    &#125;@Override    public void setName(String name) &#123;        super.setName(name);        setDirty(true);    &#125;&#125;\n但是这个UserProxy就必须在运行时动态创建出来了，因为编译时ORM框架根本不知道User类。\n现在问题来了，动态生成字节码，难度有多大？\n如果我们要自己直接输出二进制格式的字节码，在完成这个任务前，必须先认真阅读JVM规范第四章，详细了解class文件结构。估计读完规范后，两个月过去了。\n所以，第一种方法，自己动手，从零开始创建字节码，理论上可行，实际上很难。\n第二种方法，使用已有的一些能操作字节码的库，帮助我们创建class。\n目前，能够操作字节码的开源库主要有CGLIB和Javassist两种，它们都提供了比较高级的API来操作字节码，最后输出为class文件。\n比如CGLib，典型的用法如下：\n123456789Enhancer e = new Enhancer();e.setSuperclass(...);e.setStrategy(new DefaultGeneratorStrategy() &#123;    protected ClassGenerator transform(ClassGenerator cg) &#123;        return new TransformingGenerator(cg,            new AddPropertyTransformer(new String[]&#123; &quot;foo&quot; &#125;,                    new Class[] &#123; Integer.TYPE &#125;));    &#125;&#125;);Object obj = e.create();\n比自己生成class要简单，但是，要学会它的API还是得花大量的时间，并且，上面的代码很难看懂对不对？\n有木有更简单的方法？\n有！\n换一个思路，如果我们能创建UserProxy.java这个源文件，再调用Java编译器，直接把源码编译成class，再加载进虚拟机，任务完成！\n毕竟，创建一个字符串格式的源码是很简单的事情，就是拼字符串嘛，高级点的做法可以用一个模版引擎。\n如何编译？\nJava的编译器是javac，但是，在很早很早的时候，Java的编译器就已经用纯Java重写了，自己能编译自己，行业黑话叫“自举”。从Java 1.6开始，编译器接口正式放到JDK的公开API中，于是，我们不需要创建新的进程来调用javac，而是直接使用编译器API来编译源码。\n使用起来也很简单：\n12JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();int compilationResult = compiler.run(null, null, null, &#x27;/path/to/Test.java&#x27;);\n这么写编译是没啥问题，问题是我们在内存中创建了Java代码后，必须先写到文件，再编译，最后还要手动读取class文件内容并用一个ClassLoader加载。\n有木有更简单的方法？\n有！\n其实Java编译器根本不关心源码的内容是从哪来的，你给它一个String当作源码，它就可以输出byte[]作为class的内容。\n所以，我们需要参考Java Compiler API的文档，让Compiler直接在内存中完成编译，输出的class内容就是byte[]。\n代码改造如下：\n12345678910Map&lt;String, byte[]&gt; results;JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();StandardJavaFileManager stdManager = compiler.getStandardFileManager(null, null, null);try (MemoryJavaFileManager manager = new MemoryJavaFileManager(stdManager)) &#123;    JavaFileObject javaFileObject = manager.makeStringSource(fileName, source);    CompilationTask task = compiler.getTask(null, manager, null, null, null, Arrays.asList(javaFileObject));    if (task.call()) &#123;        results = manager.getClassBytes();    &#125;&#125;\n上述代码的几个关键在于：\n用MemoryJavaFileManager替换JDK默认的StandardJavaFileManager，以便在编译器请求源码内容时，不是从文件读取，而是直接返回String；\n用MemoryOutputJavaFileObject替换JDK默认的SimpleJavaFileObject，以便在接收到编译器生成的byte[]内容时，不写入class文件，而是直接保存在内存中。\n最后，编译的结果放在Map&lt;String, byte[]&gt;中，Key是类名，对应的byte[]是class的二进制内容。\n为什么编译后不是一个byte[]呢？\n因为一个.java的源文件编译后可能有多个.class文件！只要包含了静态类、匿名类等，编译出的class肯定多于一个。\n如何加载编译后的class呢？\n加载class相对而言就容易多了，我们只需要创建一个ClassLoader，覆写findClass()方法：\n12345678910111213141516class MemoryClassLoader extends URLClassLoader &#123;Map&lt;String, byte[]&gt; classBytes = new HashMap&lt;String, byte[]&gt;();public MemoryClassLoader(Map&lt;String, byte[]&gt; classBytes) &#123;        super(new URL[0], MemoryClassLoader.class.getClassLoader());        this.classBytes.putAll(classBytes);    &#125;@Override    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;        byte[] buf = classBytes.get(name);        if (buf == null) &#123;            return super.findClass(name);        &#125;        classBytes.remove(name);        return defineClass(name, buf, 0, buf.length);    &#125;&#125;","plink":"https://zinki.github.io/2018/06/15/Java字节码相关知识/"},{"title":"堆外内存相关知识","date":"2018-05-11T11:20:00.000Z","date_formatted":{"ll":"2018年5月11日","L":"2018/05/11","MM-DD":"05-11"},"updated":"2024-10-11T08:03:54.461Z","content":"堆外内存是把内存对象分配在Java虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机），这样做的结果就是能够在一定程度上减少垃圾回收对应用程序造成的影响。\n定义\n创建Java.nio.DirectByteBuffer时分配的内存。\n优缺点\n优点： 提升了IO效率（避免了数据从用户态向内核态的拷贝）；减少了GC次数（节约了大量的堆内内存）。\n缺点：分配和回收堆外内存比分配和回收堆内存耗时；（解决方案：通过对象池避免频繁地创建和销毁堆外内存）\n为什么堆外内存能够提升IO效率？\n堆内内存由JVM管理，属于“用户态”；而堆外内存由OS管理，属于“内核态”。如果从堆内向磁盘写数据时，数据会被先复制到堆外内存，即内核缓冲区，然后再由OS写入磁盘，使用堆外内存避免了数据从用户内向内核态的拷贝。\n申请\nJDK的ByteBuffer类提供了一个接口allocateDirect(int capacity)进行堆外内存的申请，底层通过unsafe.allocateMemory(size)实现。Netty、Mina等框架提供的接口也是基于ByteBuffer封装的。\n释放\nJDK中使用DirectByteBuffer对象来表示堆外内存，每个DirectByteBuffer对象在初始化时，都会创建一个对应的Cleaner对象，用于保存堆外内存的元信息（开始地址、大小和容量等），当DirectByteBuffer被GC回收后，Cleaner对象被放入ReferenceQueue中，然后由ReferenceHandler守护线程调用unsafe.freeMemory(address)，回收堆外内存。\n主动回收(推荐)\n对于Sun的JDK，只要从DirectByteBuffer里取出那个sun.misc.Cleaner，然后调用它的clean()就行；\n基于 GC 回收：堆内的DirectByteBuffer对象被GC时，会调用cleaner回收其引用的堆外内存。问题是YGC只会将将新生代里的不可达的DirectByteBuffer对象及其堆外内存回收，如果有大量的DirectByteBuffer对象移到了old区，但是又一直没有做CMS GC或者FGC，而只进行YGC，物理内存会被慢慢耗光，触发OOM；\n堆外内存溢出\nJava.nio.DirectByteBuffer所需的内存超过了物理分配的堆外内存，出现”java.lang.OutOfMemoryError: Direct buffer memory”。\n使用注意\njava.nio.DirectByteBuffer对象在创建过程中会先通过Unsafe接口直接通过os::malloc来分配内存，然后将内存的起始地址和大小存到java.nio.DirectByteBuffer对象里，这样就可以直接操作这些内存。这些内存只有在DirectByteBuffer回收掉之后才有机会被回收，因此如果这些对象大部分都移到了old，但是一直没有触发CMS GC或者Full GC，那么悲剧将会发生，因为你的物理内存被他们耗尽了，因此为了避免这种悲剧的发生，通过-XX:MaxDirectMemorySize来指定最大的堆外内存大小，当使用达到了阈值的时候将调用System.gc来做一次full gc，以此来回收掉没有被使用的堆外内存。\n堆外内存默认大小\n\n堆外内存默认值： (-Xmx值) - (1个survivor大小)\n\n关于堆外内存的回收\n堆外内存的回收其实依赖于我们的GC机制(堆外内存不会对GC造成什么影响)\n首先我们要知道在java层面和我们在堆外分配的这块内存关联的只有与之关联的DirectByteBuffer对象了，它记录了这块内存的基地址以及大小，那么既然和GC也有关，那就是GC能通过操作DirectByteBuffer对象来间接操作对应的堆外内存了。\nDirectByteBuffer对象在创建的时候关联了一个PhantomReference，说到PhantomReference它其实主要是用来跟踪对象何时被回收的，它不能影响GC决策.\nGC过程中如果发现某个对象除了只有PhantomReference引用它之外，并没有其他的地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在GC完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理, 而DirectByteBuffer关联的PhantomReference是PhantomReference的一个子类，在最终的处理里会通过Unsafe的free接口来释放DirectByteBuffer对应的堆外内存块\n\n为什么Cleaner对象能够被放入ReferenceQueue中？\nCleaner对象关联了一个PhantomReference引用，如果GC过程中某个对象除了只有PhantomReference引用它之外，并没有其他地方引用它了，那将会把这个引用放到java.lang.ref.Reference.pending队列里，在GC完毕的时候通知ReferenceHandler这个守护线程去执行一些后置处理，在最终的处理里会通过Unsafe的free接口来释放DirectByteBuffer对应的堆外内存块。\n\n为什么要主动调用System.gc\nSystem.gc()会对新生代的老生代都会进行内存回收，这样会比较彻底地回收DirectByteBuffer对象以及他们关联的堆外内存.\nDirectByteBuffer对象本身其实是很小的，但是它后面可能关联了一个非常大的堆外内存，因此我们通常称之为冰山对象.\n我们做ygc的时候会将新生代里的不可达的DirectByteBuffer对象及其堆外内存回收了，但是无法对old里的DirectByteBuffer对象及其堆外内存进行回收，这也是我们通常碰到的最大的问题.\n如果有大量的DirectByteBuffer对象移到了old，但是又一直没有做cms gc或者full gc，而只进行ygc，那么我们的物理内存可能被慢慢耗光，但是我们还不知道发生了什么，因为heap明明剩余的内存还很多(前提是我们禁用了System.gc – JVM参数DisableExplicitGC)。\n","plink":"https://zinki.github.io/2018/05/11/堆外内存相关知识/"},{"title":"Spring boot配置","date":"2018-04-09T12:00:00.000Z","date_formatted":{"ll":"2018年4月9日","L":"2018/04/09","MM-DD":"04-09"},"updated":"2024-10-10T08:03:05.459Z","content":"\n\nThe Spring Boot CLI is a command line tool that can be used if you want to quickly prototype with Spring. It allows you to run Groovy scripts, which means that you have a familiar Java-like syntax, without so much boilerplate code.\nSDKMAN! (The Software Development Kit Manager) can be used for managing multiple versions of various binary SDKs, including Groovy and the Spring Boot CLI. Get SDKMAN! from sdkman.io and install Spring Boot with\n123$ sdk install springboot$ spring --versionSpring Boot v2.0.0.M5\n\nSpring Boot 最重要的功能是：自动配置。\n为什么说是自动配置？\nSpring Boot 的开启注解是：@SpringBootApplication，其实它就是由下面三个注解组成的：\n123• @Configuration• @ComponentScan• @EnableAutoConfiguration\n上面三个注解，前面两个都是 Spring 自带的，和 Spring Boot 无关，所以说上面的回答的不是在点上。具体请看这篇文章：Spring Boot 最核心的 3 个注解详解。\n所以说 Spring Boot 最最核心的就是这个 @EnableAutoConfiguration 注解了，它能根据类路径下的 jar 包和配置动态加载配置和注入bean。\n举个例子，比如我在 lib 下放一个 druid 连接池的 Jar 包，然后在 application.yml 文件配置 druid 相关的参数，Spring Boot 就能够自动配置所有我们需要的东西，如果我把 jar 包拿掉或者把参数去掉，那 Spring Boot 就不会自动配置。\n这样我们就能把许多功能做成公共的自动配置的启动器（starters），其实 druid 连接池就是这么做的，它提供了针对 Spring Boot 的启动器：druid-spring-boot-starter。\n有了这个自动配置的启动器，我们就能非常简单的使用它，\n先添加 Jar 包依赖：\n12345&lt;dependency&gt;   &lt;groupId&gt;com.alibaba&lt;/groupId&gt;   &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;   &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;\n再添加相关参数：\n1234spring.datasource.url= spring.datasource.username=spring.datasource.password=……\n如果是传统的项目，我们要自己手动写一大堆的配置，而且还不灵活，有了这个启动器，我们就可以做到简单集成\n","plink":"https://zinki.github.io/2018/04/09/Spring boot 配置/"},{"title":"常用正则表达式","date":"2018-03-17T13:00:00.000Z","date_formatted":{"ll":"2018年3月17日","L":"2018/03/17","MM-DD":"03-17"},"updated":"2024-10-10T08:03:05.467Z","content":"\n校验数字的表达式\n数字：^[0-9]*$\nn位的数字：^\\d&#123;n&#125;$\n至少n位的数字：^\\d&#123;n,&#125;$\nm-n位的数字：^\\d&#123;m,n&#125;$\n零和非零开头的数字：^(0|[1-9][0-9]*)$\n非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(\\.[0-9]&#123;1,2&#125;)?$\n带1-2位小数的正数或负数：^(\\-)?\\d+(\\.\\d&#123;1,2&#125;)$\n正数、负数、和小数：^(\\-|\\+)?\\d+(\\.\\d+)?$\n有两位小数的正实数：^[0-9]+(\\.[0-9]&#123;2&#125;)?$\n有1~3位小数的正实数：^[0-9]+(\\.[0-9]&#123;1,3&#125;)?$\n非零的正整数：^[1-9]\\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\\+?[1-9][0-9]*$\n非零的负整数：^\\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\\d*$\n非负整数：^\\d+$ 或 ^[1-9]\\d*|0$\n非正整数：^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$\n非负浮点数：^\\d+(\\.\\d+)?$ 或 ^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0$\n非正浮点数：^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*))|0?\\.0+|0$\n正浮点数：^[1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*$ 或 ^(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*))$\n负浮点数：^-([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*)$ 或 ^(-(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*)))$\n浮点数：^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d*\\.\\d*|0\\.\\d*[1-9]\\d*|0?\\.0+|0)$\n校验字符的表达式\n汉字：^[\\u4e00-\\u9fa5]&#123;0,&#125;$\n英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$\n长度为3-20的所有字符：^.&#123;3,20&#125;$\n由26个英文字母组成的字符串：^[A-Za-z]+$\n由26个大写英文字母组成的字符串：^[A-Z]+$\n由26个小写英文字母组成的字符串：^[a-z]+$\n由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$\n由数字、26个英文字母或者下划线组成的字符串：^\\w+$ 或 ^\\w&#123;3,20&#125;$\n中文、英文、数字包括下划线：^[\\u4E00-\\u9FA5A-Za-z0-9_]+$\n中文、英文、数字但不包括下划线等符号：^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 ^[\\u4E00-\\u9FA5A-Za-z0-9]&#123;2,20&#125;$\n可以输入含有^%&amp;',;=?$&quot;等字符：[^%&amp;',;=?$\\x22]+\n禁止输入含有~的字符：[^~\\x22]+\n特殊需求表达式\nEmail地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$\n域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(\\.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+\\.?\nInternetURL：[a-zA-z]+://[^\\s]* 或 ^http://([\\w-]+\\.)+[\\w-]+(/[\\w-./?%&amp;=]*)?$\n手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|4|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\\d&#123;8&#125;$\n电话号码(“XXX-XXXXXXX”、“XXXX-XXXXXXXX”、“XXX-XXXXXXX”、“XXX-XXXXXXXX”、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\\(\\d&#123;3,4&#125;-)|\\d&#123;3.4&#125;-)?\\d&#123;7,8&#125;$\n国内电话号码(0511-4405222、021-87888822)：\\d&#123;3&#125;-\\d&#123;8&#125;|\\d&#123;4&#125;-\\d&#123;7&#125;\n电话号码正则表达式（支持手机号码，3-4位区号，7-8位直播号码，1－4位分机号）: ((\\d&#123;11&#125;)|^((\\d&#123;7,8&#125;)|(\\d&#123;4&#125;|\\d&#123;3&#125;)-(\\d&#123;7,8&#125;)|(\\d&#123;4&#125;|\\d&#123;3&#125;)-(\\d&#123;7,8&#125;)-(\\d&#123;4&#125;|\\d&#123;3&#125;|\\d&#123;2&#125;|\\d&#123;1&#125;)|(\\d&#123;7,8&#125;)-(\\d&#123;4&#125;|\\d&#123;3&#125;|\\d&#123;2&#125;|\\d&#123;1&#125;))$)\n身份证号(15位、18位数字)，最后一位是校验位，可能为数字或字符X：(^\\d&#123;15&#125;$)|(^\\d&#123;18&#125;$)|(^\\d&#123;17&#125;(\\d|X|x)$)\n帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$\n密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\\w&#123;5,17&#125;$\n强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在 8-10 之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z])[a-zA-Z0-9]&#123;8,10&#125;$\n强密码(必须包含大小写字母和数字的组合，可以使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$\n日期格式：^\\d&#123;4&#125;-\\d&#123;1,2&#125;-\\d&#123;1,2&#125;\n一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$\n一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$\n钱的输入格式：\n有四种钱的表示形式我们可以接受:“10000.00” 和 “10,000.00”, 和没有 “分” 的 “10000” 和 “10,000”：^[1-9][0-9]*$\n这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$\n一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$\n这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧。下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$\n\n必须说明的是,小数点后面至少应该有1位数,所以&quot;10.“是不通过的,但是 “10” 和 “10.2” 是通过的：^[0-9]+(.[0-9]&#123;2&#125;)?$\n这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]&#123;1,2&#125;)?$\n这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*(.[0-9]&#123;1,2&#125;)?$\n1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*)(.[0-9]&#123;1,2&#125;)?$\n备注：这就是最终结果了,别忘了”+“可以用”*&quot;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里\n\nxml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\\\.[x|X][m|M][l|L]$\n中文字符的正则表达式：[\\u4e00-\\u9fa5]\n双字节字符：[^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))\n空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行)\nHTML标记的正则表达式：&lt;(\\S*?)[^&gt;]*&gt;.*?|&lt;.*? /&gt; ( 首尾空白字符的正则表达式：^\\s*|\\s*$或(^\\s*)|(\\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)\n腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)\n中国邮政编码：[1-9]\\d&#123;5&#125;(?!\\d) (中国邮政编码为6位数字)\nIP地址：((?:(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d)\\\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\\\d|[01]?\\\\d?\\\\d))\n其他\n网上找不到合适的匹配HTML便签的正则,jquery.validate支持自定义校验:\n1234$.validator.addMethod(&quot;checkHtml&quot;,function(value,element,params)&#123;                  var checkHtml = /&lt;(\\S*?)[^&gt;]*&gt;.*?|&lt;.*? \\/&gt;/;                  return this.optional(element)||(!checkHtml.test(value));              &#125;,&quot;请输入正确格式&quot;);  \n校验金额:/(^[1-9]([0-9]+)?(\\.[0-9]&#123;1,2&#125;)?$)|(^(0)&#123;1&#125;$)|(^[0-9]\\.[0-9]([0-9])?$)/\n正整数和0:/^([1-9]\\d*|[0]&#123;1,1&#125;)$/\n参考\n正则表达式在线测试\n","plink":"https://zinki.github.io/2018/03/17/常用正则表达式/"},{"title":"HashMap死循环问题","date":"2018-03-09T12:07:00.000Z","date_formatted":{"ll":"2018年3月9日","L":"2018/03/09","MM-DD":"03-09"},"updated":"2024-10-10T08:03:05.444Z","content":"HashMap在并发执行put操作后get操作会引起死循环, 是因为多线程会导致 HashMap的 Entry链表形成环形数据结构, 一旦形成环形数据结构, Entry 的 next 节点永远不为空, 就会产生死循环获取Entry。\nHashMap通常会用一个指针数组（假设为table[]）来做分散所有的key，当一个key被加入时，会通过Hash算法通过key算出这个数组的下标i，然后就把这个&lt;key, value&gt;插到table[i]中，如果有两个不同的key被算在了同一个i，那么就叫冲突，又叫碰撞，这样会在table[i]上形成一个链表。\n我们知道，如果table[]的尺寸很小，比如只有2个，如果要放进10个keys的话，那么碰撞非常频繁，于是一个O(1)的查找算法，就变成了链表遍历，性能变成了O(n)，这是Hash表的缺陷（可参看《Hash Collision DoS 问题》）。\n所以，Hash表的尺寸和容量非常的重要。一般来说，Hash表这个容器当有数据要插入时，都会检查容量有没有超过设定的thredhold，如果超过，需要增大Hash表的尺寸，但是这样一来，整个Hash表里的无素都需要被重算一遍。这叫rehash，这个成本相当的大。\n为何出现死循环？\n大家都知道，HashMap采用链表解决Hash冲突，具体的HashMap的分析可以参考一下Java集合—HashMap源码剖析 的分析。因为是链表结构，那么就很容易形成闭合的链路，这样在循环的时候只要有线程对这个HashMap进行get操作就会产生死循环。但是，我好奇的是，这种闭合的链路是如何形成的呢。在单线程情况下，只有一个线程对HashMap的数据结构进行操作，是不可能产生闭合的回路的。那就只有在多线程并发的情况下才会出现这种情况，那就是在put操作的时候，如果size&gt;initialCapacity*loadFactor那么这时候HashMap就会进行rehash操作，随之HashMap的结构就会发生翻天覆地的变化。很有可能就是在两个线程在这个时候同时触发了rehash操作，产生了闭合的回路。\n下面我们从源码中一步一步地分析这种回路是如何产生的。先看一下put操作：\n存储数据put\n1234567891011121314151617181920212223public V put(K key, V value) &#123;        if (table == EMPTY_TABLE) &#123;            inflateTable(threshold);        &#125;        if (key == null)            return putForNullKey(value);        int hash = hash(key);        int i = indexFor(hash, table.length);        for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123;            Object k;            if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123;                V oldValue = e.value;                e.value = value;                e.recordAccess(this);                return oldValue;            &#125;        &#125;         modCount++;        addEntry(hash, key, value, i);        return null;    &#125;\n当我们往HashMap中put元素的时候，先根据key的hash值得到这个元素在数组中的位置（即下标），然后就可以把这个元素放到对应的位置中了。 如果这个元素所在的位置上已经存放有其他元素了，那么在同一个位子上的元素将以链表的形式存放，新加入的放在链头，而先前加入的放在链尾。\n检查容量是否超标addEntry\n123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123;        if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123;            resize(2 * table.length);            hash = (null != key) ? hash(key) : 0;            bucketIndex = indexFor(hash, table.length);        &#125;         createEntry(hash, key, value, bucketIndex);    &#125;\n可以看到，如果现在size已经超过了threshold，那么就要进行resize操作,新建一个更大尺寸的hash表，然后把数据从老的Hash表中迁移到新的Hash表中：\n调整Hash表大小resize\n1234567891011121314void resize(int newCapacity) &#123;       Entry[] oldTable = table;       int oldCapacity = oldTable.length;       if (oldCapacity == MAXIMUM_CAPACITY) &#123;           threshold = Integer.MAX_VALUE;           return;       &#125;       Entry[] newTable = new Entry[newCapacity];       transfer(newTable, initHashSeedAsNeeded(newCapacity));       table = newTable;       threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);   &#125;\n\n当table[]数组容量较小，容易产生哈希碰撞，所以，Hash表的尺寸和容量非常的重要。一般来说，Hash表这个容器当有数据要插入时，都会检查容量有没有超过设定的thredhold，如果超过，需要增大Hash表的尺寸，这个过程称为resize。\n\n多个线程同时往HashMap添加新元素时，多次resize会有一定概率出现死循环，因为每次resize需要把旧的数据映射到新的哈希表，这一部分代码在HashMap#transfer() 方法，如下：\n12345678910111213141516void transfer(Entry[] newTable, boolean rehash) &#123;        int newCapacity = newTable.length;        for (Entry&lt;K,V&gt; e : table) &#123;            while(null != e) &#123;                Entry&lt;K,V&gt; next = e.next;                if (rehash) &#123;                    e.hash = null == e.key ? 0 : hash(e.key);                &#125;                int i = indexFor(e.hash, newCapacity);                e.next = newTable[i];                newTable[i] = e;                e = next;            &#125;        &#125;    &#125;\ntransfer部分代码是导致多线程使用hashmap出现CUP使用率骤增，从而多个线程阻塞的罪魁祸首。\n解决方案\nSun认为这不是一个问题，HashMap不支持并发操作，若有并发需求使用ConcurrentHashmap。\n参考\nJAVA HASHMAP的死循环\n","plink":"https://zinki.github.io/2018/03/09/HashMap死循环问题/"},{"title":"Javascript引擎工作原理","date":"2018-02-06T14:09:00.000Z","date_formatted":{"ll":"2018年2月6日","L":"2018/02/06","MM-DD":"02-06"},"updated":"2024-10-10T08:03:05.447Z","content":"\n什么是JavaScript解析引擎？\n简单地说，JavaScript解析引擎就是能够“读懂”JavaScript代码，并准确地给出代码运行结果的一段程序。比方说，当你写了 var a = 1 + 1; 这样一段代码，JavaScript引擎做的事情就是看懂（解析）你这段代码，并且将a的值变为2。\n学过编译原理的人都知道，对于静态语言来说（如Java、C++、C），处理上述这些事情的叫编译器（Compiler），相应地对于JavaScript这样的动态语言则叫解释器（Interpreter）。这两者的区别用一句话来概括就是：编译器是将源代码编译为另外一种代码（比如机器码，或者字节码），而解释器是直接解析并将代码运行结果输出。 比方说，firebug的console就是一个JavaScript的解释器。\n但是，现在很难去界定说，JavaScript引擎它到底算是个解释器还是个编译器，因为，比如像V8（Chrome的JS引擎），它其实为了提高 JS的运行性能，在运行之前会先将JS编译为本地的机器码（native machine code），然后再去执行机器码（这样速度就快很多），相信大家对JIT（Just In Time Compilation）一定不陌生吧。\n我个人认为，不需要过分去强调JavaScript解析引擎到底是什么，了解它究竟做了什么事情我个人认为就可以了。对于编译器或者解释器究竟是如何看懂代码的，翻出大学编译课的教材就可以了。\n这里还要强调的就是，JavaScript引擎本身也是程序，代码编写而成。比如V8就是用C/C++写的。\nJavaScript解析引擎与ECMAScript是什么关系？\nJavaScript引擎是一段程序，我们写的JavaScript代码也是程序，如何让程序去读懂程序呢？这就需要定义规则。比如，之前提到的var a = 1 + 1;，它表示：\n1234567左边var代表了这是申明（declaration），它申明了a这个变量右边的+表示要将1和1做加法中间的等号表示了这是个赋值语句最后的分号表示这句语句结束了\n上述这些就是规则，有了它就等于有了衡量的标准，JavaScript引擎就可以根据这个标准去解析JavaScript代码了。那么这里的 ECMAScript就是定义了这些规则。其中ECMAScript 262这份文档，就是对JavaScript这门语言定义了一整套完整的标准。其中包括：\nvar，if，else，break，continue等是JavaScript的关键词\n\nabstract，int，long等是JavaScript保留词\n\n怎么样算是数字、怎么样算是字符串等等\n\n定义了操作符（+，-，&gt;，&lt;等）\n\n定义了JavaScript的语法\n\n定义了对表达式，语句等标准的处理算法，比如遇到==该如何处理\n\n⋯⋯\n\n标准的JavaScript引擎就会根据这套文档去实现，注意这里强调了标准，因为也有不按照标准来实现的，比如IE的JS引擎。这也是为什么JavaScript会有兼容性的问题。至于为什么IE的JS引擎不按照标准来实现，就要说到浏览器大战了，这里就不赘述了，自行Google之。\n所以，简单的说，ECMAScript定义了语言的标准，JavaScript引擎根据它来实现，这就是两者的关系。\nJavaScript解析引擎与浏览器又是什么关系？\n简单地说，JavaScript引擎是浏览器的组成部分之一。因为浏览器还要做很多别的事情，比如解析页面、渲染页面、Cookie管理、历史记录 等等。那么，既然是组成部分，因此一般情况下JavaScript引擎都是浏览器开发商自行开发的。比如：IE9的Chakra、Firefox的 TraceMonkey、Chrome的V8等等。\n从而也看出，不同浏览器都采用了不同的JavaScript引擎。因此，我们只能说要深入了解哪个JavaScript引擎。\n参考\nSpring Cloud OpenFeign自定义日志\n","plink":"https://zinki.github.io/2018/02/06/Javascript引擎工作原理/"},{"title":"秒杀方案设计","date":"2018-01-17T12:05:00.000Z","date_formatted":{"ll":"2018年1月17日","L":"2018/01/17","MM-DD":"01-17"},"updated":"2024-10-10T08:03:05.473Z","content":"秒杀的核心问题就是极高并发处理，由于系统要在瞬时承受平时数十倍甚至上百倍的流量，这往往超出系统上限，因此处理秒杀的核心思路是流控和性能优化\n秒杀带来了什么？\n秒杀或抢购活动一般会经过【预约】【抢订单】【支付】这3个大环节，而其中【抢订单】这个环节是最考验业务提供方的抗压能力的。\n抢订单环节一般会带来2个问题：\n\n高并发\n\n比较火热的秒杀在线人数都是10w起的，如此之高的在线人数对于网站架构从前到后都是一种考验。\n2. 超卖\n任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购活动都要面临的难题。\n如何解决？\n首先，产品解决方案我们就不予讨论了。我们只讨论技术解决方案\n1、前端\n面对高并发的抢购活动，前端常用的三板斧是【扩容】【静态化】【限流】\nA：扩容\n加机器，这是最简单的方法，通过增加前端池的整体承载量来抗峰值。\nB：静态化\n将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。\nC：限流\n一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。\n或者活动入口的时候增加游戏或者问题环节进行消峰操作。\nD：有损服务\n最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。\n2、后端\n那么后端的数据库在高并发和超卖下会遇到什么问题呢？主要会有如下3个问题：（主要讨论写的问题，读的问题通过增加cache可以很容易的解决）\nI：　首先MySQL自身对于高并发的处理性能就会出现问题，一般来说，MySQL的处理性能会随着并发thread上升而上升，但是到了一定的并发度之后会出现明显的拐点，之后一路下降，最终甚至会比单thread的性能还要差。\nII： 其次，超卖的根结在于减库存操作是一个事务操作，需要先select，然后insert，最后update -1。最后这个-1操作是不能出现负数的，但是当多用户在有库存的情况下并发操作，出现负数这是无法避免的。\nIII：最后，当减库存和高并发碰到一起的时候，由于操作的库存数目在同一行，就会出现争抢InnoDB行锁的问题，导致出现互相等待甚至死锁，从而大大降低MySQL的处理性能，最终导致前端页面出现超时异常。\n针对上述问题，如何解决呢？ 我们先看眼淘宝的高大上解决方案：\n\n\n关闭死锁检测，提高并发处理性能。\n\n\n修改源代码，将排队提到进入引擎层前，降低引擎层面的并发度。\n\n\n组提交，降低server和引擎的交互次数，降低IO消耗。\n\n\n以上内容可以参考丁奇在DTCC2013上分享的《秒杀场景下MySQL的低效》一文。在文中所有优化都使用后，TPS在高并发下，从原始的150飙升到8.5w，提升近566倍，非常吓人！！！\n不过结合我们的实际，改源码这种高大上的解决方案显然有那么一点不切实际。于是小伙伴们需要讨论出一种适合我们实际情况的解决方案。以下就是我们讨论的解决方案：\n首先设定一个前提，为了防止超卖现象，所有减库存操作都需要进行一次减后检查，保证减完不能等于负数。（由于MySQL事务的特性，这种方法只能降低超卖的数量，但是不可能完全避免超卖）\n1update number set x=x-1 where (x -1 ) &gt;= 0;\n解决方案1：\n将存库从MySQL前移到Redis中，所有的写操作放到内存中，由于Redis中不存在锁故不会出现互相等待，并且由于Redis的写性能和读性能都远高于MySQL，这就解决了高并发下的性能问题。然后通过队列等异步手段，将变化的数据异步写入到DB中。\n优点：解决性能问题\n缺点：没有解决超卖问题，同时由于异步写入DB，存在某一时刻DB和Redis中数据不一致的风险。\n解决方案2：\n引入队列，然后将所有写DB操作在单队列中排队，完全串行处理。当达到库存阀值的时候就不在消费队列，并关闭购买功能。这就解决了超卖问题。\n优点：解决超卖问题，略微提升性能。\n缺点：性能受限于队列处理机处理性能和DB的写入性能中最短的那个，另外多商品同时抢购的时候需要准备多条队列。\n解决方案3：\n将写操作前移到MC中，同时利用MC的轻量级的锁机制CAS来实现减库存操作。\n优点：读写在内存中，操作性能快，引入轻量级锁之后可以保证同一时刻只有一个写入成功，解决减库存问题。\n缺点：没有实测，基于CAS的特性不知道高并发下是否会出现大量更新失败？不过加锁之后肯定对并发性能会有影响。\n解决方案4：\n将提交操作变成两段式，先申请后确认。然后利用Redis的原子自增操作（相比较MySQL的自增来说没有空洞），同时利用Redis的事务特性来发号，保证拿到小于等于库存阀值的号的人都可以成功提交订单。然后数据异步更新到DB中。\n优点：解决超卖问题，库存读写都在内存中，故同时解决性能问题。\n缺点：由于异步写入DB，可能存在数据不一致。另可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为0，但是订单数并没有达到库存阀值。\n总结\n\n前端三板斧【扩容】【限流】【静态化】\n后端两条路【内存】+【排队】\n\n参考\n关于秒杀和超卖的性能问题\n","plink":"https://zinki.github.io/2018/01/17/秒杀方案设计/"},{"title":"WebSocket原理","date":"2018-01-05T11:10:00.000Z","date_formatted":{"ll":"2018年1月5日","L":"2018/01/05","MM-DD":"01-05"},"updated":"2024-10-11T08:03:01.213Z","content":"WebSocket 是一种在单个TCP连接上进行全双工通信的协议。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。\n在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接， 并进行双向数据传输。（维基百科） \n背景\n在 WebSocket 协议出现以前，创建一个和服务端进双通道通信的 web 应用，需要依赖HTTP协议，进行不停的轮询，这会导致一些问题：\n服务端被迫维持来自每个客户端的大量不同的连接\n大量的轮询请求会造成高开销，比如会带上多余的header，造成了无用的数据传输。\n所以，为了解决这些问题，WebSocket 协议应运而生。\n基础帧结构分析\n\nFIN:占用1 bit,表示这是消息的最后一个片段。第一个片段也有可能是最后一个片段。\nRSV1，RSV2，RSV3: 每个1 bit\n必须设置为0，除非扩展了非0值含义的扩展。如果收到了一个非0值但是没有扩展任何非0值的含义，接收终端必须断开WebSocket连接。\nOpcode: 4 bit,操作码，如果收到一个未知的操作码，接收终端必须断开WebSocket连接。\n%x0 表示一个持续帧\n​\t%x1 表示一个文本帧\n​\t%x2 表示一个二进制帧\n​\t%x3-7 预留给以后的非控制帧\n​\t%x8 表示一个连接关闭包\n​\t%x9 表示一个ping包\n​\t%xA 表示一个pong包\n​\t%xB-F 预留给以后的控制帧\nMask: 1 bit，mask标志位，定义“有效负载数据”是否添加掩码。如果设置为1，那么掩码的键值存在于Masking-Key中。\nPayload length: 7 bits, 7+16 bits, or 7+64 bits，以字节为单位的“有效负载数据”长度。\nMasking-Key: 0 or 4 bytes，\n​\t所有从客户端发往服务端的数据帧都已经与一个包含在这一帧中的32 bit的掩码进行过了运算。如果mask标志位（1 bit）为1，那么这个字段存在，如果标志位为0，那么这个字段不存在。\n备注：载荷数据的长度，不包括mask key的长度。。\nPayload data： 有效负载数据\n\n为什么需要掩码？\n为了安全，但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。\n\n抓包\n请求\n\n响应\n\n这里的请求与响应就是反应了 WebSocket 的一次握手，我们根据上图可以简单抽象一下 WebSocket 的请求和响应格式： 客户端握手请求格式：\n123456789GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==Origin: http://example.comSec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13\n服务端握手响应：\n123456HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=Sec-WebSocket-Protocol: chat\n我们重点说明下结果请求字段：\nUpgrade：表示HTTP协议升级为webSocket\nconnection:Upgrade 请求升级。\nSec-WebSocket-Key： 用于服务端进行标识认证，生成全局唯一id,GUID。\nSec-WebSocket-Version： 版本\nSec-WebSocket-Protocol: 请求服务端使用指定的子协议。如果指定了这个字段，服务器需要包含相同的字段，并且从子协议的之中选择一个值作为建立连接的响应。\nSec-WebSocket-Extensions: WebSocket的扩展。\nSec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= 生成的全局唯一id，GUID。\nGUID的生成算法\n算法思想：通过 Sec-WebSocket-Key 传入的\n值，dGhlIHNhbXBsZSBub25jZQ==，连接服务端生成的字符串，拼接格式如下\n12dGhlIHNhbXBsZSBub25jZQ==258EAFA5-E914-47DA-95CA- C5AB0DC85B11\n然后采用SHA-1哈希算法，然后用base64编码生成最终的 Sec-WebSocket-Accept的值，生成的值就是\n1s3pPLMBiTxaQ9kYGzzhZRbK+xOo=\n\n（注意，这里SHA1哈希算法生成的结果必须是二进制的哈希结果，比如\nPython代码中的\n12h = hashlib.sha1(&quot;dGhlIHNhbXBsZSBub25jZQ==258EAFA5-E914-47DA-95CA-C5AB0DC85B11&quot;).digest()\n如果用在线处理工具生成，生成的Hash是16进制的哈希，用 Base64就会生成错误结果）。\n\n总结\n\nWebSocket 是为了在 web 应用上进行双通道通信而产生的协议，相比于轮询HTTP请求的方式，WebSocket 有节省服务器资源，效率高等优点。\n\n\nWebSocket 中的掩码是为了防止早期版本中存在中间缓存污染攻击等问题而设置的，客户端向服务端发送数据需要掩码，服务端向客户端发送数据不需要掩码。\n\n\nWebSocket 中 Sec-WebSocket-Key 的生成算法是拼接服务端和客户端生成的字符串，进行SHA1哈希算法，再用base64编码。\n\n\nWebSocket 协议握手是依靠 HTTP 协议的，依靠于 HTTP 响应101进行协议升级转换。\n\n参考\n简单聊聊WebSocket\n","plink":"https://zinki.github.io/2018/01/05/WebSocket原理/"},{"title":"深入分析ReentrantLock","date":"2017-12-13T12:17:00.000Z","date_formatted":{"ll":"2017年12月13日","L":"2017/12/13","MM-DD":"12-13"},"updated":"2024-10-11T08:04:46.127Z","content":"ReentrantLock是java concurrent包提供的一种锁实现。不同于synchronized，ReentrantLock是从代码层面实现同步的。 \n\nLock定义了锁的接口规范。 \nReentrantLock实现了Lock接口。 \nAbstractQueuedSynchronizer中以队列的形式实现线程之间的同步。 \nReentrantLock的方法都依赖于AbstractQueuedSynchronizer的实现。\nLock接口定义了如下方法：\n\nlock()方法的实现\n进入lock()方法，发现其内部调用的是sync.lock();\n123public void lock() &#123;    sync.lock();&#125;\nsync是在ReentrantLock的构造函数中实现的。其中fair参数的不同可实现公平锁和非公平锁。由于在锁释放的阶段，锁处于无线程占有的状态，此时其他线程和在队列中等待的线程都可以抢占该锁，从而出现公平锁和非公平锁的区别。 \n非公平锁：当锁处于无线程占有的状态，此时其他线程和在队列中等待的线程都可以抢占该锁。 \n公平锁：当锁处于无线程占有的状态，在其他线程抢占该锁的时候，都需要先进入队列中等待。 \n本文以非公平锁NonfairSync的sync实例进行分析。\n123456public ReentrantLock() &#123;    sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123;    sync = (fair)? new FairSync() : new NonfairSync();&#125;\n由图可知，NonfairSync继承自Sync，因此也继承了AbstractQueuedSynchronizer中的所有方法实现。接着进入NonfairSync的lock()方法。\n12345678final void lock() &#123;           // 利用cas置状态位，如果成功，则表示占有锁成功           if (compareAndSetState(0, 1))               // 记录当前线程为锁拥有者               setExclusiveOwnerThread(Thread.currentThread());           else               acquire(1);       &#125;\n在lock方法中，利用cas实现ReentrantLock的状态置位（cas即compare and swap，它是CPU的指令，因此赋值操作都是原子性的）。如果成功，则表示占有锁成功，并记录当前线程为锁拥有者。当占有锁失败，则调用acquire(1)方法继续处理。\n123456public final void acquire(int arg) &#123;    //尝试获得锁，如果失败，则加入到队列中进行等待    if (!tryAcquire(arg) &amp;&amp;        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;\nacquire()是AbstractQueuedSynchronizer的方法。它首先会调用tryAcquire()去尝试获得锁，如果获得锁失败，则将当前线程加入到CLH队列中进行等待。tryAcquire()方法在NonfairSync中有实现，但最终调用的还是Sync中的nonfairTryAcquire()方法。\n123456789101112131415161718192021222324252627protected final boolean tryAcquire(int acquires) &#123;    return nonfairTryAcquire(acquires);&#125;final boolean nonfairTryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    // 获得状态    int c = getState();    // 如果状态为0，则表示该锁未被其他线程占有    if (c == 0) &#123;        // 此时要再次利用cas去尝试占有锁        if (compareAndSetState(0, acquires)) &#123;            // 标记当前线程为锁拥有者            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    // 如果当前线程已经占有了，则state + 1,记录占有次数    else if (current == getExclusiveOwnerThread()) &#123;        int nextc = c + acquires;        if (nextc &lt; 0) // overflow            throw new Error(&quot;Maximum lock count exceeded&quot;);        // 此时无需利用cas去赋值，因为该锁肯定被当前线程占有        setState(nextc);        return true;    &#125;    return false;&#125;\n在nonfairTryAcquire()中，首先会去获得锁的状态，如果为0，则表示锁未被其他线程占有，此时会利用cas去尝试将锁的状态置位，并标记当前线程为锁拥有者；如果锁的状态大于0，则会判断锁是否被当前线程占有，如果是，则state + 1，这也是为什么lock()的次数要和unlock()次数对等；如果占有锁失败，则返回false。 \n在nonfairTryAcquire()返回false的情况下，会继续调用acquireQueued(addWaiter(Node.EXCLUSIVE), arg))方法，将当前线程加入到队列中继续尝试获得锁。\n12345678910111213141516171819202122232425262728293031323334353637383940private Node addWaiter(Node mode) &#123;    //　创建当前线程的节点    Node node = new Node(Thread.currentThread(), mode);    // Try the fast path of enq; backup to full enq on failure    Node pred = tail;    // 如果尾节点不为空    if (pred != null) &#123;        // 则将当前线程的节点加入到尾节点之后，成为新的尾节点        node.prev = pred;        if (compareAndSetTail(pred, node)) &#123;            pred.next = node;            return node;        &#125;    &#125;    enq(node);    return node;&#125;private Node enq(final Node node) &#123;    // CAS方法有可能失败，因此要循环调用，直到当前线程的节点加入到队列中    for (;;) &#123;        Node t = tail;        if (t == null) &#123; // Must initialize            Node h = new Node(); // Dummy header，头节点为虚拟节点            h.next = node;            node.prev = h;                if (compareAndSetHead(h)) &#123;                tail = node;                  return h;            &#125;        &#125;        else &#123;            node.prev = t;            if (compareAndSetTail(t, node)) &#123;                t.next = node;                return t;            &#125;        &#125;    &#125;&#125;\naddWaiter()是AbstactQueuedSynchronizer的方法，会以节点的形式来标记当前线程，并加入到尾节点中。enq()方法是在节点加入到尾节点失败的情况下，通过for(;;)循环反复调用cas方法，直到节点加入成功。由于enq()方法是非线程安全的，所以在增加节点的时候，需要使用cas设置head节点和tail节点。此时添加成功的结点状态为Node.EXCLUSIVE。 \n在节点加入到队列成功之后，会接着调用acquireQueued()方法去尝试获得锁。\n12345678910111213141516171819202122final boolean acquireQueued(final Node node, int arg) &#123;    try &#123;        boolean interrupted = false;        for (;;) &#123;            // 获得前一个节点            final Node p = node.predecessor();            // 如果前一个节点是头结点，那么直接去尝试获得锁            // 因为其他线程有可能随时会释放锁，没必要Park等待            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                return interrupted;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; catch (RuntimeException ex) &#123;        cancelAcquire(node);        throw ex;    &#125;&#125;\n在acquireQueued()方法中，会利用for (;;)一直去获得锁，如果前一个节点为head节点，则表示可以直接尝试去获得锁了，因为占用锁的线程随时都有可能去释放锁并且该线程是被unpark唤醒的CLH队列中的第一个节点，获得锁成功后返回。 \n如果该线程的节点在CLH队列中比较靠后或者获得锁失败，即其他线程依然占用着锁，则会接着调用shouldParkAfterFailedAcquire()方法来阻塞当前线程，以让出CPU资源。在阻塞线程之前，会执行一些额外的操作以提高CLH队列的性能。由于队列中前面的节点有可能在等待过程中被取消掉了，因此当前线程的节点需要提前，并将前一个节点置状态位为SIGNAL，表示可以阻塞当前节点。因此该函数在判断到前一个节点为SIGNAL时，直接返回true即可。此处虽然存在对CLH队列的同步操作，但由于局部变量节点肯定是不一样的，所以对CLH队列操作是线程安全的。由于在compareAndSetWaitStatus(pred, ws, Node.SIGNAL)执行之前可能发生pred节点抢占锁成功或pred节点被取消掉，因此此处需要返回false以允许该节点可以抢占锁。 \n当shouldParkAfterFailedAcquire()返回true时，会进入parkAndCheckInterrupt()方法。parkAndCheckInterrupt()方法最终调用safe.park()阻塞该线程，以免该线程在等待过程中无线循环消耗cpu资源。至此，当前线程便被park了。那么线程何时被unpark，这将在unlock()方法中进行。 \n这里有一个小细节需要注意，在线程被唤醒之后，会调用Thread.interrupted()将线程中断状态置位为false，然后记录下中断状态并返回上层函数去抛出异常。我想这样设计的目的是为了可以让该线程可以完成抢占锁的操作，从而可以使当前节点称为CLH的虚拟头节点。\n12345678910111213141516171819202122232425262728293031private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;    int ws = pred.waitStatus;    if (ws == Node.SIGNAL)        /*         * This node has already set status asking a release         * to signal it, so it can safely park         */        return true;        if (ws &gt; 0) &#123;        // 如果前面的节点是CANCELLED状态，则一直提前        do &#123;            node.prev = pred = pred.prev;        &#125; while (pred.waitStatus &gt; 0);        pred.next = node;    &#125; else &#123;        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);    &#125;     return false;&#125;private final boolean parkAndCheckInterrupt() &#123;    LockSupport.park(this);    return Thread.interrupted();&#125;public static void park(Object blocker) &#123;    Thread t = Thread.currentThread();    setBlocker(t, blocker);    unsafe.park(false, 0L);    setBlocker(t, null);&#125;\nunlock()方法的实现\n同lock()方法，unlock()方法依然调用的是sync.release(1)。\n123456789101112131415161718192021222324public final boolean release(int arg) &#123;    // 释放锁    if (tryRelease(arg)) &#123;        Node h = head;        // 此处有个疑问，为什么需要判断h.waitStatus != 0        if (h != null &amp;&amp; h.waitStatus != 0)            unparkSuccessor(h);        return true;    &#125;    return false;&#125;protected final boolean tryRelease(int releases) &#123;    int c = getState() - releases;    if (Thread.currentThread() != getExclusiveOwnerThread())        throw new IllegalMonitorStateException();    boolean free = false;    if (c == 0) &#123;        free = true;        setExclusiveOwnerThread(null);    &#125;    setState(c);    return free;&#125;\n可以看到，tryRelease()方法实现了锁的释放，逻辑上即是将锁的状态置为0。当释放锁成功之后，通常情况下不需要唤醒队列中线程，因此队列中总是有一个线程处于活跃状态。\n总结\nReentrantLock的锁资源以state状态描述，利用CAS则实现对锁资源的抢占，并通过一个CLH队列阻塞所有竞争线程，在后续则逐个唤醒等待中的竞争线程。ReentrantLock继承AQS完全从代码层面实现了java的同步机制，相对于synchronized，更容易实现对各类锁的扩展。同时，AbstractQueuedSynchronizer中的Condition配合ReentrantLock使用，实现了wait/notify的功能。\n参考\n深入分析ReentrantLock\n","plink":"https://zinki.github.io/2017/12/13/深入分析ReentrantLock/"},{"title":"Nginx部署实践","date":"2017-11-27T11:30:00.000Z","date_formatted":{"ll":"2017年11月27日","L":"2017/11/27","MM-DD":"11-27"},"updated":"2024-10-11T08:01:48.253Z","content":"Nginx是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。\n模块依赖\nnginx安装需要以下模块\ngzip模块需要 zlib 库\n1sudo apt-get install zlib1g-dev\nrewrite模块需要 pcre 库\nssl 功能需要openssl库\n编译环境\n1apt-get install build-essential\n下载nginx软件包\n1wget http://nginx.org/download/nginx-1.10.0.tar.gz\n解压\n1tar zxvf nginx-1.10.0.tar.gz\n编译\n1234root@ubuntu:/usr/local/src# cd nginx-1.10.0./configure --prefix=/usr/local/nginxmake allmake install\n安装成功\n启动\n1root@ubuntu:/usr/local/nginx/sbin# ./nginx\n查询nginx主进程号\n1234ps -ef | grep nginx从容停止   kill -QUIT 主进程号快速停止   kill -TERM 主进程号强制停止   kill -9 nginx\n若nginx.conf配置了pid文件路径，如果没有，则在logs目录下\n12345kill -信号类型 &#x27;/usr/local/nginx/logs/nginx.pid&#x27; nginx -t 测试配置文件是否正确nginx -s reload 重新启动nginx -s stop\n根据实验，nginx的后缀匹配会将请求的路径追加到root/alias后面\nnginx的正则使用PCRE（Perl Compatible Regular Expressions）\n\n参考\nNginx官网\n","plink":"https://zinki.github.io/2017/11/27/Nginx部署实践/"},{"title":"跨域及解决方案","date":"2017-11-05T12:19:00.000Z","date_formatted":{"ll":"2017年11月5日","L":"2017/11/05","MM-DD":"11-05"},"updated":"2024-10-11T02:16:40.029Z","content":"同源策略是浏览器的一项最为基本同时也是必须遵守的安全策略。同源策略的存在，限制了“源”自A的脚本只能操作“同源”页面的DOM，“跨源”操作来源于B的页面将会被拒绝。所谓的“同源”，必须要求相应的URI在如下3个方面均是相同的。\n\n主机名称（域名/子域名或者IP地址）\n端口号\n网络协议（Scheme，分别采用“http”和“https”协议的两个URI被视为不同源\n\n对于一段JavaScript脚本来说，其“源”与它存储的地址无关，而取决于脚本被加载的页面。比如在某个页面中通过 &lt;script&gt;标签引用了来源于不同地方的两个JavaScript脚本，它们均与当前页面同源。\njavascript\n\n\n1234567891011121314151617除了`&lt;script&gt;`标签其它一些具有src属性的标签（比如`&lt;img&gt;`），它们均具有跨域加载资源的能力，所以同源策略对它们不做限制。同源策略主要限制了通过XMLHttpRequest实现的Ajax请求，如果请求的是一个“异源”地址，浏览器将不允许读取返回的内容。JSONP实现跨域资源共享通过`&lt;script&gt;`标签的src属性加载的JavaScript脚本```javascript&lt;script type=&quot;text/javascript&quot; src=&quot;http://localhost:8080/api/test?callback=test&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt;function test(arg)&#123;&#125;&lt;/script&gt;\nJSONP是利用&lt;script&gt;的src标签加载的脚本不受同源策略约束而采取的一种编程技巧，不是一种官方协议。由于具有src属性的HTML标签均通过HTTP-GET的方式来加载目标资源，JSONP只适用于HTTP-GET请求。\n我们可以利用JQuery发送JSONP的Ajax跨域请求，调用$.ajax方法并将dataType参数设置为“jsonp”\n12345678&lt;script type=&quot;text/javascript&quot;&gt;    $(function ()    &#123;        $.ajax(&#123;             dataType : &quot;jsonp&quot;        &#125;);    &#125;);&lt;/script&gt;","plink":"https://zinki.github.io/2017/11/05/跨域及解决方案/"},{"title":"并发常见问题","date":"2017-10-21T14:11:00.000Z","date_formatted":{"ll":"2017年10月21日","L":"2017/10/21","MM-DD":"10-21"},"updated":"2024-10-11T08:03:27.881Z","content":"start()方法和run()方法的区别\n只有调用了start()方法，才会表现出多线程的特性，不同线程的run()方法里面的代码交替执行。如果只是调用run()方法，那么代码还是同步执行的，必须等待一个线程的run()方法里面的代码全部执行完毕之后，另外一个线程才可以执行其run()方法里面的代码\n\nYield join区别\n一个调用yield()方法使当前线程从执行状态(运行状态)变为可执行态(就绪状态)。cpu会从众多的可执行态里选择\n线程实例的方法join()方法可以使得一个线程在另一个线程结束后再执行\nRunnable接口和Callable接口的区别\nRunnable接口中的run()方法的返回值是void，它做的事情只是纯粹地去执行run()方法中的代码而已；Callable接口中的call()方法是有返回值的，是一个泛型，和Future、FutureTask配合可以用来获取异步执行的结果。\n\n这其实是很有用的一个特性，因为多线程相比单线程更难、更复杂的一个重要原因就是因为多线程充满着未知性，某条线程是否执行了？某条线程执行了多久？某条线程执行的时候我们期望的数据是否已经赋值完毕？无法得知，我们能做的只是等待这条多线程的任务执行完毕而已。而Callable+Future/FutureTask却可以获取多线程运行的结果，可以在等待时间太长没获取到需要的数据的情况下取消该线程的任务，真的是非常有用。\n\nCyclicBarrier和CountDownLatch的区别\n两个看上去有点像的类，都在java.util.concurrent下，都可以用来表示代码运行到某个点上，二者的区别在于：\n\nCyclicBarrier的某个线程运行到某个点上之后，该线程即停止运行，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程继续运行\nCyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务\nCyclicBarrier可重用，CountDownLatch不可重用，计数值为0该CountDownLatch就不可再用了\n\nvolatile关键字的作用\n理解volatile关键字的作用的前提是要理解Java内存模型\n\n多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据\n代码底层执行不像我们看到的高级语言—-Java程序这么简单，它的执行是Java代码–&gt;字节码–&gt;根据字节码执行对应的C/C++代码–&gt;C/C++代码被编译成汇编语言–&gt;和硬件电路交互，现实中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率\n\n\n从实践角度而言，volatile的一个重要作用就是和CAS结合，保证了原子性，详细的可以参见java.util.concurrent.atomic包下的类，比如AtomicInteger。\n\n什么是线程安全\n如果你的代码在多线程下执行和在单线程下执行永远都能获得一样的结果，那么你的代码就是线程安全的\n线程安全的几个级别\n（1）不可变\n像String、Integer、Long这些，都是final类型的类，任何一个线程都改变不了它们的值，要改变除非新创建一个，因此这些不可变对象不需要任何同步手段就可以直接在多线程环境下使用\n（2）绝对线程安全\n不管运行时环境如何，调用者都不需要额外的同步措施。要做到这一点通常需要付出许多额外的代价，Java中标注自己是线程安全的类，实际上绝大多数都不是线程安全的，不过绝对线程安全的类，Java中也有，比方说CopyOnWriteArrayList、CopyOnWriteArraySet\n（3）相对线程安全\n相对线程安全也就是我们通常意义上所说的线程安全，像Vector这种，add、remove方法都是原子操作，不会被打断，但也仅限于此，如果有个线程在遍历某个Vector、有个线程同时在add这个Vector，99%的情况下都会出现ConcurrentModificationException，也就是fail-fast机制。\n（4）线程非安全\n这个就没什么好说的了，ArrayList、LinkedList、HashMap等都是线程非安全的类\n\nfail-fast 机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。\n\nJava中如何获取到线程dump文件\n死循环、死锁、阻塞、页面打开慢等问题，打线程dump是最好的解决问题的途径。所谓线程dump也就是线程堆栈，获取到线程堆栈有两步:\n\n获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java\n打印线程堆栈，可以通过使用jstack pid命令，在Linux环境下还可以使用kill -3 pid\n另外提一点，Thread类提供了一个getStackTrace()方法也可以用于获取线程堆栈。这是一个实例方法，因此此方法是和具体线程实例绑定的，每次获取获取到的是具体某个线程当前运行的堆栈\n\nsleep方法和wait方法有什么区别\n这个问题常问，sleep方法和wait方法都可以用来放弃CPU一定的时间，不同点在于如果线程持有某个对象的监视器，sleep方法不会放弃这个对象的监视器，wait方法会放弃这个对象的监视器\nThreadLocal有什么用\n简单说ThreadLocal就是一种以空间换时间的做法，在每个Thread里面维护了一个以开地址法实现的ThreadLocal.ThreadLocalMap，把数据进行隔离，数据不共享，自然就没有线程安全方面的问题了\n##为什么wait()方法和notify()/notifyAll()方法要在同步块中被调用\n这是JDK强制的，wait()方法和notify()/notifyAll()方法在调用前都必须先获得对象的锁\nwait()方法和notify()/notifyAll()方法在放弃对象监视器时有什么区别\nwait()方法和notify()/notifyAll()方法在放弃对象监视器的时候的区别在于：wait()方法立即释放对象监视器，notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。\n为什么要使用线程池\n避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以根据项目灵活地控制并发的数目。\n怎么检测一个线程是否持有对象监视器\nThread类提供了一个holdsLock(Object obj)方法，当且仅当对象obj的监视器被某条线程持有的时候才会返回true，注意这是一个static方法，这意味着“某条线程”指的是当前线程。\nsynchronized和ReentrantLock的区别\nsynchronized是和if、else、for、while一样的关键字，ReentrantLock是类，这是二者的本质区别。既然ReentrantLock是类，那么它就提供了比synchronized更多更灵活的特性，可以被继承、可以有方法、可以有各种各样的类变量，ReentrantLock比synchronized的扩展性体现在几点上：\n\nReentrantLock可以对获取锁的等待时间进行设置，这样就避免了死锁\nReentrantLock可以获取各种锁的信息\nReentrantLock可以灵活地实现多路通知\n另外，二者的锁机制其实也是不一样的。ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word，这点我不能确定。\n\nConcurrentHashMap的并发度是什么\nConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap，这也是ConcurrentHashMap对Hashtable的最大优势，任何情况下，Hashtable能同时有两条线程获取Hashtable中的数据吗\nReadWriteLock是什么\n首先明确一下，不是说ReentrantLock不好，只是ReentrantLock某些时候有局限。如果使用ReentrantLock，可能本身是为了防止线程A在写数据、线程B在读数据造成的数据不一致，但这样，如果线程C在读数据、线程D也在读数据，读数据是不会改变数据的，没有必要加锁，但是还是加锁了，降低了程序的性能。\n因为这个，才诞生了读写锁ReadWriteLock。ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。\nLinux环境下如何查找哪个线程使用CPU最长\n\n获取项目的pid，jps或者ps -ef | grep java\ntop -H -p pid，顺序不能改变\n\n怎么唤醒一个阻塞的线程\n如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它；如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统\nJava中用到的线程调度算法是什么\n抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行\nThread.sleep(0)的作用是什么\n由于Java采用抢占式的线程调度算法，因此可能会出现某条线程常常获取到CPU控制权的情况，为了让某些优先级比较低的线程也能获取到CPU控制权，可以使用Thread.sleep(0)手动触发一次操作系统分配时间片的操作，这也是平衡CPU控制权的一种操作。\n什么是自旋\n很多synchronized里面的代码只是一些很简单的代码，执行时间非常快，此时等待的线程都加锁可能是一种不太值得的操作，因为线程阻塞涉及到用户态和内核态切换的问题。既然synchronized里面的代码执行得非常快，不妨让等待锁的线程不要被阻塞，而是在synchronized的边界做忙循环，这就是自旋。如果做了多次忙循环发现还没有获得锁，再阻塞，这样可能是一种更好的策略。\n什么是CAS\nCAS，全称为Compare and Swap，即比较-替换。假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功\n什么是AQS\n简单说一下AQS，AQS全称为AbstractQueuedSychronizer，翻译过来应该是抽象队列同步器。\n如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等等都用到了它。AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。\nAQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。\n单例模式的线程安全性\n老生常谈的问题了，首先要说的是单例模式的线程安全意味着：某个类的实例在多线程环境下只会被创建一次出来。单例模式有很多种的写法，我总结一下：\n\n饿汉式单例模式的写法：线程安全\n懒汉式单例模式的写法：非线程安全\n双检锁单例模式的写法：线程安全\n\nSemaphore有什么作用\nSemaphore就是一个信号量，它的作用是限制某段代码块的并发数。Semaphore有一个构造函数，可以传入一个int型整数n，表示某段代码最多只有n个线程可以访问，如果超出了n，那么请等待，等到某个线程执行完毕这段代码块，下一个线程再进入。由此可以看出如果Semaphore构造函数中传入的int型整数n=1，相当于变成了一个synchronized了。\n同步方法和同步块，哪个是更好的选择\n同步块，这意味着同步块之外的代码是异步执行的，这比同步整个方法更提升代码的效率。请知道一条原则：同步的范围越小越好。\n虽说同步的范围越少越好，但是在Java虚拟机中还是存在着一种叫做锁粗化的优化方法，这种方法就是把同步范围变大。这是有用的，比方说StringBuffer，它是一个线程安全的类，自然最常用的append()方法是一个同步方法，我们写代码的时候会反复append字符串，这意味着要进行反复的加锁-&gt;解锁，这对性能不利，因为这意味着Java虚拟机在这条线程上要反复地在内核态和用户态之间进行切换，因此Java虚拟机会将多次append方法调用的代码进行一个锁粗化的操作，将多次的append的操作扩展到append方法的头尾，变成一个大的同步块，这样就减少了加锁–&gt;解锁的次数，有效地提升了代码执行的效率。\n可重入锁指同一个线程可以再次获得之前已经获得的锁。\n可重入锁可以用户避免死锁。\nJava中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock\n锁的实现：\nSynchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的\n在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术\n所谓死锁： 是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。\n查看死锁方法:Jconsole\n\nJstack\n先用jps查出现有线程\n然后 jstack -l PID 查看find one dead lock之类的\n参考\nJava线程面试题\n","plink":"https://zinki.github.io/2017/10/21/并发常见问题/"},{"title":"自定义Feign日志打印","date":"2017-10-09T13:09:00.000Z","date_formatted":{"ll":"2017年10月9日","L":"2017/10/09","MM-DD":"10-09"},"updated":"2024-10-10T08:03:05.475Z","content":"使用Feign进行Rest请求很方便，打印日志比较繁琐。AOP可以解决这个问题，对性能有所损耗；另一种办法是自定义日志输出\nAOP打印日志\n123456789101112131415161718192021222324252627282930313233@Aspect@Component@Slf4jpublic class ClientInvokeResultAOP &#123;    private static final int SUCCESS_CODE = ConstantsUtils.CommonCode.SUCCESS_CODE;    @Pointcut(&quot;execution(public * com.yonghui..*.client..*.*(..))&quot;)    public void invoke() &#123;    &#125;    @Around(&quot;invoke()&quot;)    public Object around(ProceedingJoinPoint pjp) throws Throwable &#123;        long begin = System.currentTimeMillis();        Object proceed = pjp.proceed();        long end = System.currentTimeMillis();        Method targetMethod = ((MethodSignature) (pjp.getSignature())).getMethod();        String className = targetMethod.getDeclaringClass().getName();        String methodName = targetMethod.getName();        log.info(&quot;[client trace] &#123;&#125; - &#123;&#125; consume &#123;&#125; ms&quot;, className, methodName, end - begin);        if (proceed instanceof R) &#123;            R r = (R) proceed;            if (SUCCESS_CODE != r.getCode()) &#123;                throw new RRException(r.getCode(), r.getMessage());            &#125;        &#125; else if (proceed instanceof Rpage) &#123;            Rpage rpage = (Rpage) proceed;            if (SUCCESS_CODE != rpage.getCode()) &#123;                throw new RRException(rpage.getCode(), rpage.getMessage());            &#125;        &#125;        return proceed;    &#125;&#125;\n自定义日志输出\n12345678910111213141516171819202122232425262728293031323334353637383940@Component@Slf4jpublic class RemoteInfoLogger extends Logger &#123;    @Override    protected void log(String s, String s1, Object... objects) &#123;    &#125;    @Override    protected void logRequest(String configKey, Logger.Level logLevel, Request request) &#123;    &#125;    @Override    protected Response logAndRebufferResponse(String configKey, Logger.Level logLevel, Response response, long elapsedTime) throws IOException &#123;        if (response.body() != null) &#123;            String result=&quot;&quot;;            byte[] bodyData = Util.toByteArray(response.body().asInputStream());            int bodyLength = bodyData.length;            if (bodyLength &gt; 0) &#123;                result = Util.decodeOrDefault(bodyData, Util.UTF_8, &quot;Binary data&quot;);            &#125;            Response build = response.toBuilder().body(bodyData).build();            Request request = build.request();            String bodyText =  request.requestBody().asString();            log.info(&quot;请求URL:&quot; + request.url());            log.info(&quot;请求参数:&quot; + bodyText);            log.info(&quot;请求结果:&quot; + result);            log.info(&quot;本次请求耗时:&quot; + elapsedTime);            return build;        &#125;        return response;    &#125;    protected IOException logIOException(String configKey, Level logLevel, IOException ioe, long elapsedTime) &#123;        //IOException 自带log输出即可 logger.error();        // com.netflix.client.ClientException: Load balancer does not have available server for client: lzh-cloud-test 服务没发现未进IO异常        return ioe;    &#125;&#125;\n使用的话需要在FeignConfig指定\n1234@BeanLogger.Level feignLoggerLevel() &#123;    return Logger.Level.BASIC;&#125;\n参考\nSpring Cloud OpenFeign自定义日志\n","plink":"https://zinki.github.io/2017/10/09/自定义Feign日志打印/"},{"title":"如何让JVM崩溃","date":"2017-09-27T13:00:00.000Z","date_formatted":{"ll":"2017年9月27日","L":"2017/09/27","MM-DD":"09-27"},"updated":"2024-10-10T08:03:05.466Z","content":"A perfect JVM implementation will never crash.\nTo crash a JVM, aside from JNI, you need to find a bug in the VM itself. An infinite loop just consumes CPU. Infinitely allocating memory should just cause OutOfMemoryError’s in a well built JVM. This would probably cause problems for other threads, but a good JVM still should not crash.\nIf you can find a bug in the source code of the VM, and for example cause a segmentation fault in the memory usage of the implementation of the VM, then you can actually crash it.\n\n\n这个你需要说一下你指的“崩溃”是什么：是指让机器的资源用尽，还是触发系统不允许的异常，还是触发JVM的设计错误，还是其他的。“崩溃”这个概念还是很宽泛的。——资源用尽，不管任何语言都有个万能的办法：几个空函数循环调用，让系统的递归栈爆栈，也就是stack overflow。触发系统不允许的异常，访问不在自己程序申请之内的内存即可，也就是segmentation fault。不过我相信你期待的多半不是这两个答案。\n\n12345678910111213package jvm;public class Crash &#123;    public static void main(String[] args) &#123;        //Object[] o = &#123;“abc”&#125;;初始值赋值，不会有影响。        Object[] o = null;        while (true) &#123;            o = new Object[] &#123; o &#125;;            //System.out.println(o);        &#125;            &#125;&#125;\nException in thread “main” java.lang.OutOfMemoryError: Java heap space at jvm.Crash.main(Crash.java:10)是因为程序无法申请到足够的内存的时候抛出的异常，Object数组o不断指向新的Object数组，数组元素是原来的Object数组，这使得Object维数越来越高。不断申请内存空间，最终导致超出jvm中堆的最大值。\n输出打印的话，虚拟机并不是不会崩溃，而是崩溃的时间大大延长了。而崩溃时间延长其实是假象，是因为输出属于IO事件，每次输出CPU都被中断，IO很耗时，所以，感觉上才会时间延长。\n参考\nHow do you crash a JVM?\n","plink":"https://zinki.github.io/2017/09/27/如何让JVM崩溃/"},{"title":"Dubbo源码简析","date":"2017-09-04T02:07:00.000Z","date_formatted":{"ll":"2017年9月4日","L":"2017/09/04","MM-DD":"09-04"},"updated":"2024-10-11T07:59:08.905Z","content":"RPC英文全名为Remote Procedure Call，也叫远程过程调用，其实就是一个计算机通信协议，它是一种通过网络从远程计算机程序上请求服务,而不需要了解底层网络技术的协议\n\n模块说明\n\ndubbo-common 公共逻辑模块：包括 Util 类和通用模型。\n通用模型就是贯穿整个项目的统一格式,例如URL\nURL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。\ndubbo以URL为总线，运行过程中所有的状态数据信息都可以通过URL来获取，比如当前系统采用什么序列化，采用什么通信，采用什么负载均衡等信息，都是通过URL的参数来呈现的，所以在框架运行过程中，运行到某个阶段需要相应的数据，都可以通过对应的Key从URL的参数列表中获取。\ndubbo-remoting 远程通讯模块：相当于 Dubbo 协议的实现，如果 RPC 用 RMI协议则不需要使用此包。\ndubbo-rpc 远程调用模块：抽象各种协议，以及动态代理，只包含一对一的调用，不关心集群的管理。\ndubbo-cluster 集群模块：将多个服务提供方伪装为一个提供方，包括：负载均衡, 容错，路由等，集群的地址列表可以是静态配置的，也可以是由注册中心下发。\ndubbo-registry 注册中心模块：基于注册中心下发地址的集群方式，以及对各种注册中心的抽象。\ndubbo-monitor 监控模块：统计服务调用次数，调用时间的，调用链跟踪的服务。\ndubbo-config 配置模块：是 Dubbo 对外的 API，用户通过 Config 使用Dubbo，隐藏Dubbo 所有细节。\ndubbo-container 容器模块：是一个 Standlone 的容器，以简单的 Main 加载 Spring 启动，因为服务通常不需要 Tomcat/JBoss 等 Web 容器的特性，没必要用 Web 容器去加载服务。\n\n核心领域模型\n\nProtocol 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。\n\n\nInvoker 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。\n\n\nInvocation 是会话域，它持有调用过程中的变量，比如方法名，参数等。\n\nSPI\nSPI(Service Provider Interface)是Java提供的一种服务加载方式，可以避免在Java代码中写死服务提供者，而是通过SPI服务加载机制进行服务的注册和发现，实现多个模块的解耦。\nJava SPI的具体约定为:在服务提供者提供了服务接口的一种实现之后，在Jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里的就是实现该服务接口的具体实现类。在外部程序装配这个模块时，就能通过该Jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。基于这样一个约定就能很好地找到服务接口的实现类，而不需要在代码里指定。JDK提供了服务实现查找的一个工具类，即java.util.ServiceLoader.\nDubbo 并未使用 Java SPI，而是重新实现了一套功能更强的 SPI 机制。Dubbo SPI 的相关逻辑被封装在了 ExtensionLoader 类中，通过 ExtensionLoader，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在META-INF/dubbo 路径下\n消息体\n\nDubbo 数据包分为消息头和消息体，消息头用于存储一些元信息，比如魔数（Magic），数据包类型（Request/Response），消息体长度（Data Length）等。消息体中用于存储具体的调用消息，比如方法名称，参数列表等。下面简单列举一下消息头的内容。\n的调用消息，比如方法名称，参数列表等。下面简单列举一下消息头的内容。\n\n对于双向通信，HeaderExchangeHandler 首先向后进行调用，得到调用结果。然后将调用结果封装到 Response 对象中，最后再将该对象返回给服务消费方。如果请求不合法，或者调用失败，则将错误信息封装到 Response 对象中，并返回给服务消费方\n参考\nDubbo官方文档\n","plink":"https://zinki.github.io/2017/09/04/Dubbo源码简析/"},{"title":"Echarts生成定时报表","date":"2017-08-17T07:43:00.000Z","date_formatted":{"ll":"2017年8月17日","L":"2017/08/17","MM-DD":"08-17"},"updated":"2024-10-10T08:03:05.442Z","content":"项目中使用Echarts来生成报表，效果不错，之后有个需求要设置定时时间给指定的邮箱发送报表邮件。后台使用JFreeChart生成的话样式不协调，而Echarts需要浏览器内核来执行js，后来尝试过htmlunit，对echarts支持的不是很好，遂放弃了。后来搜索中在一篇博客看到PhantomJs的介绍博客地址可以实现上述需求。\nPhantomJS简介\nPhantomJs是一个无头浏览器，对前端页面支持不错，对于一些需要爬取异步加载的页面很有用。\n安装步骤\n12345678910111213# 进入/opt目录,下载phantomjscd /optwget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2# 解压软件压缩包tar xvf phantomjs-2.1.1-linux-x86_64.tar.bz2# 编辑配置文件vim /etc/profile# 将PhantomJS的bin目录加入到PATH环境变量中export PATH=$&#123;PATH&#125;:/opt/phantomjs-2.1.1-linux-x86_64/bin# 使用source命令让刚才的配置即时生效source /etc/profile# 测试PhantomJS是否安装成功，如果打出了版本信息，即安装成功.phantomjs -v\n安装完成需要编辑phantomjs脚本，可参考以下脚本：\n12345678910111213141516171819202122232425262728293031var system = require(&#x27;system&#x27;);  var page = require(&#x27;webpage&#x27;).create();// 如果是windows,设置编码为gbk，防止中文乱码,Linux本身是UTF-8var osName = system.os.name;  if (&#x27;windows&#x27; === osName.toLowerCase()) &#123;      phantom.outputEncoding=&quot;gbk&quot;;&#125;// 获取第二个参数(即请求地址url).var url = system.args[1];// 显示控制台日志.page.onConsoleMessage = function(msg) &#123;      console.log(&#x27;[&#x27; + msg + &#x27;]&#x27;);&#125;;//打开给定url的页面.page.open(url, function(status) &#123;      if (status == &#x27;success&#x27;) &#123;        //console.log(&#x27;echarts页面加载完成,加载耗时:&#x27; + (new Date().getTime() - start) + &#x27; ms&#x27;);        // 由于echarts动画效果，延迟500毫秒确保图片渲染完毕再调用下载图片方法.         console.log(&quot;页面加载成功!&quot;);    &#125; else &#123;        console.log(&quot;页面加载失败 Page failed to load!&quot;);    &#125;    // 10秒后再关闭浏览器.    setTimeout(function() &#123;        phantom.exit();    &#125;, 10000);&#125;);\n将phantom.js放到/opt目录下\n问题\n\n在刚开始使用时发现没有执行页面JS，将page.content打印才发现访问页面被登陆拦截了。\n\n上传服务器时报错2018-09-21 15:41:29[DEBUG]-[Thread: TP-exec-1]-[org.springframework.web.method.support.InvocableHandlerMethod.getMethodArgumentValues()]: Failed to resolve argument 0 of type ‘java.lang.String’\norg.springframework.web.bind.MissingServletRequestParameterException: Required String parameter ‘doc’ is not present\n后来发现是web容器做了上传限制导致,在tomcat配置中加入maxPostSize=&quot;-1&quot;即可\n\nPhantomjs+echarts后台生成报表遇到一个问题生成报表文件的base64编码的URL的图片,体积会100倍,内容里会多出很多个A,在GitHub搜索到类似情况并给出解决方案\n大致因为phantomjs对canvas和png格式不兼容导致,需要明确质量参数\n解决方法是修改Echarts源码将echarts中用canvas生成图片的方法指定质量参数0即可解决,类似以下:\n\n1varo=&quot;svg&quot;===this._zr.painter.getType()?this.getSvgDataUrl():this.getRenderedCanvas(t).toDataURL(&quot;image/&quot;+(t&amp;&amp;t.type||&quot;png&quot;,0.5));\n使用jepg格式可以规避这种问题\n12345myChart.getDataURL(&#123;       type:&#x27;jpeg&#x27;,       pixelRatio: 1,       backgroundColor: &#x27;#fff&#x27;   &#125;);\n\n后来又发现个问题,线上和仿真渲染出的图片文字模糊一直存在,一直在找phantomjs的问题,想找个替代的方案.今天想到模糊的文字都是没有中文的,然后就想到是系统字体的原因\n操作步骤如下:\n\n1234561.将附件中字体复制到 /usr/share/fonts/zh_CN  目录下2.对目录授权 #chmod 777 /usr/share/fonts/zh_CN  3.#mkfontscale  // 如果提示 mkfontscale: command not found，需自行安装 #yum install mkfontscale4.#mkfontdir5.#fc-cache –fv // 刷新内存中的字体缓存6.#source /etc/profile  // 执行以下命令让字体生效\n","plink":"https://zinki.github.io/2017/08/17/Echarts定时报表/"},{"title":"Kubernetes基本概念","date":"2017-07-27T10:19:00.000Z","date_formatted":{"ll":"2017年7月27日","L":"2017/07/27","MM-DD":"07-27"},"updated":"2024-10-10T08:03:05.450Z","content":"Kubernetes（k8s）是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展。如果你曾经用过Docker容器技术部署容器，那么可以将Docker看成Kubernetes内部使用的低级别组件。Kubernetes不仅仅支持Docker，还支持Rocket，这是另一种容器技术。\nKubernetes作用\n\n自动化容器的部署和复制\n随时扩展或收缩容器规模\n将容器组织成组，并且提供容器间的负载均衡\n很容易地升级应用程序容器的新版本\n提供容器弹性，如果容器失效就替换它\n\n基本概念\n\nCluster\nCluster是计算、存储和网络资源的集合，Kubernetes 利用这些资源运行各种基于容器的应用。\nMaster\nMaster是Cluster的大脑，它的主要职责是调度,即决定将应用放在哪里运行。Master运行Linux操作系统，可以是物理机或者虚拟机。为了实现高可用，可以运行多个Master。\nNode\nNode的职责是运行容器应用。Node由Master管理,Node负责监控并汇报容器的状态，同时根据Master的要求管理容器的生命周期。Node运行在Linux操作系统上，可以是物理机或者是虚拟机。\nPod\nPod是Kubernetes 的最小工作单元。每个Pod 包含-一个或多个容器。Pod中的容器会作为一个整体被Master 调度到一个Node上运行。\nController\nKubernetes通常不会直接创建Pod，而是通过Controller 来管理Pod 的。Controller 中定义了Pod的部署特性，比如有几个副本、在什么样的Node.上运行等。 为了满足不同的业务场景，Kubernetes 提供了多种Controller， 包括Deployment、 ReplicaSet、 DaemonSet、StatefuleSet、Job等，我们逐- -讨论。\n(1) Deployment是最常用的Controller， 比如在线教程中就是通过创建Deployment 来部署应用的。Deployment 可以管理Pod的多个副本，并确保Pod按照期望的状态运行。\n(2) ReplicaSet实现了Pod 的多副本管理。使用Deployment 时会自动创建ReplicaSet,也就是说Deployment 是通过ReplicaSet 来管理Pod 的多个副本的，我们通常不需要直接使用ReplicaSet。\n(3) DaemonSet 用于每个Node 最多只运行一个Pod副本的场景。正如其名称所揭示的，DaemonSet 通常用于运行daemon。\n(4) StatefuleSet 能够保证Pod的每个副本在整个生命周期中名称是不变的，而其他Controller不提供这个功能。当某个Pod发生故障需要删除并重新启动时，Pod 的名称会发生变化，同时StatefuleSet 会保证副本按照固定的顺序启动、更新或者删除。\n(5) Job用于运行结束就删除的应用，而其他Controller中的Pod通常是长期持续运行。\nService\nDeployment可以部署多个副本，每个Pod都有自己的IP, 外界如何访问这些副本呢?通过Pod的IP吗?\n要知道Pod很可能会被频繁地销毁和重启，它们的IP会发生变化，用IP 来访问不太现实。\n答案是Service。\nKubernetes Service定义了外界访问一组特定Pod 的方式。Service有自己的IP和端口，Service为Pod提供了负载均衡。\nKubernetes运行容器(Pod)与访问容器(Pod)这两项任务分别由Controller 和Service执行。\nNamespace\n如果有多个用户或项目组使用同-一个 Kubernetes Cluster,如何将他们创建的Controller、Pod等资源分开呢?\n答案就是Namespace。\nNamespace可以将-一个物理的Cluster 逻辑上划分成多个虚拟Cluster， 每个Cluster 就是一个Namespace。不同Namespace里的资源是完全隔离的。\nKubernetes默认创建了两个Namespace\n\ndefault:创建资源时如果不指定，将被放到这个Namespace 中。\nkube-system: Kubernetes 自己创建的系统资源将放到这个Namespace 中。\nkubelet 运行在Cluster 所有节点上，负责启动Pod和容器。\nkubeadm 用于初始化Cluster。\nkubectl是Kubernetes 命令行工具。通过kubectl可以部署和管理应用，查看各种资源，创建、删除和更新各种组件。\nMaster节点\n\nAPI Server ( kube- apiserver )\nAPI Server 提供HTTP/HTTPS RESTful API，即Kubernetes API。 API Server 是Kubernetes Cluster的前端接口，各种客户端工具(CLI或UI)以及Kubernetes 其他组件可以通过它管理Cluster 的各种资源。\nScheduler ( kube -scheduler )\nScheduler负责决定将Pod 放在哪个Node. 上运行。 Scheduler 在调度时会充分考虑Cluster的拓扑结构，当前各个节点的负载，以及应用对高可用、性能、数据亲和性的需求。\nController Manager ( kube-controller-manager )\nController Manager负责管理Cluster 各种资源，保证资源处于预期的状态。ControllerManager由多种controller 组成，包括replication controller、 endpoints controller、 namespacecontroller、serviceaccounts controller\n不同的controller 管理不同的资源。例如，replication controller 管理Deployment 、StatefulSet、DaemonSet 的生命周期，namespace controller管理Namespace 资源。\netcd\netcd负责保存Kubernetes Cluster 的配置信息和各种资源的状态信息。当数据发生变化时，etcd 会快速地通知Kubernetes 相关组件。\nPod网络\nPod要能够相互通信，Kubernetes Cluster 必须部署Pod 网络，flannel 是其中一个可选方案。\n\nNode节点\n\nkubelet\nkubelet是Node的agent， 当Scheduler 确定在某个Node.上运行Pod 后，会将Pod ，\n的具体配置信息(image、 volume 等)发送给该节点的kubelet, kubelet 根据这些信息创建和运行容器，并向Master 报告运行状态。\nkube-proxy\nservice在逻辑.上代表了后端的多个Pod,外界通过service 访问Pod。 service 接收到的请求是如何转发到Pod的呢?这就是kube-proxy要完成的工作。\n每个Node都会运行kube-proxy 服务，它负责将访问service 的TCP/UPD数据流转发到后端的容器。如果有多个副本，kube-proxy 会实现负载均衡。\nPod网络\nPod.要能够相互通信，Kubernetes Cluster 必须部署Pod 网络，flannel 是其中-一个可选方案。\n\nkubelet是唯一没 有以容器形式运行的Kubernetes 组件，它在Ubuntu 中通过Systemd服务运行\nHelm\n每个成功的软件平台都有一个优秀的打包系统，比如Debian、 Ubuntu 的apt, Red Hat、CentOS的yum。 Helm 则是Kubernetes上的包管理器。\nHelm有两个重要的概念: chart 和release。\n\nchart 是创建一个应用的信息集合，包括各种Kubernetes 对象的配置模板、参数定\n义、依赖关系、文档说明等。chart 是应用部署的自包含逻辑单元。可以将chart想象成apt、yum中的软件安装包。\nrelease是chart 的运行实例，代表了一个正在运行的应用。当chart 被安装到\nKubernetes集群，就生成一个release。 chart 能够多次安装到同一个集群，每次安装都是一个release。\n\nHelm是包管理工具，这里的包就是指的chart。 Helm能够:\n\n从零创建新chart。\n与存储chart 的仓库交互，拉取、保存和更新chart。在Kubernetes 集群中安装和卸载release。\n更新、回滚和测试release.\n\n参考\nKubernetes 文档\n","plink":"https://zinki.github.io/2017/07/27/Kubernetes基本概念/"},{"title":"Pip install超时解决方案","date":"2017-07-19T07:42:00.000Z","date_formatted":{"ll":"2017年7月19日","L":"2017/07/19","MM-DD":"07-19"},"updated":"2024-10-10T08:03:05.456Z","content":"pip install会出现连接超时解决方案\n原因\n采用默认的pypi源(国外的pypi源)，这个很容易出现这种连接超时的问题，所以应当采用国内的镜像源,一些国内常用的pypi源如下：\n阿里云 http://mirrors.aliyun.com/pypi/simple/\n中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/\n豆瓣(douban) http://pypi.douban.com/simple/\n清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/\n中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/\n解决办法\n在你需要安装的xx后面添加-i + pypi源：\n1pip install xx -i [http://pypi.douban.com/simple/](http://pypi.douban.com/simple/)\n如果还出现下面的情况：\npypi.douban.com is not a trusted or secure host and is being ignored…\n那么命令就变成这样：\n1pip install xx -i [http://pypi.douban.com/simple](http://pypi.douban.com/simple) --trusted-host pypi.douban.com\n这样就可以解决，但是这样需要每次在后面添加-i http://pypi.douban.com/simple --trusted-host pypi.douban.com这么一长串的后缀，那么问题来了，我们可不可以设置修改默认的pypi源呢？答案是肯定的，下面就教你如何配置。\n修改默认pypi源\n在liunx环境下，在当前的虚拟环境下面新建pip.conf文件:\n1~/.pip/pip.conf\n在windows环境下，在当前的虚拟环境下面的pip文件夹新建pip.ini，并配置系统环境变量：\n1%HOMEPATH%\\\\pip\\\\pip.ini\n在上面2个文件夹里面写入这些代码：\n123456[global]#这个pypi源自己定义index-url = https://pypi.tuna.tsinghua.edu.cn/simple/[install]trusted-host=pypi.tuna.tsinghua.edu.cn  # 这个也是根据pypi源自己定义\n现在使用pip来安装时，就会默认调用该镜像，你不需要再添加那些后缀了。当然如果你想临时修改某个pypi源，（不想用清华镜像，想用豆瓣镜像）这也是可以的，操作方法如下：\n在前面添加如下代码：\n1234import ospackage = raw_input(&quot;Please input the package which you want to install：\\\\n&quot;)command = &quot;pip install %s -i [http://pypi.douban.com/simple/](http://pypi.douban.com/simple/) --trusted-host pypi.douban.com&quot; % packageos.system(command)\n参考\n使用默认pypi源出现连接超时的解决办法\n","plink":"https://zinki.github.io/2017/07/19/Pip install超时解决方案/"},{"title":"PlantUML简明教程","date":"2017-07-03T03:19:00.000Z","date_formatted":{"ll":"2017年7月3日","L":"2017/07/03","MM-DD":"07-03"},"updated":"2024-10-11T08:02:11.730Z","content":"PlantUML 是一个开源项目，支持快速绘制时序图、用例图、类图、活动图、组件图、状态图、对象图、部署图等。同时还支持非 UML 图的甘特图、架构图等。例如下面等用例图： \nPlantUML 简介\n一款还算不错的绘图工具-- Plantuml, 它本质上是也算一门可以快速画图的设计语言，学习起来也很方便。可以在http://plantuml.com/网站上体验一下。 在vscode, webstorm都有相关的插件可以使用。\n123456789101112131415161718192021222324252627@startumlP: PENDINGP: Pending for resultN: NO_RESULT_YETN: Did not send the KYC check yet Y: APPROVEDY: KYC check successfulR: REJECTEDR: KYC check found the applicant&#x27;s R: information not correct X: EXPIREDX: Proof of Address (POA) too old[*] --&gt; N : Card application receivedN --&gt; P : Submitted the KYC checkP --&gt; YP --&gt; RP --&gt; X : Proof of Address (POA) too oldP --&gt; X : explicitly by KYCY --&gt; [*]R --&gt; [*]X --&gt; [*]@enduml\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@startumlskinparam rectangle &#123;    BackgroundColor DarkSeaGreen    FontStyle Bold    FontColor DarkGreen&#125;:User: as urectangle Tool as trectangle &quot;Knowledge Base&quot; as kb(Robot Framework) as rf(DUT) as dutnote as ts    test scriptend notenote as act    query    &amp;    actionend notenote as t_cmt    - 执行测试脚本    - 按照知识库响应消息end notenote as kb_cmt    - 根据当前消息确定响应方法    - 根据上下文填充消息    - 保存信息到相关上下文end noteu --&gt; rfrf =right=&gt; tsts =down=&gt; tkb &lt;=left=&gt; actact &lt;=up=&gt; tt = dutt_cmt -- tkb_cmt -left- kb@enduml\n\n1234567891011121314151617181920212223@startumlinterface Command &#123;    execute()    undo()&#125;class Invoker&#123;    setCommand()&#125;class Clientclass Receiver&#123;    action()&#125;class ConcreteCommand&#123;    execute()    undo()&#125;Command &lt;|-down- ConcreteCommandClient -right-&gt; ReceiverClient --&gt; ConcreteCommandInvoker o-right-&gt; CommandReceiver &lt;-left- ConcreteCommand@enduml\n\n时序图\n时序图相对来说是平常比较经常画的一种设计图稿，在这里记录一下plantuml中相关的语法。\n基本用法\n1234@startumlA -&gt; B: do somethingB -&gt; A: do something@enduml\n\n时序图角色可以分为: actor, boundary, control, entity, database，每种角色呈现的图形也是不一样的。\n设置不同的角色\n1234567891011121314@startumlactor Foo1boundary Foo2control Foo3entity Foo4database Foo5collections Foo6Foo1 -&gt; Foo2 : To boundaryFoo1 -&gt; Foo3 : To controlFoo1 -&gt; Foo4 : To entityFoo1 -&gt; Foo5 : To databaseFoo1 -&gt; Foo6 : To collections@enduml\n\n不用的箭头样式\n12345678910111213141516@startumlBob -&gt;x AliceBob -&gt; AliceBob -&gt;&gt; AliceBob -\\ AliceBob \\\\- AliceBob //-- AliceBob -&gt;o AliceBob o\\\\-- AliceBob &lt;-&gt; AliceBob &lt;-&gt;o AliceBob -[#red]&gt; Alice : helloAlice -[#0000FF]-&gt;Bob : ok@enduml\n\n分页\n123456789101112131415@startumlAlice -&gt; Bob : message 1Alice -&gt; Bob : message 2newpageAlice -&gt; Bob : message 3Alice -&gt; Bob : message 4newpage A title for the\\nlast pageAlice -&gt; Bob : message 5Alice -&gt; Bob : message 6@enduml\n\n分段\n12345678910111213@startuml== Initialization ==Alice -&gt; Bob: Authentication RequestBob --&gt; Alice: Authentication Response== Repetition ==Alice -&gt; Bob: Another authentication RequestAlice &lt;-- Bob: another authentication Response@enduml\n\n生命线\n12345678910111213141516171819@startumlparticipant UserUser -&gt; A: DoWorkactivate A #FFBBBBA -&gt; A: Internal callactivate A #DarkSalmonA -&gt; B: &lt;&lt; createRequest &gt;&gt;activate BB --&gt; A: RequestCreateddeactivate Bdeactivate AA -&gt; User: Donedeactivate A@enduml\n\n图例注脚等\n12345678910111213@startumlheader Page Headerfooter Page %page% of %lastpage%title Example TitleAlice -&gt; Bob : message 1note left: this is a first noteAlice -&gt; Bob : message 2@enduml\n\nC4架构图\nC4 model是一种软件架构图的设计方法，具体介绍可以参考C4 architecture model。利用C4-PlantUML工具，可以画出很多很不错的架构图。 C4模型分为Context, Container, Component和Code 4个组成部分，我们一般在画图的时候主要用到前三个组成部分\n1234567891011@startuml C4_Elements!includeurl https://raw.githubusercontent.com/RicardoNiepel/C4-PlantUML/master/C4_Context.puml!includeurl https://raw.githubusercontent.com/RicardoNiepel/C4-PlantUML/master/C4_Container.puml!includeurl https://raw.githubusercontent.com/RicardoNiepel/C4-PlantUML/master/C4_Component.pumlSystem(systemAlias, &quot;System&quot;, &quot;这可以看作系统上下文(Context)&quot;)Container(containerAlias, &quot;Container&quot;, &quot;这是Container&quot;)Person(personAlias, &quot;Person&quot;, &quot;这可以看作是组件(Component)&quot;)Rel(personAlias, containerAlias, &quot;Label&quot;, &quot;设置关联关系&quot;)@enduml\n\n参考\nPlantUML 简明教程\n","plink":"https://zinki.github.io/2017/07/03/PlantUML简明教程/"},{"title":"SpringBoot获取配置信息","date":"2017-06-15T02:37:00.000Z","date_formatted":{"ll":"2017年6月15日","L":"2017/06/15","MM-DD":"06-15"},"updated":"2024-10-10T08:03:05.459Z","content":"SpiringBoot提供了@Value注解形式获取配置信息，不过需要自动装在的Bean才能实现自动注入。比如一些封装的静态工具类无法使用这种方式，可以使用Environment的方式获取。\n\n将配置信息设置到Environment\n123456789101112131415161718import org.springframework.context.annotation.Configuration;import org.springframework.core.env.Environment;import javax.annotation.PostConstruct;import javax.annotation.Resource;@Configurationpublic class PropertiesConfig &#123;    @Resource    private Environment env;    @PostConstruct    public void setProperties() &#123;        PropertiesUtil.setEnvironment(env);    &#125;&#125;\n通过Environment获取properties配置\n12345678910111213141516171819import org.springframework.core.env.Environment;/** * @Description * @Date 2019-08-21 */public class PropertiesUtil &#123;    private static Environment env = null;    public static void setEnvironment(Environment env) &#123;        PropertiesUtil.env = env;    &#125;    public static String getProperty(String key) &#123;        return PropertiesUtil.env.getProperty(key);    &#125;&#125;\n使用\n1PropertiesUtil.getProperty(&quot;XXX&quot;);\n参考\n创建普通properties工具类读取spring boot的application.properties文件中的属性\n","plink":"https://zinki.github.io/2017/06/15/SpringBoot获取配置信息/"},{"title":"利用wordcloud生成云图","date":"2017-06-05T09:04:00.000Z","date_formatted":{"ll":"2017年6月5日","L":"2017/06/05","MM-DD":"06-05"},"updated":"2024-10-11T08:03:07.796Z","content":"最近学习了Python的语法,写了个生成云图的小demo. \n代码在Jupyter Notebook上运行\n安装执行\n12python -m pip install –upgrade pippython -m pip install jupyter\n首先读取文本\n123filename = &quot;E:\\codeStyle.txt&quot;with open(filename,encoding=&#x27;utf-8&#x27;) as f:    mytext = f.read()\n通过jieba分词\n12import jiebamytext = &quot;&quot;.join(jieba.cut(mytext))\n接下来就是用wordcloud生成云图了\n1234567891011121314151617181920from wordcloud import WordCloudimport imageiofrom os import path#path.join(path.dirname(__file__),&quot;timg.jpg&quot;)trump_coloring = imageio.imread(path.join(path.abspath(&#x27;.&#x27;),&quot;E:\\\\timg.jpg&quot;))wordcloud = WordCloud(font_path=&quot;E:\\\\simsun.ttf&quot;,                      margin=5,                      width=1800,                      height=800,                      background_color=&quot;white&quot;,                      max_words=300,                      mask=trump_coloring,                      max_font_size=40,                      random_state=42).generate(mytext)import matplotlib.pyplot as plt#%pylab inline  这行会报提示&quot;Populating the interactive namespace from numpy and matplotlib&quot;plt.imshow(wordcloud, interpolation=&#x27;bilinear&#x27;)wordcloud.to_file(&#x27;E:\\\\output.png&#x27;)plt.axis(&quot;off&quot;)plt.show()\n\n这里面有几个坑\n\n必须是实际存在的.py文件，如果在命令行执行，则会引发异常NameError: name file is not defined；应该结合os.path.abspath()使用\n如果报类似”ImportError: No module named scipy.misc”这样的异常,就用pip安装对应的组件\n默认字体不支持中文,我们需要自己下载字体放到当前目录\n\n","plink":"https://zinki.github.io/2017/06/05/Wordcloud生成云图/"},{"title":"常用lambda表达式","date":"2017-05-30T04:59:00.000Z","date_formatted":{"ll":"2017年5月30日","L":"2017/05/30","MM-DD":"05-30"},"updated":"2024-10-10T08:03:05.466Z","content":"lambda表达式可以简化代码书写，提高代码可读性，尤其对于集合操作很有用。\n从List获取某一属性列表\n1hots.stream().map(集合变量::集合类变量属性).collect(Collectors.toList());\n过滤属性写法\n123staffBOS.stream().filter((CrmStaffBO staffBO) -&gt; staffIds.contains(staffBO.getStaffId())).collect(Collectors.toList())# 过滤空值orderItemList.stream().filter(Objects::nonNull).collect(Collectors.toList());\nList 转Map\n1orderItemList.stream().collect(Collectors.toMap(ProductRespVO::getId,a-&gt;a,(k1,k2)-&gt;k1));\nList分组\n1Map&lt;String,Integer&gt;promotionalOffersMap=orderItemList.stream().collect(Collectors.groupingBy(YhPlatformOrderItem::getProductCode,Collectors.summingInt(YhPlatformOrderItem::getPromotionalOffers)));\n从List获取属性Map\n123Map&lt;Long,String&gt;urlMap=imageVideoVOS.stream().collect(Collectors.toMap(ResProductImageVideoVO::getId,ResProductImageVideoVO::getUrl,(k1,k2)-&gt;k1));# 以下形式Map&lt;String,Object&gt;productImageUrls=productCodes.stream().collect(Collectors.toMap(productCode-&gt;productCode,productCode-&gt;productClient.getProductImageUrl(productCode)));\nBigdecimal值累加\n1BigDecimaltotalCount=vo.getItemVOS().stream().map(ReqYhMiniProgOrderItemVO::getQuantity).reduce(BigDecimal.ZERO,BigDecimal::add);\n有种写法不会报错，却不会执行\n1yhPlatformOrderItems.stream().map(yhPlatformOrderItemMapper::updateById);\n不会执行,必须以下形式\n1yhPlatformOrderItems.stream().forEach(yhPlatformOrderItemMapper::updateById);","plink":"https://zinki.github.io/2017/05/30/常用lamda表达式/"},{"title":"搭建ShadowsocksR","date":"2017-05-18T03:19:00.000Z","date_formatted":{"ll":"2017年5月18日","L":"2017/05/18","MM-DD":"05-18"},"updated":"2024-10-10T08:03:05.471Z","content":"为了更好的学习(FQ),搭建VPS是必不可少的,目前在用hostwinds,优点是支持免费换IP\n使用命令搭建SSR：\n12yum -y install wget   wget -N —no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.sh &amp;&amp; chmod +x ssr.sh &amp;&amp; bash ssr.sh\n执行命令\n1bash ssr.sh\n问题\n使用了十天左右YouTube打不开了，通过IP检测网站得知VPS没问题\nIP检测网站\n在网上得知有可能默认端口2333被封了。\n切换端口即可解决，尽量大一点。\n加速\n后来发现很慢，在网上找到一个加速工具很好用\n一键安装BBR脚本\n1cd /usr/src &amp;&amp; wget -N --no-check-certificate &quot;https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh&quot; &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh\n一般默认选择“1”，安装完之后要输入“y”，重启VPS服务器。\n再次登录之后执行启动BBR执行命令：\n1cd /usr/src &amp;&amp; ./tcp.sh\n一般选择“5”，启动BBR魔改版加速。\n","plink":"https://zinki.github.io/2017/05/18/搭建ShadowsocksR/"},{"title":"Crontab的一些事","date":"2017-05-07T01:08:00.000Z","date_formatted":{"ll":"2017年5月7日","L":"2017/05/07","MM-DD":"05-07"},"updated":"2024-10-10T08:03:05.440Z","content":"这两天研究自动续订博客证书的事情，把Cron从头到尾捋了一遍，踩了不少坑 \nCron的基本命令\n下面命令都是基于CentOS Linux release 7.5.1804版本\n123456789101112131415# 编辑croncrontab -e# 查看croncrontab -l# 重载cron配置service crond reload# 重启cron服务service crond restart# 查看cron服务状态service crond status# 查看cron日志cat /var/log/cron- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\ncron表达式的坑\ncron表达式和一般定时任务表达式不一样\nCron表达式从左往右，从秒开始；而Crontab则是从分钟开始的\nCron表达式是一个字符串，字符串以5或6个空格隔开，分为6或7个域，每一个域代表一个含义，Cron有如下两种语法格\n\nMinutes Hours DayofMonth Month DayofWeek Year\nSeconds Minutes Hours DayofMonth Month DayofWeek\n\n下面放分钟执行的对比\n1234# 一般表达式0 */1 * * * ?# cron表达式* * * * *\n执行cron任务输出日志\n如果命令执行比较频繁（如每分钟一次），或者命令输出内容较多，会使这个邮件文件不断追加内容，文件越来越大。而邮件文件一般存放在根分区，根分区一般相对较小，所以会造成根分区写满而无法登录服务器\n1234567891011121314# 默认会发送邮件 通过设置取消MAILTO=&quot;&quot;SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/bin* * * * * /root/certbot.sh &gt; /root/certbot.log 2&gt;&amp;1 &amp;# 不输出内容&amp;&gt;/dev/null 2&gt;&amp;1# 将正确和错误日志都输出&gt; /root/certbot.log 2&gt;&amp;1 &amp;# 只输出正确日志&gt; /root/certbot.log &amp;# 只输出错误日志2&gt; /root/certbot.log &amp; \n名词解释\n在shell中，每个进程都和三个系统文件相关联：标准输入stdin，标准输出stdout和标准错误stderr，三个系统文件的文件描述符分别为0，1和2。所以这里2&gt;&amp;1的意思就是将标准错误也输出到标准输出当中。\n&gt; 就相当于 1&gt; 也就是重定向标准输出，不包括标准错误。通过2&gt;&amp;1，就将标准错误重定向到标准输出了（stderr已作为stdout的副本），那么再使用&gt;重定向就会将标准输出和标准错误信息一同重定向了。如果只想重定向标准错误到文件中，则可以使用2&gt; file\nTips\n重定向输出文件&gt;覆盖而&gt;&gt;是追加\n问题\n/bin/sh: root: command not found\n执行cron命令添加root用户会报错\n问题在于文件/var/spool/cron/root已默认，无需再写root\n参考\ncrontab在线工具\ncrontab 脚本错误日志和正确的输出写入到文件\n","plink":"https://zinki.github.io/2017/05/07/Crontab的一些事/"},{"title":"免费升级Https","date":"2017-04-29T09:57:00.000Z","date_formatted":{"ll":"2017年4月29日","L":"2017/04/29","MM-DD":"04-29"},"updated":"2024-10-10T08:03:05.464Z","content":"Https正在流行,刚好了解到Let’s Encryp免费提供证书,借此把博客升级一下 \n到官网申请证书\n具体步骤按提示一步一步来,最终得到这样的提示说明证书已经生成\n12345678** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry**          (The test certificates below have not been saved.)Congratulations, all renewals succeeded. The following certs have been renewed:  /etc/letsencrypt/live/zeroz.top/fullchain.pem (success)** DRY RUN: simulating &#x27;certbot renew&#x27; close to cert expiry**          (The test certificates above have not been saved.)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nnginx配置升级\n编辑配置文件\n1vi /etc/nginx/conf.d/https.conf\n重定向到htpps\n123listen 80;server_name zeroz.top;rewrite ^(.*) https://$server_name$1 permanent;\n编辑配置文件\n1vi /etc/nginx/nginx.conf\n1234567891011121314151617181920212223242526272829303132333435363738    server &#123;        listen       443 ssl http2 default_server;        listen       [::]:443 ssl http2 default_server;        server_name  zeroz.top;        root         /usr/share/nginx/html;        ssl on;        ssl_certificate &quot;/etc/letsencrypt/live/zeroz.top/fullchain.pem&quot;;        ssl_certificate_key &quot;/etc/letsencrypt/live/zeroz.top/privkey.pem&quot;;        ssl_session_cache shared:SSL:1m;        ssl_session_timeout  10m;        ssl_ciphers HIGH:!aNULL:!MD5;        ssl_prefer_server_ciphers on;##        # Load configuration files for the default server block.#        include /etc/nginx/default.d/*.conf;#        location / &#123;        &#125;        location /blog &#123;            root /var/www/;        &#125;        location ~ .*\\.(eot|ttf|woff|woff2)$        &#123;            root /var/www/;            add_header Access-Control-Allow-Origin *;        &#125;        error_page 404 /404.html;            location = /40x.html &#123;        &#125;        error_page 500 502 503 504 /50x.html;            location = /50x.html &#123;        &#125;    &#125;\n重启nginx\n1$ nginx -s reload\n第三步 证书续订\n利用cron定时续订证书\n因为证书每90天过期,certbot很贴心的提供了证书延期命令\n1$ sudo certbot renew --dry-run\n配置cron命令让服务器定时执行即可实现自动化\n12345crontab -e#添加cron0 0,3 * * * python -c&#x27;导入随机; 进口时间; time.sleep（random.random（）* 3600）&#x27;&amp;&amp; certbot renew#编辑完成$ /bin/systemctl start crond.service\n也可用cron执行shell\n之前cron不会执行的原因是环境变量，需要调整crontab规则\n1234SHELL=/bin/shPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin* * */1 * * ./etc/profile;/bin/sh /usr/sbin/certbot.sh\n脚本附下\n123456789101112131415#! /bin/bash## Certbot Automating renewalnginx=&quot;/usr/sbin/nginx&quot;prog=$(basename $nginx)NGINX_CONF_FILE=&quot;/etc/nginx/nginx.conf&quot;echo 开始停止nginxnginx -s stopecho 开始续订证书# sudo certbot renew --dry-runsudo certbot renew --dry-runecho 启动nginxnginxecho 证书续订结束\n问题\nLet’s Encryp致力于推广Https,操作步骤已经很简单了,有一点问题就是证书的生成和续订需要http请求,而nginx默认的监听端口也是80,所以会报端口占用.需要先关闭nginx,续订完成再启动\n上述脚本sudo certbot renew --dry-run当中–dry-run不会保存生成证书\n** DRY RUN: simulating ‘certbot renew’ close to cert expiry\n**          (The test certificates above have not been saved.)\nAnother instance of Certbot is already running (Letsencrypt)\nIf it is not running, check whether there are .certbot.lock files in your system.\n1find / -type f -name &quot;.certbot.lock&quot;\nIf there are, you can remove them:\n1find / -type f -name &quot;.certbot.lock&quot; -exec rm &#123;&#125; \\;\n参考\nCertbot：Automatically enable HTTPS on your website with EFF’s Certbot, deploying Let’s Encrypt certificates\n","plink":"https://zinki.github.io/2017/04/29/免费升级Https/"},{"title":"使用Hexo和Git hooks搭建静态博客","date":"2017-04-24T02:14:00.000Z","date_formatted":{"ll":"2017年4月24日","L":"2017/04/24","MM-DD":"04-24"},"updated":"2024-10-10T08:03:05.463Z","content":"之前用Git Pages搭建博客，有个缺陷，要么付费，要么放在公共仓库，刚好git前几天宣布私有仓库免费，周末研究了下，把博客站点放到VPS上面。其间遇到很多坑，大多是和权限相关，遇到问题可以见招拆招。\n服务端\n安装所需环境，包括 git，Nginx\n创建一个 git 用户，用来运行 git 服务：\n12$ sudo adduser git$ sudo passwd password\n授权sudo权限\n123456$ #编辑 sudo 分组$ sudo visudo$ ...  root    ALL=(ALL)       ALL  git   ALL=(ALL)       NOPASSWD: ALL    #免密配置  ...\n创建公钥\n将id_rsa.pub文件内容添加到服务器/home/git/.ssh/authorized_keys文件中\n如果你之前没有生成过公钥，则可能就没有 id_rsa.pub 文件，具体的生成方法，可以参考这里。\n测试方法: ssh git@IP\n初始化 Git 仓库\n12$ cd /home/git$ sudo git init --bare hexo.git\n\n使用 git init --bare  可以创建一个裸仓库，并且这个仓库是可以被正常 clone 和 push 更新的， 裸仓库不包含工作区，所以并不会存在在裸仓库上直接提交变更的情况，裸仓库一般情况下是作为远端的中心仓库而存在的\n配置 git hooks，关于 hooks 的详情内容可以参考这里\n\n12$ cd /var/repo/blog.git/hooks$ vim post-receive\n\n在 post-receive 文件中写入如下内容：\n\n1234#!/bin/bashsudo rm -rf /var/www/bloggit clone /home/git/hexo.git /var/www/blog\n\n不要忘记设置这个文件的可执行权限：\n\n12chmod +x post-receive$ sudo git init --bare hexo.git\n\n创建站点部署目录\n\n1$ cd /var/ &amp;&amp; mkdir -p www/blog\n\n添加git用户权限\n\n12$ sudo chown -R git:git hexo.git$ sudo chown -R git:git /var/www\n禁用 git 用户的 shell 登录权限\n编辑 /etc/passwd 来实现，在 /etc/passwd 中找到类似下面的一行：\n1git:x:1001:1001:,,,:/home/git:/bin/bash\n将其改为:\n1git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell\n这样 git 用户可以通过 ssh 正常使用 git，但是无法登录 shell。\n客户端\n安装 nodeJs，hexo\n1234brew updatebrew install node# 安装hexonpm install hexo-cli -g\n初始化 Hexo &amp;&amp; 修改仓库地址\n\n在本地目录执行初始化\n\n1234hexo init hexocd hexonpm install hexo-deployer-git --savevi _config.yml\n\n跳到最后一行，修改仓库地址，允许配置多个\n\n1234567deploy:- type: git  repo: git@IP:/home/git/hexo.git  branch: master- type: git  repo: git@github.com:user/blog.git  branch: master\n依次执行即可实现动态部署\n123hexo ghexo shexo d\n后续拓展\n12345678910# 插件hexo-auto-excerpt # 不需要时uninstall方起作用# hexo推荐使用&lt;!--more--&gt;npm install hexo-excerpt --save# 看板娘npm install --save hexo-helper-live2dnpm install live2d-widget-model-harunpm install live2d-widget-model-shizuku\n参考\n使用 Git Hook 自动部署 Hexo 到个人 VPS\n博客摘要hexo-excerpt\n","plink":"https://zinki.github.io/2017/04/24/使用Hexo和Git hooks搭建静态博客/"}]