{"title":"大数据日知录笔记","date":"2019-11-16T02:10:00.000Z","date_formatted":{"ll":"2019年11月16日","L":"2019/11/16","MM-DD":"11-16"},"link":"2019/11/16/大数据日知录笔记","tags":["大数据","笔记"],"categories":["笔记"],"updated":"2024-10-10T08:03:05.465Z","content":"<p><img src=\"https://i.loli.net/2020/06/09/r6cSQVZyz4DF8NP.png\" alt=\"\" loading=\"lazy\" class=\"φbp\"></p>\n<span id=\"more\"></span>\n<p>硬件成本的快速下降,使得电子设备的无处不在成为可能,数据无处不在,无时不在.<br>\nIBM用3V(Volume,Velocity,Variety)来描述大数据的特点,后来又增加了Value这个维度,即价值密度低的数据成为大数据,需要从低价值的原始海量数据中进行深度挖掘和计算,总结出具有高价值的数据.</p>\n<p>CAP/ACID/BASE三者的关系<br>\nACID和BASE原则是在明确提出CAP理论之前关于如何对待可用性和强一致性的两种完全不同的设计哲学.ACID更强调数据一致性,这是传统数据库设计思路.而BASE更强调可用性,弱化数据强一致性的概念,这是互联网时代对于大规模分布式数据系统的一种需求,尤其是其中的软状态和最终一致性,这两者是在容忍分区情形下强调可用性的具体手段.</p>\n<p>布隆过滤器是由Howard Bloom在1970年提出的二进制向量数据结构,具有很好的空间和时间效率,尤其是空间效率极高,经常用于检测某个元素是否在巨量数据集合中的成员.<br>\nBF可以高效地表征集合数据. 其使用长度为m的位数组来存储集合信息. 同时使用k个相互独立的哈希函数将数据映射到位数组空间.<br>\n其基本思想如下:首先将长度为m的位数组元素全部置为0 对于集合S中的某个成员a,分别使k个哈希函数对其计算. 如果</p>\n<p><img src=\"http://latex.codecogs.com/gif.latex?h_i(a)=x(l%3Ci%3Ck,l%3Cx%3Cm)\" alt=\"\" loading=\"lazy\" class=\"φbp\"></p>\n<p>则将位数组的第x位置为1,对于成员a来说, 经过k个哈希函数计算后. 可能会将位数组中的W<br>\n位(w&lt;=k)设置为1.对于集合中的其他成员也如此处理,这样即可完成位数组空间的集合表示<br>\n算法流程如下:<br>\n<img src=\"https://i.loli.net/2020/06/09/ZihOHAcFmYvSszf.png\" alt=\"\" loading=\"lazy\"></p>\n<p>因为BF使用位数组和哈希函数来表征集合. 并不需要实际存储集合数据本身内容,所以空间利用率非常高. 但是有个潜在问题. 即在查询某个成员是否属于集合时,会发生误判(False Resitive)</p>\n<p>SkipList由Wil1iam Pugh于1990年提出,这是一种可替代平衡树的数据结构.不像平衡树需要强制保持树的平衡. SkipList 依靠随机生成数以一定概率来保持数据的平衡分布。 尽管在最坏情况下skipList的效率要低于平衡树. 但是大多数情况下其效率仍然常,其插入、删除、查找数据的时间复杂度都是O(log(N)).</p>\n<p>LSM树(Log-structured Merge-tree)的本质是将大量的随机写操作转换成批量的序列写. 这样可以极大地提升磁盘数据写入速度, 所以LSM树非常适合对写操作效率有高要求的应用场景.但是其对应付出的代价是读效率有所降低. 这往往可以引入Bloom Filter或者缓存等优化措施来 对读性能进行改善.</p>\n<p>Merkle哈希树由Ralph Merkle于l979年发音 . 因故得此名.一般还将其称为Merkle树或哈<br>\n希树(Hash Tree). Merkle树最初用于高效Lamport签名验证.后来被广泛应用在分布式领域,主要用来在海量数据下快速定位少量变化的数据内容(变化原因可能是损毁、篡改或正常变化.<br>\n比特币也引用了Merkle树对交易进行验证.</p>\n<p>Snappy是Google开源出的高效数据压缩与解压缩算法库, 其目标并非是最高的数据压缩率, 而<br>\n是在合理的的压缩率基础上追求尽可能快的压缩和解压缩速度, 其压缩和解压缩速度极快, 可以在单核处埋器上达到250MB/S的压缩效率和500MB/s的解压缩效率。与此同时,snappy相比其他压缩方案占用CPU时间更少.<br>\n数据压缩与解压缩本质上是通过增加CPU计算时间成本采换取较小的存储成本以及网络和I/O传输成本.如果只是追求存储成本最小化.Snappy这种技术方案是不适用的, 但是对于很多情形,<br>\n在合理压缩率情况下追求最高的压缩和解压缩速度比单纯追求最小的存储成本更重要。</p>\n<p>与霍夫曼编码这种统计编码不同, LZ77是一种动态词典编码 (Dictionary Coding). 词典编码的基本思路是: 文本中的词用它在词典中表示位置的号码代替的无损数据压缩方法, 一般分为静态词典方法和动态词典方法两种</p>\n<p>Kafka通过消息副本机制提供了高可用的消息服务，其副本管理单位不是Topic消息队列，而是Topic的数据分片（Partition）。在配置文件里可以指定数据分片的副本个数，在多个副本里，其中一个作为主副本（Leader），其他作为次级副本（Slave）。所以针对这个数据分片的消息读/写请求都由主副本负责响应，次级副本只是以主副本数据消费者的方式从主副本同步数据；当主副本发生故障时，Kafka将其中某个次级副本提升为主副本，以此来达到整个消息系统的高可用性。<br>\nKafka未使用类似Zab或Paxos协议的多数投票机制来保证主备数据的一致性，而是提出一种称为ISR（In-Sync Replicas）的机制保证数据一致性。原因是如果副本个数是2f+1，那么多数投票机制最多允许f歌副本发生故障，即如果需要1个副本容错，至少要保持3个数据副本，如果需要2个副本容错，至少要维护5个数据副本。考虑到消息系统的应用场景，只允许1个副本容错过于脆弱，至少要支持2个副本容错，即至少要维护5个数据副本，效率太低。</p>\n<p>ISR的运行机制如下：将所有次级副本数据分到两个集合，其中一个被称为ISR集合，这个集合备份数据的特点是即时和主副本数据保持一致，而另外一个备份数据允许其消息队列落后于主副本的数据。在做主备切换时，只允许从ISR集合中选择候选主副本，这样可保证切换后新的主副本数据状态和老的主副本保持一致。在数据分片进行消息写入时，只有ISR集合内所有备份都写成功才能认为这次写入操作成功。在具体实现时，Kafka利用Zookeeper来保存每个ISR集合的信息，当ISR集合内成员变化时，相关构件也便于通知。通过这种方式，如果设定ISR集合大小为f+1，那么最多可允许f个副本故障。</p>\n<p>使用磁盘读/写根本且普适的原则是：尽可能避免随机读/写，同时尽可能利用顺序读/写，即连续读/写整块数据。<br>\nKafka高效处理大批量消息的重要原因是将读/写操作尽可能转换为顺序读/写，比如类似于Log文件方式的文件尾部追加写。另外，Kafka涉及将文件内容通过网络进行传输，为提升效率，Kafka采用Linux操作系统的SendFile调用。为了避免多次数据复制，操作系统可以直接将数据从内核页缓存中复制到网卡缓存，这样可以加大整个过程的速度。</p>\n<p>分布式系统中一个重要的研究内容是如何将数据通知到网络中的多个接收方，一般称为多传播通信。<br>\nGossip原意是谣言或小道消息，Gossip协议被称为感染协议（Epidemic Protocol）。<br>\nGossip协议用来尽快将本地更新数据通知到网络中的所有其他节点，更新模型可分为3种：<br>\n全部通知模型，反熵模型，散布谣言模型。</p>\n<p>GFS在实际存储时首先会将不同大小的文件切割成固定大小的数据块，每一块称称为一个Chunk，通常设定大小为64MB。<br>\n<img src=\"https://i.loli.net/2020/06/09/PGNZMAzg4svrmLD.png\" alt=\"\" loading=\"lazy\"></p>\n<p>GFS系统化内部需要维护文件名称到其对应的多个Chunk之间的映射关系，Chunk服务器负责对Chunk的实际存储，同时响应GFS客户端对自己负责的Chunk的读/写操作。<br>\n<img src=\"https://i.loli.net/2020/06/09/2Bkqw6bJZN1EYyK.png\" alt=\"\" loading=\"lazy\"></p>\n<p>Google的云存储平台有个显著的特点，就是大量采用主从结构，即单一的主控服务器和众多的存储服务器，主控服务器主要从事系统元数据存储管理及整个分布式系统的管理，比如负载均衡，数据在存储服务器之间迁移，检测新加入的机器及失效机器等工作。<br>\n采用主从结构的好处是整个系统存在一个全局的主控节点，管理相对简单，缺点是因为主控节点是唯一的，很多服务请求都需经过主控服务器，很容易称为整个系统的瓶颈，另外，存在单点失效问题，如果主控服务器瘫痪，整个系统不可用。</p>\n<p>为了增加存储系统的可靠性和数据的可用性，经常使用数据备份来达到这一点，通常的做法是对数据做3备份，但数据备份带来的缺点是增加存储成本。常见的解决方案是对于热点数据，在大规模存储系统中仍然保留3个备份，对于冷数据，只保留1分数据，通过纠删码保证数据的可靠性。<br>\n纠删码通过对原始数据进行校验并保留校验数据，以增加冗余的方式保证数据的可恢复性。极大距离可分码（Maximum Distance Separable Codes，MDS）是一种常用的纠删码，其将数据文件切割为等长的n个数据块，并根据这n个数据块生成m个冗余的校验信息，使得n+m块数据中即使任意m块数据损失，也可通过剩下n块数据对m块损失的数据进行重构，以此俩完成数据容错功能。</p>\n<p>和传统的MMP架构（并行数据库系统）相比，MapReduce更适合非结构化数据的ETL处理累操作，且其可拓展性及容错性明显占优，但单机处理效率低。尽管MR提供了简洁的API和完善的容错处理机制，使得大规模兵法处理海量数据称为可能，但从发展趋势看，相对复杂的任务转换为MR任务开发效率不够高，所以有逐步封装到下层的趋势，即在上层系统提供更简洁的API，在底层由系统自动转换为大量MR任务。<br>\nDAG是有向无环图（Directed Acyclic Graph）的简称。在大数据处理中，DAG计算常常指的是将计算任务在内部分解成为若干个子任务，将这些子任务之间的逻辑关系或顺序构建成DAG（有向无环图）结构。DAG计算模型可以认为是对MR计算机制的一种拓展。</p>\n<p>Hive是Facebook设计并开源的构建在Hadoop基础之上额度数据仓库解决方案，与传统数据仓库相比，Hive能处理超大规模的数据且有更好的容错性。Hive的本质思想是为Hadoop存储的数据增加模式（schema），并为用户提供sql语言，Hive将类sql语言转换为一系列MR任务来实现数据的处理，以此手段达到便利操作数据仓库的目的。</p>\n<p>Hive的缺点是查询处理效率较低，是MR固有的一些特性导致的，主要是因为Hive和Hadoop绑定关系太紧密导致的。</p>\n<p>机器学习的目的是从数据中自动习得模型，对未知数据进行预测，近期学习的任务是从数据中学习决策函数fx–&gt;y，这个决策函数将输入变量x映射到输出空间的输出变量y中，即根据输入产生预测。</p>\n<h2 id=\"参考\">参考<a title=\"#参考\" href=\"#参考\"></a></h2>\n<p><a href=\"https://book.douban.com/subject/25984046/\" target=\"_blank\">大数据日知录</a></p>\n","prev":{"title":"OOP-KLASS二分模型","link":"2019/12/10/OOP-KLASS二分模型"},"next":{"title":"数据库相关知识","link":"2019/10/05/数据库相关知识"},"plink":"https://zinki.github.io/2019/11/16/大数据日知录笔记/","toc":[{"id":"参考","title":"参考","index":"1"}]}