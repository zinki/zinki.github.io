{"title":"Hadoop伪分布式部署","date":"2019-01-09T07:00:00.000Z","date_formatted":{"ll":"2019年1月9日","L":"2019/01/09","MM-DD":"01-09"},"link":"2019/01/09/Hadoop伪分布式部署","tags":["Hadoop"],"categories":["学习"],"updated":"2024-10-10T08:03:05.443Z","content":"<p>Hadoop can also be run on a single-node in a pseudo-distributed mode where each Hadoop daemon runs in a separate Java process.</p>\n<span id=\"more\"></span>\n<h2 id=\"配置\">配置<a title=\"#配置\" href=\"#配置\"></a></h2>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etc/hadoop/core-site.xml:</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">etc/hadoop/hdfs-site.xml:</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class=\"line\">        &lt;value&gt;1&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>\n<h2 id=\"ssh免密码\">SSH免密码<a title=\"#ssh免密码\" href=\"#ssh免密码\"></a></h2>\n<p>Now check that you can ssh to the localhost without a passphrase:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh localhost</span><br></pre></td></tr></table></figure>\n<p>If you cannot ssh to localhost without a passphrase, execute the following commands:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh-keygen -t rsa -P &#x27;&#x27; -f ~/.ssh/id_rsa</span><br><span class=\"line\">$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class=\"line\">$ chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure>\n<h2 id=\"执行\">执行<a title=\"#执行\" href=\"#执行\"></a></h2>\n<ol>\n<li>Format the filesystem:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>Start NameNode daemon and DataNode daemon:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>\n<p>The hadoop daemon log output is written to the $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs).</p>\n<ol start=\"3\">\n<li>Browse the web interface for the NameNode; by default it is available at:</li>\n</ol>\n<blockquote>\n<p>○ NameNode - <a href=\"http://localhost:9870/\">http://localhost:9870/</a></p>\n</blockquote>\n<ol start=\"4\">\n<li>Make the HDFS directories required to execute MapReduce jobs:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hdfs dfs -mkdir /user</span><br><span class=\"line\">$ bin/hdfs dfs -mkdir /user/&lt;username&gt;</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>Copy the input files into the distributed filesystem:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hdfs dfs -mkdir input</span><br><span class=\"line\">$ bin/hdfs dfs -put etc/hadoop/*.xml input</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<ol start=\"6\">\n<li>Run some of the examples provided:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#x27;dfs[a-z.]+&#x27;</span><br></pre></td></tr></table></figure>\n<ol start=\"7\">\n<li>Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hdfs dfs -get output output</span><br><span class=\"line\">$ cat output/*</span><br></pre></td></tr></table></figure>\n<p>or<br>\nView the output files on the distributed filesystem:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ bin/hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>\n<ol start=\"8\">\n<li>When you’re done, stop the daemons with:</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\">参考<a title=\"#参考\" href=\"#参考\"></a></h2>\n<p><a href=\"https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html\" target=\"_blank\">Hadoop: Setting up a Single Node Cluster.</a></p>\n","prev":{"title":"JVM调优","link":"2019/04/15/JVM调优"},"next":{"title":"网络相关知识","link":"2018/12/11/网络相关知识"},"plink":"https://zinki.github.io/2019/01/09/Hadoop伪分布式部署/","toc":[{"id":"配置","title":"配置","index":"1"},{"id":"ssh免密码","title":"SSH免密码","index":"2"},{"id":"执行","title":"执行","index":"3"},{"id":"参考","title":"参考","index":"4"}]}