{"title":"Kafka相关知识","date":"2021-02-17T13:10:00.000Z","date_formatted":{"ll":"2021年2月17日","L":"2021/02/17","MM-DD":"02-17"},"link":"2021/02/17/Kafka相关知识","tags":["Kafka"],"categories":["学习"],"updated":"2024-10-11T04:19:35.121Z","content":"<p>Kafka是一种分布式的，基于发布/订阅的消息系统。<span id=\"more\"></span></p>\n<p><img src=\"http://zeven.site:7521/2024/10/202410110953842.png\" alt=\"\" loading=\"lazy\" class=\"φbp\"></p>\n<h3 id=\"相关名词解释\">相关名词解释<a title=\"#相关名词解释\" href=\"#相关名词解释\"></a></h3>\n<ol>\n<li>producer：消息生产者，发布消息到 kafka 集群的终端或服务。</li>\n<li>broker：kafka 集群中包含的服务器。</li>\n<li>topic：每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。</li>\n<li>partition：partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。</li>\n<li>consumer：从 kafka 集群中消费消息的终端或服务。</li>\n<li>Consumer group：high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 中的一个 Consumer 消费，但可以被多个 consumer group 消费。</li>\n<li>replica：partition 的副本，保障 partition 的高可用。</li>\n<li>leader：replica 中的一个角色， producer 和 consumer 只跟 leader 交互。</li>\n<li>follower：replica 中的一个角色，从 leader 中复制数据。</li>\n<li>controller：kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。</li>\n<li>zookeeper：kafka 通过 zookeeper 来存储集群的 meta 信息。</li>\n</ol>\n<p>kafka 在 zookeeper 中的存储结构如下图所示：<br>\n<img src=\"http://zeven.site:7521/2024/10/202410110954804.png\" alt=\"\" loading=\"lazy\"></p>\n<p>producer delivery guarantee<br>\n一般情况下存在三种情况：</p>\n<ol>\n<li><code>At most once</code> 消息可能会丢，但绝不会重复传输</li>\n<li><code>At least one</code> 消息绝不会丢，但可能会重复传输</li>\n<li><code>Exactly once</code> 每条消息肯定会被传输一次且仅传输一次<br>\n当 producer 向 broker 发送消息时，一旦这条消息被 commit，由于 replication 的存在，它就不会丢。但是如果 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那 Producer 就无法判断该条消息是否已经 commit。虽然 Kafka 无法确定网络故障期间发生了什么，但是 producer 可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了 <code>Exactly once</code>，但目前还并未实现。所以目前默认情况下一条消息从 producer 到 broker 是确保了 <code>At least once</code>，可通过设置 producer 异步发送实现<code>At most once</code>。</li>\n</ol>\n<p>consumer delivery guarantee<br>\n如果将 consumer 设置为 autocommit，consumer 一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那 Kafka 确保了 Exactly once。<br>\n但实际使用中应用程序并非在 consumer 读取完数据就结束了，而是要进行进一步处理，而数据处理与 commit 的顺序在很大程度上决定了consumer delivery guarantee：</p>\n<ol>\n<li>读完消息先 commit 再处理消息。<br>\n这种模式下，如果 consumer 在 commit 后还没来得及处理消息就 crash 了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once</li>\n<li>读完消息先处理再 commit。<br>\n这种模式下，如果在处理完消息之后 commit 之前 consumer crash 了，下次重新开始工作时还会处理刚刚未 commit 的消息，实际上该消息已经被处理过了。这就对应于 <code>At least once</code>。</li>\n<li>如果一定要做到 <code>Exactly once</code>，就需要协调 offset 和实际操作的输出。<br>\n精典的做法是引入两阶段提交。如果能让 offset 和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer 拿到数据后可能把数据放到 HDFS，如果把最新的 offset 和数据本身一起写到 HDFS，那就可以保证数据的输出和 offset 的更新要么都完成，要么都不完成，间接实现 Exactly once。（目前就 <code>high-level API</code>而言，offset 是存于Zookeeper 中的，无法存于HDFS，而<code>SimpleConsuemr API</code>的 offset 是由自己去维护的，可以将之存于 HDFS 中）</li>\n</ol>\n<p>总之，Kafka 默认保证<code>At least once</code>，并且允许通过设置 producer 异步提交来实现 <code>At most once</code>。而 <code>Exactly once</code> 要求与外部存储系统协作，幸运的是 kafka 提供的 offset 可以非常直接非常容易得使用这种方式</p>\n<h3 id=\"kafka拓扑结构\">Kafka拓扑结构<a title=\"#kafka拓扑结构\" href=\"#kafka拓扑结构\"></a></h3>\n<p><img src=\"http://zeven.site:7521/2024/10/202410110954506.png\" alt=\"\" loading=\"lazy\" class=\"φbp\"></p>\n<p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>\n<p>Topic &amp; Partition<br>\nTopic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹</p>\n<p>每个日志文件都是一个log entrie序列，每个log entrie包含一个4字节整型数值（值为N+5），1个字节的&quot;magic value&quot;，4个字节的CRC校验码，其后跟N个字节的消息体。每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">message length ： 4 bytes (value: 1+4+n)</span><br><span class=\"line\">&quot;magic&quot; value ： 1 byte </span><br><span class=\"line\">crc ： 4 bytes </span><br><span class=\"line\">payload ： n bytes </span><br></pre></td></tr></table></figure>\n<p>这个log entries并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以<code>.kafka</code>为后缀。另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围，如下图所示:</p>\n<p><img src=\"http://zeven.site:7521/2024/10/202410110955089.png\" alt=\"\" loading=\"lazy\" class=\"φbp\"></p>\n<p>因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。</p>\n<blockquote>\n<p>ISR（in-sync replicas）副本同步</p>\n</blockquote>\n","prev":{"title":"线程池设置线程名称","link":"2021/03/20/线程池设置线程名称"},"next":{"title":"如何删除服务器攻击脚本","link":"2020/12/11/如何删除服务器攻击脚本"},"plink":"https://zinki.github.io/2021/02/17/Kafka相关知识/","toc":[{"id":"相关名词解释","title":"相关名词解释","index":"1"},{"id":"kafka拓扑结构","title":"Kafka拓扑结构","index":"2"}]}